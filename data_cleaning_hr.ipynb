{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning steps:\n",
    "- replace @ handles with: hdl (chose a word with no punctuation so no extra step is needed to process, hdl = handle)\n",
    "- replace urls by: url\n",
    "- replace emoticons with corresponding emojis\n",
    "- split retweets in tweet and retweet\n",
    "\n",
    "For all of these, first check what is the prevalence and if it is worth the effort. \n",
    "\n",
    "Ideas:\n",
    "- split hashtags into words -> Carlo tackling that\n",
    "- Tweets not in english -> Daniel tackling that\n",
    "- replace contractions & spellchecking\n",
    "    - Character ngram will probably be more efficient due to the really low quality of speach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 140\n",
    "import nltk\n",
    "import re\n",
    "from IPython.display import display\n",
    "import happyfuntokenizing\n",
    "from happyfuntokenizing import TweetTokenizer\n",
    "\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder cannot be called in this file before the all subfunctions are defined\n",
    "def clean(df):\n",
    "    \"\"\"Data cleaning steps:\n",
    "    - replace @ handles with: hdl (chose a word with no punctuation so no extra step is needed to process, hdl = handle)\n",
    "    - replace urls by: url\n",
    "    - replace emoticons with corresponding emojis\n",
    "    - split retweets in tweet and retweet\n",
    "    \n",
    "    To be added:\n",
    "    - remove non english tweets, done on the text only (not retweet). Needs to be applied after emoji split. \n",
    "    - hashtags splits\n",
    "    \n",
    "    Returns None (data cleaning in place)\n",
    "    \"\"\"\n",
    "    cleanHandle(df)\n",
    "    cleanURL(df)\n",
    "    convertEmoticon(df)\n",
    "    cleanRetweets(df)\n",
    "    splitTextEmoji(df)\n",
    "    df = cleanNonEnglish(df)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loader(filename):\n",
    "    \"\"\" Load tweets from filename. Resets the index. Returns the loaded data frame\"\"\"\n",
    "    with open(filename,'r') as f:\n",
    "        df = pd.DataFrame(json.load(f))\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace @ handles with hdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanHandle(df):\n",
    "    \"\"\" Replace in-place handles with hdl keyword\n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    pattern = r\"@[a-zA-Z0-9_]{1,15}\" #from http://kagan.mactane.org/blog/2009/09/22/what-characters-are-allowed-in-twitter-usernames/\n",
    "    print(\"{} handles replaced\".format(np.sum(df.text.str.contains(pattern).values)))\n",
    "    df.text = df.text.str.replace(pattern, \" hdl \")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No \"hdl\" words for confusion in the txt. Good replacement name. \n",
    "\n",
    "Best to replace handles with \"\\ hdl\\ \", so for tokenization it will be easier to identify as a word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace URLs with url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanURL(df):\n",
    "    \"\"\" Replace in-place URLs with url keyword\n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    pattern = r'(?:http://|https://|www.)[^‚Äú‚Äù\"\\' ]+' # From http://stackoverflow.com/questions/7679970/python-regular-expression-nltk-website-extraction\n",
    "    print(\"{} urls replaced\".format(np.sum(df.text.str.contains(pattern).values)))\n",
    "    df.text = df.text.str.replace(pattern, \" url \")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URLs are quiet well formed and are generally at the end of tweets. No risk of engulfing in the cleaning some more text after the url.\n",
    "\n",
    "keyword url is used only 4 times in dataset, no risk of confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert emoticons to emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Based on:\n",
    "# https://slack.zendesk.com/hc/en-us/articles/202931348-Emoji-and-emoticons\n",
    "# http://unicodey.com/emoji-data/table.htm\n",
    "# http://www.unicode.org/emoji/charts/emoji-list.html\n",
    "\n",
    "def convertEmoticon(df):\n",
    "    \"\"\" Replace in-place common emoticons to emojis.\n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    emoticon2emoji = {\n",
    "        r\"<3\": \"\\u2764\",\n",
    "        r\"</3\": \"\\U0001F494\",\n",
    "        r\"8\\)\": \"\\U0001F60E\",\n",
    "        r\"D:\": \"\\U0001F627\",\n",
    "        r\":'\\(\": \"\\U0001F622\",\n",
    "        r\":o\\)\": \"\\U0001F435\",\n",
    "        r\":-*\\*\": \"\\U0001F48B\",\n",
    "        r\"=-*\\)\": \"\\U0001F600\",\n",
    "        r\":-*D\": \"\\U0001F600\",\n",
    "        r\";-*\\)\": \"\\U0001F609\",\n",
    "        r\":-*>\": \"\\U0001F606\",\n",
    "        r\":-*\\|\": \"\\U0001F610\",\n",
    "        r\":-*[Oo]\": \"\\U0001F62E\",\n",
    "        r\">:-*\\(\": \"\\U0001F620\",\n",
    "        r\":-*\\)|\\(:\": \"\\U0001F603\",\n",
    "        r\":-*\\(|\\):\": \"\\U0001F61E\",\n",
    "        r\":-*[/\\\\]\": \"\\U0001F615\",\n",
    "        r\":-*[PpbB]\": \"\\U0001F61B\",\n",
    "        r\";-*[PpbB]\": \"\\U0001F61C\"\n",
    "    }\n",
    "    \n",
    "    total = 0\n",
    "    for emoticon in emoticon2emoji:\n",
    "        nreplacements = np.sum(df.text.str.contains(emoticon).values)\n",
    "        total += nreplacements\n",
    "        print(\"{:10} -> {:>5} replaced {:6} times\".format(emoticon, emoticon2emoji[emoticon], nreplacements))\n",
    "        df.text = df.text.str.replace(emoticon, emoticon2emoji[emoticon])\n",
    "    print(\"{:3} replaced {} times\".format(\"ALL\", total))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split retweets into user content and retweeted content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cannot be called before functions within are defined \n",
    "def cleanRetweets(df):\n",
    "    \"\"\" Remove from the text column the retweet column and add to seperate column \"retweet\". \n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    nsplits = 0\n",
    "    nsplits += splitRetweets(df)\n",
    "    nsplits += splitQuotes(df) # Need to maintain that order\n",
    "    print(\"{} retweets processed\".format(nsplits))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitRetweets(df):\n",
    "    \"\"\" Extract retweets with the RT keyword\"\"\"\n",
    "    pattern = r\"\"\"(.*(?:\\W|^))(RT(?:\\ ?[\\\":‚Äú]|$).*) # Retweets with RT keyword\"\"\"\n",
    "    retweets = pd.DataFrame(df.text.str.extract(pattern, flags=re.X))\n",
    "    retweets.columns = [\"text\", \"retweet\"]\n",
    "    non_null_idxs = retweets.retweet.notnull()\n",
    "    df.loc[non_null_idxs,[\"text\"]] = retweets.text[non_null_idxs]\n",
    "    df[\"retweet\"] = retweets.retweet\n",
    "    return len(non_null_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def splitQuotes(df):\n",
    "    \"\"\" Extract retweets in quote format.\n",
    "    See http://support.gnip.com/articles/identifying-and-understanding-retweets.html\n",
    "    \"\"\"\n",
    "    pattern = r\"(.*?)((?:([\\\"\\'])|(?:(‚Äú))|‚Äò)\\s*hdl.*(?(3)\\3|(?(4)‚Äù|‚Äô)))(.*)\" #Pattern to match quote, possibly nested\n",
    "    retweets = pd.DataFrame(df.text.str.extract(pattern, flags=re.X)[[0,1,4]])\n",
    "    retweets.columns = [\"text_before\", \"retweet\", \"text_after\"]\n",
    "    non_null_idxs = retweets.retweet.notnull()\n",
    "    retweets[\"text\"] = retweets.loc[non_null_idxs, [\"text_before\", \"text_after\"]].apply(lambda x: \" \".join(x), axis=1)\n",
    "    df.loc[non_null_idxs,[\"text\"]] = retweets.text[non_null_idxs].copy()\n",
    "    df[\"retweet\"] = retweets.retweet.copy()\n",
    "    return len(retweets[non_null_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Text and Emoji and create two new columns for only text and only emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Wide UCS-4 build\n",
    "    highpoints = re.compile(u'['\n",
    "        u'\\U0001F300-\\U0001F64F'\n",
    "        u'\\U0001F680-\\U0001F6FF'\n",
    "        u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "        re.UNICODE)\n",
    "except re.error:\n",
    "    # Narrow UCS-2 build\n",
    "    highpoints = re.compile(u'('\n",
    "        u'\\ud83c[\\udf00-\\udfff]|'\n",
    "        u'\\ud83d[\\udc00-\\ude4f\\ude80-\\udeff]|'\n",
    "        u'[\\u2600-\\u26FF\\u2700-\\u27BF])+', \n",
    "        re.UNICODE)\n",
    "# Functions to check whether there's an emoji in the text, return 1 if true, 0 if false\n",
    "def is_emoji(text):\n",
    "    if highpoints.search(text):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def splitTextEmoji(df):\n",
    "    tok = happyfuntokenizing.TweetTokenizer(preserve_case=False)\n",
    "    def emojiExtract(sent):\n",
    "        return [word for word in tok.tokenize(sent) if is_emoji(word) == 1]\n",
    "\n",
    "    def textExtract(sent):\n",
    "        return ''.join([word for word in sent if is_emoji(word) == 0])\n",
    "\n",
    "    def addEmoji(df):\n",
    "        df['only_emoji'] = [emojiExtract(word) for word in df.text]\n",
    "\n",
    "    def addText(df):\n",
    "        df['only_text'] = [textExtract(word) for word in df.text]\n",
    "    \n",
    "    addText(df)\n",
    "    addEmoji(df)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Functions to clean non-english columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "punctuation = string.punctuation\n",
    "ex = ['‚Äú', '‚Äî', '‚Äô', ' Ô∏è', 'Ô∏è', '...', '‚Äù', '‚Ä¶', ' Óêí, Óêí, Óêí,', '?ÓêÇ', ' ÓêÖ', ' ‚É£', '‚àû', 'üÜí']\n",
    "for pun in [word for word in ex if word not in punctuation]:\n",
    "    punctuation += pun\n",
    "def isEnglish(list):\n",
    "    try:\n",
    "        [word.encode('ascii') for word in list if word not in punctuation]\n",
    "    except Exception:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "def cleanNonEnglish(df):\n",
    "    \"\"\" \n",
    "    \n",
    "    Needs to be applied after emoji splitting as emojis are considered non-english\n",
    "    \"\"\"\n",
    "    text_list = df['only_text'].values\n",
    "    english_Boolean = [isEnglish(sent) for sent in text_list]\n",
    "    print(\"{} number of tweets are not English\".format(len(english_Boolean) - sum(english_Boolean)))\n",
    "    return df[english_Boolean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save clean file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73386 handles replaced\n",
      "46844 urls replaced\n",
      ":o\\)       ->     üêµ replaced      2 times\n",
      ":-*\\)|\\(:  ->     üòÉ replaced   3139 times\n",
      ":-*[Oo]    ->     üòÆ replaced     71 times\n",
      ":-*\\*      ->     üíã replaced     62 times\n",
      ":'\\(       ->     üò¢ replaced     68 times\n",
      ":-*[PpbB]  ->     üòõ replaced    223 times\n",
      ";-*\\)      ->     üòâ replaced    707 times\n",
      ";-*[PpbB]  ->     üòú replaced     68 times\n",
      "</3        ->     üíî replaced      0 times\n",
      ":-*>       ->     üòÜ replaced      0 times\n",
      "=-*\\)      ->     üòÄ replaced     40 times\n",
      "8\\)        ->     üòé replaced     16 times\n",
      ":-*D       ->     üòÄ replaced    314 times\n",
      ":-*[/\\\\]   ->     üòï replaced    422 times\n",
      ":-*\\(|\\):  ->     üòû replaced   1163 times\n",
      "D:         ->     üòß replaced     37 times\n",
      "<3         ->     ‚ù§ replaced      0 times\n",
      ":-*\\|      ->     üòê replaced     15 times\n",
      ">:-*\\(     ->     üò† replaced      0 times\n",
      "ALL replaced 6347 times\n",
      "208809 retweets processed\n",
      "4870 number of tweets are not English\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     clean_tweets_df = loader('./data/tweets_training.json')\n",
    "    clean_tweets_df = loader('./data/tweets_test.json')\n",
    "    clean_tweets_df = clean(clean_tweets_df)\n",
    "#     clean_tweets_df.to_json('./data/tweets_training_clean.json', force_ascii=False)\n",
    "    clean_tweets_df.to_json('./data/tweets_test_clean.json', force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_total_text(df):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    total_text = df.text.apply(lambda x: tokenizer.tokenize(x))\n",
    "    \n",
    "    stop_words = nltk.corpus.stopwords.words('english') + [\"http\", 'hdl', 'url'] \n",
    "    punctuation_words = list(set(string.punctuation)) + [\":\", \":/\"]\n",
    "\n",
    "    total_text = list(total_text)\n",
    "    total_text = [word for _list in total_text for word in _list if word not in stop_words and word not in punctuation_words]\n",
    "    \n",
    "    return total_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_text = tokenize_total_text(clean_tweets_df)\n",
    "wordcost = dict((k, log((i+1)*log(len(total_text)))) for i,k in enumerate(total_text))\n",
    "maxword = max(len(x) for x in total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_hashtag(df):\n",
    "    def addHashTag(df):\n",
    "        df['only_HashTag'] = [re.findall(r\"(#\\w+)\", word) for word in df.text]\n",
    "\n",
    "    def is_hashtag(text):\n",
    "        if re.search(r\"(#\\w+)\", text):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def textEmojiExtract(sent):\n",
    "        tok = happyfuntokenizing.TweetTokenizer(preserve_case=False)\n",
    "        return ' '.join([word for word in tok.tokenize(sent) if is_hashtag(word) == 0])\n",
    "\n",
    "    def textHashtagSplit(sent):\n",
    "        tok = happyfuntokenizing.TweetTokenizer(preserve_case=True)\n",
    "        return ' '.join([word if is_hashtag(word) == 0 else apply_hashtag_text(word) for word in tok.tokenize(sent)])\n",
    "\n",
    "    def noHashtagText(df):\n",
    "        df['only_text_splithashtag'] = [textHashtagSplit(word) for word in df.only_text]\n",
    "    #     df['text_splithashtag'] = [textHashtagSplit(word) for word in df.text]\n",
    "        return\n",
    "\n",
    "    def infer_spaces(s):\n",
    "        \"\"\"Uses dynamic programming to infer the location of spaces in a string\n",
    "        without spaces.\"\"\"\n",
    "\n",
    "        # Build a cost dictionary, assuming Zipf's law and cost = -math.log(probability).\n",
    "\n",
    "        # Find the best match for the i first characters, assuming cost has\n",
    "        # been built for the i-1 first characters.\n",
    "        # Returns a pair (match_cost, match_length).\n",
    "        def best_match(i):\n",
    "            candidates = enumerate(reversed(cost[max(0, i-maxword):i]))\n",
    "            return min((c + wordcost.get(s[i-k-1:i], 9e999), k+1) for k,c in candidates)\n",
    "\n",
    "        # Build the cost array.\n",
    "        cost = [0]\n",
    "        for i in range(1,len(s)+1):\n",
    "            c,k = best_match(i)\n",
    "            cost.append(c)\n",
    "\n",
    "        # Backtrack to recover the minimal-cost string.\n",
    "        out = []\n",
    "        i = len(s)\n",
    "        while i>0:\n",
    "            c,k = best_match(i)\n",
    "            assert c == cost[i]\n",
    "            out.append(s[i-k:i])\n",
    "            i -= k\n",
    "\n",
    "        return list(reversed(out))\n",
    "\n",
    "    def apply_hashtag_split(_hashtag):\n",
    "        # for each hashtag in list of hashtags, split on # and take second item\n",
    "        item = [item.split('#')[1] for item in _hashtag if len(item) > 0]\n",
    "\n",
    "        # regex pattern\n",
    "        # (1) split on two caps or more, and only keep caps\n",
    "        # (2) split on exactly one cap or more, and keep trailing letters\n",
    "        pattern = r'([A-Z]{2,})|([A-Z]{1}[a-z]*)'\n",
    "\n",
    "        # loop through each item in list of hashtags\n",
    "        final_hashtags = []\n",
    "        for word in item:\n",
    "\n",
    "            # if len of word is 0, then there is no hashtag\n",
    "            if len(word) == 0:\n",
    "                final_hashtags.append(\"empty_hashtag\")\n",
    "\n",
    "            # use (1)) regex: funciton lowercase, as \"Treatlowercase\" can be treated as lowercase\n",
    "            elif word[0].isupper() and word[1:].islower():\n",
    "                final_hashtags.append(infer_spaces(word.lower()))\n",
    "\n",
    "            # use (1) regex: funciton lowercase\n",
    "            elif word.islower():\n",
    "                final_hashtags.append(infer_spaces(word))\n",
    "\n",
    "            # use (2) regex: customized uppercase\n",
    "            else:\n",
    "                final_hashtags.append(list(filter(None, re.split(pattern, word))))\n",
    "        return final_hashtags\n",
    "\n",
    "    def apply_hashtag_text(_hashtag):\n",
    "        word = _hashtag.split('#')[1] \n",
    "\n",
    "        # regex pattern\n",
    "        # (1) split on two caps or more, and only keep caps\n",
    "        # (2) split on exactly one cap or more, and keep trailing letters\n",
    "        pattern = r'([A-Z]{2,})|([A-Z]{1}[a-z]*)'\n",
    "\n",
    "        # if len of word is 0, then there is no hashtag\n",
    "        if len(word) == 0:\n",
    "            final_hashtags = \"\"\n",
    "\n",
    "        # use (1)) regex: funciton lowercase, as \"Treatlowercase\" can be treated as lowercase\n",
    "        elif word[0].isupper() and word[1:].islower():\n",
    "            final_hashtags =  infer_spaces(word.lower())\n",
    "\n",
    "        # use (1) regex: funciton lowercase\n",
    "        elif word.islower():\n",
    "            final_hashtags = infer_spaces(word)\n",
    "\n",
    "        # use (2) regex: customized uppercase\n",
    "        else:\n",
    "            final_hashtags = list(filter(None, re.split(pattern, word)))\n",
    "\n",
    "        joined_hashtags = ' '.join(final_hashtags)\n",
    "        return joined_hashtags\n",
    "    \n",
    "    addHashTag(df)\n",
    "    noHashtagText(df)\n",
    "    df[\"split_hashtag\"] = df.only_HashTag.apply(apply_hashtag_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_hashtag(clean_tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>retweet</th>\n",
       "      <th>only_emoji</th>\n",
       "      <th>only_HashTag</th>\n",
       "      <th>only_text_splithashtag</th>\n",
       "      <th>split_hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>378990150476255232</td>\n",
       "      <td>In one night my mom made the same that I made working one month.</td>\n",
       "      <td>72715638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>In one night my mom made the same that I made working one month .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>378990160550973440</td>\n",
       "      <td>Phone calls like that make me miss my family</td>\n",
       "      <td>543719852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Phone calls like that make me miss my family</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>378990162014789633</td>\n",
       "      <td>hdl  I know, it was visiting your country and found the directions to be terrible.</td>\n",
       "      <td>4200301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl I know , it was visiting your country and found the directions to be terrible .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>378990171972042752</td>\n",
       "      <td>hdl  Great job of the  hdl   team in LA! Resetting the spaces at  hdl  with     Ricitos de Oro and Chamomile Shampoo</td>\n",
       "      <td>386657055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl Great job of the hdl team in LA ! Resetting the spaces at hdl with Ricitos de Oro and Chamomile Shampoo</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>378990172483776513</td>\n",
       "      <td>hdl  yeah el Friday Lo boy a ir a vacunar</td>\n",
       "      <td>115814903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl yeah el Friday Lo boy a ir a vacunar</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>378043263279575041</td>\n",
       "      <td></td>\n",
       "      <td>517179440</td>\n",
       "      <td>‚Äú hdl : When girls where a sports bra, volley ball shorts, and socks &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;üò©üò©üòçüòçüòçüíôüíôüíô‚Äù</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>378990192897433600</td>\n",
       "      <td>Currently running on two hours of sleep. Awesome.</td>\n",
       "      <td>326540955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Currently running on two hours of sleep . Awesome .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>378990202947002369</td>\n",
       "      <td>This was a bad idea can we leave mofos</td>\n",
       "      <td>101671186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>This was a bad idea can we leave mofos</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>378990205811695616</td>\n",
       "      <td>This shit is shitty</td>\n",
       "      <td>101671186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>This shit is shitty</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>378990206214348800</td>\n",
       "      <td>It's so hot</td>\n",
       "      <td>101671186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>It's so hot</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>378043269281615872</td>\n",
       "      <td>hdl  haha I had no idea he was your bf</td>\n",
       "      <td>837118142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl haha I had no idea he was your bf</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>378990278700318722</td>\n",
       "      <td>hdl  thanks for the follow Ash, Go Broncos!!</td>\n",
       "      <td>801656173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl thanks for the follow Ash , Go Broncos ! !</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>378990383000084481</td>\n",
       "      <td>hdl  sweet!!!!!!\\n hdl   hdl</td>\n",
       "      <td>163609630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl sweet ! ! ! ! ! ! hdl hdl</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>378990385562796033</td>\n",
       "      <td>Can Gage's phone please get there today . Like c'mon now ! üò°üòï</td>\n",
       "      <td>373634620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üò°, üòï]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Can Gage's phone please get there today . Like c'mon now !</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>378990387471192064</td>\n",
       "      <td>Every time I hangout with people my mom doesn't like I tell her  hdl  is goingüòÇ</td>\n",
       "      <td>179567298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üòÇ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Every time I hangout with people my mom doesn't like I tell her hdl is going</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>378990391246467072</td>\n",
       "      <td>hdl  lol!</td>\n",
       "      <td>474593081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl lol !</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>378990426650181632</td>\n",
       "      <td>that frightening moment when a cop puts on his lights while he's behind you but the goes around you üòìüò≠</td>\n",
       "      <td>20009351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üòì, üò≠]</td>\n",
       "      <td>[]</td>\n",
       "      <td>that frightening moment when a cop puts on his lights while he's behind you but the goes around you</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>378990438855606272</td>\n",
       "      <td>Wtf OMG lmaoooo this girl must be trippenüòÇ  url</td>\n",
       "      <td>1061897816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üòÇ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Wtf OMG lmaoooo this girl must be trippen url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>378990533466927105</td>\n",
       "      <td>Drinking a Pale Ale by  hdl  at  hdl  ‚Äî  url</td>\n",
       "      <td>15005199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Drinking a Pale Ale by hdl at hdl ‚Äî url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>378990622541357056</td>\n",
       "      <td>giorgialuisa totally stealing it #stolenteesunniesdress #acnebeanie #sneakskinpurse #stolencashmere‚Ä¶  url</td>\n",
       "      <td>12646362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#stolenteesunniesdress, #acnebeanie, #sneakskinpurse, #stolencashmere]</td>\n",
       "      <td>giorgialuisa totally stealing it stolen tee sunnies dress acne beanie sneaks kin purse stolen cashmere ‚Ä¶ url</td>\n",
       "      <td>[[stolen, tee, sunnies, dress], [acne, beanie], [sneaks, kin, purse], [stolen, cashmere]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>378990678526926848</td>\n",
       "      <td>I'm at Kendall-Jackson Wine Estate &amp;amp; Gardens -  hdl  w/  hdl   url</td>\n",
       "      <td>302268453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I'm at Kendall-Jackson Wine Estate &amp; amp ; Gardens - hdl w / hdl url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>378990683991715840</td>\n",
       "      <td>Shut down</td>\n",
       "      <td>54104016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Shut down</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>378990695995805697</td>\n",
       "      <td>So erker cuz i just got my nails done this morning and they arreafy fcked</td>\n",
       "      <td>1010824356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>So erker cuz i just got my nails done this morning and they arreafy fcked</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>378990734160199680</td>\n",
       "      <td>I'm at San Francisco International Airport (SFO) (San Francisco, CA) w/ 162 others  url</td>\n",
       "      <td>24092096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I'm at San Francisco International Airport ( SFO ) ( San Francisco , CA ) w / 162 others url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>378990780460695552</td>\n",
       "      <td>Running 2's even when we're at work. Ha.üòè  url</td>\n",
       "      <td>320358441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üòè]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Running 2 ' s even when we're at work . Ha . url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>378990785674235904</td>\n",
       "      <td>Saturday afternoon drive through Napa Valley.  url</td>\n",
       "      <td>1784701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Saturday afternoon drive through Napa Valley . url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>378990798533976064</td>\n",
       "      <td>hdl  bbbbbrrrrruuuuuuuuuhhhhhhhhhhhh</td>\n",
       "      <td>54104016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl bbbbbrrrrruuuuuuuuuhhhhhhhhhhhh</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>378990834873425920</td>\n",
       "      <td>Another TD before the half  hdl</td>\n",
       "      <td>59842816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Another TD before the half hdl</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>378990835007627264</td>\n",
       "      <td>My last tweet  hdl   hdl  thumbin through the check lol</td>\n",
       "      <td>476959691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>My last tweet hdl hdl thumbin through the check lol</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>378043311103021057</td>\n",
       "      <td>I have no clue hats happening</td>\n",
       "      <td>572397098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I have no clue hats happening</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>378990865512796160</td>\n",
       "      <td>Football &amp;amp; Buffalo Wild Wings üôå</td>\n",
       "      <td>268035651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üôå]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Football &amp; amp ; Buffalo Wild Wings</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>378990894134734849</td>\n",
       "      <td>I'm predicting that Marcus Mariota wins the Heisman this year #GoDucks #WTD</td>\n",
       "      <td>628617511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#GoDucks, #WTD]</td>\n",
       "      <td>I'm predicting that Marcus Mariota wins the Heisman this year Go Ducks WTD</td>\n",
       "      <td>[[Go, Ducks], [WTD]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>378990905660669953</td>\n",
       "      <td>A&amp;amp;M has arrived. Purdue fan at the bar yelling Roll Tide. Called him a loser. He agreed. Haha.</td>\n",
       "      <td>69206373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>A &amp; amp ; M has arrived . Purdue fan at the bar yelling Roll Tide . Called him a loser . He agreed . Haha .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>378990924602564608</td>\n",
       "      <td>Just posted a video @ Amoeba Music  url</td>\n",
       "      <td>459666268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Just posted a video @ Amoeba Music url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>378990925294608384</td>\n",
       "      <td>Freddie Gibbs posing with the wife and I #rockthebells @ Shoreline Amphitheatre  url</td>\n",
       "      <td>51846644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#rockthebells]</td>\n",
       "      <td>Freddie Gibbs posing with the wife and I roc kt heb ells @ Shoreline Amphitheatre url</td>\n",
       "      <td>[[roc, kt, heb, ells]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>378990968575234049</td>\n",
       "      <td>My cousin hooked it up with this hotel. Nice lounge and everything. üò¨</td>\n",
       "      <td>239530007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üò¨]</td>\n",
       "      <td>[]</td>\n",
       "      <td>My cousin hooked it up with this hotel . Nice lounge and everything .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>378990987348959232</td>\n",
       "      <td>Not feeling to well .</td>\n",
       "      <td>149210072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Not feeling to well .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>378990995578171393</td>\n",
       "      <td>url</td>\n",
       "      <td>25580805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>378991012951363584</td>\n",
       "      <td>#chickenkatsuburrito @ HRD Coffee Shop  url</td>\n",
       "      <td>230773036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#chickenkatsuburrito]</td>\n",
       "      <td>chicken katsu burrito @ HRD Coffee Shop url</td>\n",
       "      <td>[[chicken, katsu, burrito]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>378991014154752001</td>\n",
       "      <td>I hope he knows what he's doing.</td>\n",
       "      <td>31393054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I hope he knows what he's doing .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  \\\n",
       "10  378990150476255232   \n",
       "11  378990160550973440   \n",
       "12  378990162014789633   \n",
       "13  378990171972042752   \n",
       "14  378990172483776513   \n",
       "15  378043263279575041   \n",
       "16  378990192897433600   \n",
       "17  378990202947002369   \n",
       "18  378990205811695616   \n",
       "19  378990206214348800   \n",
       "20  378043269281615872   \n",
       "21  378990278700318722   \n",
       "22  378990383000084481   \n",
       "23  378990385562796033   \n",
       "24  378990387471192064   \n",
       "25  378990391246467072   \n",
       "26  378990426650181632   \n",
       "27  378990438855606272   \n",
       "28  378990533466927105   \n",
       "29  378990622541357056   \n",
       "30  378990678526926848   \n",
       "31  378990683991715840   \n",
       "32  378990695995805697   \n",
       "33  378990734160199680   \n",
       "34  378990780460695552   \n",
       "35  378990785674235904   \n",
       "36  378990798533976064   \n",
       "37  378990834873425920   \n",
       "38  378990835007627264   \n",
       "39  378043311103021057   \n",
       "40  378990865512796160   \n",
       "41  378990894134734849   \n",
       "42  378990905660669953   \n",
       "43  378990924602564608   \n",
       "44  378990925294608384   \n",
       "45  378990968575234049   \n",
       "46  378990987348959232   \n",
       "47  378990995578171393   \n",
       "48  378991012951363584   \n",
       "49  378991014154752001   \n",
       "\n",
       "                                                                                                                     text  \\\n",
       "10                                                       In one night my mom made the same that I made working one month.   \n",
       "11                                                                           Phone calls like that make me miss my family   \n",
       "12                                     hdl  I know, it was visiting your country and found the directions to be terrible.   \n",
       "13   hdl  Great job of the  hdl   team in LA! Resetting the spaces at  hdl  with     Ricitos de Oro and Chamomile Shampoo   \n",
       "14                                                                              hdl  yeah el Friday Lo boy a ir a vacunar   \n",
       "15                                                                                                                          \n",
       "16                                                                      Currently running on two hours of sleep. Awesome.   \n",
       "17                                                                                 This was a bad idea can we leave mofos   \n",
       "18                                                                                                    This shit is shitty   \n",
       "19                                                                                                            It's so hot   \n",
       "20                                                                                 hdl  haha I had no idea he was your bf   \n",
       "21                                                                           hdl  thanks for the follow Ash, Go Broncos!!   \n",
       "22                                                                                          hdl  sweet!!!!!!\\n hdl   hdl    \n",
       "23                                                          Can Gage's phone please get there today . Like c'mon now ! üò°üòï   \n",
       "24                                        Every time I hangout with people my mom doesn't like I tell her  hdl  is goingüòÇ   \n",
       "25                                                                                                              hdl  lol!   \n",
       "26                 that frightening moment when a cop puts on his lights while he's behind you but the goes around you üòìüò≠   \n",
       "27                                                                       Wtf OMG lmaoooo this girl must be trippenüòÇ  url    \n",
       "28                                                                          Drinking a Pale Ale by  hdl  at  hdl  ‚Äî  url    \n",
       "29             giorgialuisa totally stealing it #stolenteesunniesdress #acnebeanie #sneakskinpurse #stolencashmere‚Ä¶  url    \n",
       "30                                                I'm at Kendall-Jackson Wine Estate &amp; Gardens -  hdl  w/  hdl   url    \n",
       "31                                                                                                              Shut down   \n",
       "32                                              So erker cuz i just got my nails done this morning and they arreafy fcked   \n",
       "33                               I'm at San Francisco International Airport (SFO) (San Francisco, CA) w/ 162 others  url    \n",
       "34                                                                        Running 2's even when we're at work. Ha.üòè  url    \n",
       "35                                                                    Saturday afternoon drive through Napa Valley.  url    \n",
       "36                                                                                   hdl  bbbbbrrrrruuuuuuuuuhhhhhhhhhhhh   \n",
       "37                                                                                       Another TD before the half  hdl    \n",
       "38                                                                My last tweet  hdl   hdl  thumbin through the check lol   \n",
       "39                                                                                          I have no clue hats happening   \n",
       "40                                                                                    Football &amp; Buffalo Wild Wings üôå   \n",
       "41                                            I'm predicting that Marcus Mariota wins the Heisman this year #GoDucks #WTD   \n",
       "42                     A&amp;M has arrived. Purdue fan at the bar yelling Roll Tide. Called him a loser. He agreed. Haha.   \n",
       "43                                                                               Just posted a video @ Amoeba Music  url    \n",
       "44                                  Freddie Gibbs posing with the wife and I #rockthebells @ Shoreline Amphitheatre  url    \n",
       "45                                                  My cousin hooked it up with this hotel. Nice lounge and everything. üò¨   \n",
       "46                                                                                                  Not feeling to well .   \n",
       "47                                                                                                                   url    \n",
       "48                                                                           #chickenkatsuburrito @ HRD Coffee Shop  url    \n",
       "49                                                                                       I hope he knows what he's doing.   \n",
       "\n",
       "       user_id  \\\n",
       "10    72715638   \n",
       "11   543719852   \n",
       "12     4200301   \n",
       "13   386657055   \n",
       "14   115814903   \n",
       "15   517179440   \n",
       "16   326540955   \n",
       "17   101671186   \n",
       "18   101671186   \n",
       "19   101671186   \n",
       "20   837118142   \n",
       "21   801656173   \n",
       "22   163609630   \n",
       "23   373634620   \n",
       "24   179567298   \n",
       "25   474593081   \n",
       "26    20009351   \n",
       "27  1061897816   \n",
       "28    15005199   \n",
       "29    12646362   \n",
       "30   302268453   \n",
       "31    54104016   \n",
       "32  1010824356   \n",
       "33    24092096   \n",
       "34   320358441   \n",
       "35     1784701   \n",
       "36    54104016   \n",
       "37    59842816   \n",
       "38   476959691   \n",
       "39   572397098   \n",
       "40   268035651   \n",
       "41   628617511   \n",
       "42    69206373   \n",
       "43   459666268   \n",
       "44    51846644   \n",
       "45   239530007   \n",
       "46   149210072   \n",
       "47    25580805   \n",
       "48   230773036   \n",
       "49    31393054   \n",
       "\n",
       "                                                                                                       retweet  \\\n",
       "10                                                                                                         NaN   \n",
       "11                                                                                                         NaN   \n",
       "12                                                                                                         NaN   \n",
       "13                                                                                                         NaN   \n",
       "14                                                                                                         NaN   \n",
       "15  ‚Äú hdl : When girls where a sports bra, volley ball shorts, and socks &gt;&gt;&gt;&gt;&gt;&gt;&gt;üò©üò©üòçüòçüòçüíôüíôüíô‚Äù   \n",
       "16                                                                                                         NaN   \n",
       "17                                                                                                         NaN   \n",
       "18                                                                                                         NaN   \n",
       "19                                                                                                         NaN   \n",
       "20                                                                                                         NaN   \n",
       "21                                                                                                         NaN   \n",
       "22                                                                                                         NaN   \n",
       "23                                                                                                         NaN   \n",
       "24                                                                                                         NaN   \n",
       "25                                                                                                         NaN   \n",
       "26                                                                                                         NaN   \n",
       "27                                                                                                         NaN   \n",
       "28                                                                                                         NaN   \n",
       "29                                                                                                         NaN   \n",
       "30                                                                                                         NaN   \n",
       "31                                                                                                         NaN   \n",
       "32                                                                                                         NaN   \n",
       "33                                                                                                         NaN   \n",
       "34                                                                                                         NaN   \n",
       "35                                                                                                         NaN   \n",
       "36                                                                                                         NaN   \n",
       "37                                                                                                         NaN   \n",
       "38                                                                                                         NaN   \n",
       "39                                                                                                         NaN   \n",
       "40                                                                                                         NaN   \n",
       "41                                                                                                         NaN   \n",
       "42                                                                                                         NaN   \n",
       "43                                                                                                         NaN   \n",
       "44                                                                                                         NaN   \n",
       "45                                                                                                         NaN   \n",
       "46                                                                                                         NaN   \n",
       "47                                                                                                         NaN   \n",
       "48                                                                                                         NaN   \n",
       "49                                                                                                         NaN   \n",
       "\n",
       "   only_emoji  \\\n",
       "10         []   \n",
       "11         []   \n",
       "12         []   \n",
       "13         []   \n",
       "14         []   \n",
       "15         []   \n",
       "16         []   \n",
       "17         []   \n",
       "18         []   \n",
       "19         []   \n",
       "20         []   \n",
       "21         []   \n",
       "22         []   \n",
       "23     [üò°, üòï]   \n",
       "24        [üòÇ]   \n",
       "25         []   \n",
       "26     [üòì, üò≠]   \n",
       "27        [üòÇ]   \n",
       "28         []   \n",
       "29         []   \n",
       "30         []   \n",
       "31         []   \n",
       "32         []   \n",
       "33         []   \n",
       "34        [üòè]   \n",
       "35         []   \n",
       "36         []   \n",
       "37         []   \n",
       "38         []   \n",
       "39         []   \n",
       "40        [üôå]   \n",
       "41         []   \n",
       "42         []   \n",
       "43         []   \n",
       "44         []   \n",
       "45        [üò¨]   \n",
       "46         []   \n",
       "47         []   \n",
       "48         []   \n",
       "49         []   \n",
       "\n",
       "                                                               only_HashTag  \\\n",
       "10                                                                       []   \n",
       "11                                                                       []   \n",
       "12                                                                       []   \n",
       "13                                                                       []   \n",
       "14                                                                       []   \n",
       "15                                                                       []   \n",
       "16                                                                       []   \n",
       "17                                                                       []   \n",
       "18                                                                       []   \n",
       "19                                                                       []   \n",
       "20                                                                       []   \n",
       "21                                                                       []   \n",
       "22                                                                       []   \n",
       "23                                                                       []   \n",
       "24                                                                       []   \n",
       "25                                                                       []   \n",
       "26                                                                       []   \n",
       "27                                                                       []   \n",
       "28                                                                       []   \n",
       "29  [#stolenteesunniesdress, #acnebeanie, #sneakskinpurse, #stolencashmere]   \n",
       "30                                                                       []   \n",
       "31                                                                       []   \n",
       "32                                                                       []   \n",
       "33                                                                       []   \n",
       "34                                                                       []   \n",
       "35                                                                       []   \n",
       "36                                                                       []   \n",
       "37                                                                       []   \n",
       "38                                                                       []   \n",
       "39                                                                       []   \n",
       "40                                                                       []   \n",
       "41                                                         [#GoDucks, #WTD]   \n",
       "42                                                                       []   \n",
       "43                                                                       []   \n",
       "44                                                          [#rockthebells]   \n",
       "45                                                                       []   \n",
       "46                                                                       []   \n",
       "47                                                                       []   \n",
       "48                                                   [#chickenkatsuburrito]   \n",
       "49                                                                       []   \n",
       "\n",
       "                                                                                          only_text_splithashtag  \\\n",
       "10                                             In one night my mom made the same that I made working one month .   \n",
       "11                                                                  Phone calls like that make me miss my family   \n",
       "12                           hdl I know , it was visiting your country and found the directions to be terrible .   \n",
       "13   hdl Great job of the hdl team in LA ! Resetting the spaces at hdl with Ricitos de Oro and Chamomile Shampoo   \n",
       "14                                                                      hdl yeah el Friday Lo boy a ir a vacunar   \n",
       "15                                                                                                                 \n",
       "16                                                           Currently running on two hours of sleep . Awesome .   \n",
       "17                                                                        This was a bad idea can we leave mofos   \n",
       "18                                                                                           This shit is shitty   \n",
       "19                                                                                                   It's so hot   \n",
       "20                                                                         hdl haha I had no idea he was your bf   \n",
       "21                                                                hdl thanks for the follow Ash , Go Broncos ! !   \n",
       "22                                                                                 hdl sweet ! ! ! ! ! ! hdl hdl   \n",
       "23                                                    Can Gage's phone please get there today . Like c'mon now !   \n",
       "24                                  Every time I hangout with people my mom doesn't like I tell her hdl is going   \n",
       "25                                                                                                     hdl lol !   \n",
       "26           that frightening moment when a cop puts on his lights while he's behind you but the goes around you   \n",
       "27                                                                 Wtf OMG lmaoooo this girl must be trippen url   \n",
       "28                                                                       Drinking a Pale Ale by hdl at hdl ‚Äî url   \n",
       "29  giorgialuisa totally stealing it stolen tee sunnies dress acne beanie sneaks kin purse stolen cashmere ‚Ä¶ url   \n",
       "30                                          I'm at Kendall-Jackson Wine Estate & amp ; Gardens - hdl w / hdl url   \n",
       "31                                                                                                     Shut down   \n",
       "32                                     So erker cuz i just got my nails done this morning and they arreafy fcked   \n",
       "33                  I'm at San Francisco International Airport ( SFO ) ( San Francisco , CA ) w / 162 others url   \n",
       "34                                                              Running 2 ' s even when we're at work . Ha . url   \n",
       "35                                                            Saturday afternoon drive through Napa Valley . url   \n",
       "36                                                                           hdl bbbbbrrrrruuuuuuuuuhhhhhhhhhhhh   \n",
       "37                                                                                Another TD before the half hdl   \n",
       "38                                                           My last tweet hdl hdl thumbin through the check lol   \n",
       "39                                                                                 I have no clue hats happening   \n",
       "40                                                                           Football & amp ; Buffalo Wild Wings   \n",
       "41                                    I'm predicting that Marcus Mariota wins the Heisman this year Go Ducks WTD   \n",
       "42   A & amp ; M has arrived . Purdue fan at the bar yelling Roll Tide . Called him a loser . He agreed . Haha .   \n",
       "43                                                                        Just posted a video @ Amoeba Music url   \n",
       "44                         Freddie Gibbs posing with the wife and I roc kt heb ells @ Shoreline Amphitheatre url   \n",
       "45                                         My cousin hooked it up with this hotel . Nice lounge and everything .   \n",
       "46                                                                                         Not feeling to well .   \n",
       "47                                                                                                           url   \n",
       "48                                                                   chicken katsu burrito @ HRD Coffee Shop url   \n",
       "49                                                                             I hope he knows what he's doing .   \n",
       "\n",
       "                                                                                split_hashtag  \n",
       "10                                                                                         []  \n",
       "11                                                                                         []  \n",
       "12                                                                                         []  \n",
       "13                                                                                         []  \n",
       "14                                                                                         []  \n",
       "15                                                                                         []  \n",
       "16                                                                                         []  \n",
       "17                                                                                         []  \n",
       "18                                                                                         []  \n",
       "19                                                                                         []  \n",
       "20                                                                                         []  \n",
       "21                                                                                         []  \n",
       "22                                                                                         []  \n",
       "23                                                                                         []  \n",
       "24                                                                                         []  \n",
       "25                                                                                         []  \n",
       "26                                                                                         []  \n",
       "27                                                                                         []  \n",
       "28                                                                                         []  \n",
       "29  [[stolen, tee, sunnies, dress], [acne, beanie], [sneaks, kin, purse], [stolen, cashmere]]  \n",
       "30                                                                                         []  \n",
       "31                                                                                         []  \n",
       "32                                                                                         []  \n",
       "33                                                                                         []  \n",
       "34                                                                                         []  \n",
       "35                                                                                         []  \n",
       "36                                                                                         []  \n",
       "37                                                                                         []  \n",
       "38                                                                                         []  \n",
       "39                                                                                         []  \n",
       "40                                                                                         []  \n",
       "41                                                                       [[Go, Ducks], [WTD]]  \n",
       "42                                                                                         []  \n",
       "43                                                                                         []  \n",
       "44                                                                     [[roc, kt, heb, ells]]  \n",
       "45                                                                                         []  \n",
       "46                                                                                         []  \n",
       "47                                                                                         []  \n",
       "48                                                                [[chicken, katsu, burrito]]  \n",
       "49                                                                                         []  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets_df = clean_tweets_df.drop(['lat','lng','only_text','timeStamp'], axis=1)\n",
    "clean_tweets_df[10:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_tweets_df.to_json('./data/tweets_test_clean.json', force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
