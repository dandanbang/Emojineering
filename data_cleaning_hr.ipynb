{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning steps:\n",
    "- replace @ handles with: hdl (chose a word with no punctuation so no extra step is needed to process, hdl = handle)\n",
    "- replace urls by: url\n",
    "- replace emoticons with corresponding emojis\n",
    "- split retweets in tweet and retweet\n",
    "\n",
    "For all of these, first check what is the prevalence and if it is worth the effort. \n",
    "\n",
    "Ideas:\n",
    "- split hashtags into words -> Carlo tackling that\n",
    "- Tweets not in english -> Daniel tackling that\n",
    "- replace contractions & spellchecking\n",
    "    - Character ngram will probably be more efficient due to the really low quality of speach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 140\n",
    "import nltk\n",
    "import re\n",
    "from IPython.display import display\n",
    "import happyfuntokenizing\n",
    "from happyfuntokenizing import TweetTokenizer\n",
    "\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder cannot be called in this file before the all subfunctions are defined\n",
    "def clean(df):\n",
    "    \"\"\"Data cleaning steps:\n",
    "    - replace @ handles with: hdl (chose a word with no punctuation so no extra step is needed to process, hdl = handle)\n",
    "    - replace urls by: url\n",
    "    - replace emoticons with corresponding emojis\n",
    "    - split retweets in tweet and retweet\n",
    "    \n",
    "    To be added:\n",
    "    - remove non english tweets, done on the text only (not retweet). Needs to be applied after emoji split. \n",
    "    - hashtags splits\n",
    "    \n",
    "    Returns None (data cleaning in place)\n",
    "    \"\"\"\n",
    "    cleanHandle(df)\n",
    "    cleanURL(df)\n",
    "    convertEmoticon(df)\n",
    "    cleanRetweets(df)\n",
    "    splitTextEmoji(df)\n",
    "    df = cleanNonEnglish(df)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loader(filename):\n",
    "    \"\"\" Load tweets from filename. Resets the index. Returns the loaded data frame\"\"\"\n",
    "    with open(filename,'r') as f:\n",
    "        df = pd.DataFrame(json.load(f))\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace @ handles with hdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanHandle(df):\n",
    "    \"\"\" Replace in-place handles with hdl keyword\n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    pattern = r\"@[a-zA-Z0-9_]{1,15}\" #from http://kagan.mactane.org/blog/2009/09/22/what-characters-are-allowed-in-twitter-usernames/\n",
    "    print(\"{} handles replaced\".format(np.sum(df.text.str.contains(pattern).values)))\n",
    "    df.text = df.text.str.replace(pattern, \" hdl \")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No \"hdl\" words for confusion in the txt. Good replacement name. \n",
    "\n",
    "Best to replace handles with \"\\ hdl\\ \", so for tokenization it will be easier to identify as a word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace URLs with url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanURL(df):\n",
    "    \"\"\" Replace in-place URLs with url keyword\n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    pattern = r'(?:http://|https://|www.)[^‚Äú‚Äù\"\\' ]+' # From http://stackoverflow.com/questions/7679970/python-regular-expression-nltk-website-extraction\n",
    "    print(\"{} urls replaced\".format(np.sum(df.text.str.contains(pattern).values)))\n",
    "    df.text = df.text.str.replace(pattern, \" url \")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URLs are quiet well formed and are generally at the end of tweets. No risk of engulfing in the cleaning some more text after the url.\n",
    "\n",
    "keyword url is used only 4 times in dataset, no risk of confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert emoticons to emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Based on:\n",
    "# https://slack.zendesk.com/hc/en-us/articles/202931348-Emoji-and-emoticons\n",
    "# http://unicodey.com/emoji-data/table.htm\n",
    "# http://www.unicode.org/emoji/charts/emoji-list.html\n",
    "\n",
    "def convertEmoticon(df):\n",
    "    \"\"\" Replace in-place common emoticons to emojis.\n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    emoticon2emoji = {\n",
    "        r\"<3\": \"\\u2764\",\n",
    "        r\"</3\": \"\\U0001F494\",\n",
    "        r\"8\\)\": \"\\U0001F60E\",\n",
    "        r\"D:\": \"\\U0001F627\",\n",
    "        r\":'\\(\": \"\\U0001F622\",\n",
    "        r\":o\\)\": \"\\U0001F435\",\n",
    "        r\":-*\\*\": \"\\U0001F48B\",\n",
    "        r\"=-*\\)\": \"\\U0001F600\",\n",
    "        r\":-*D\": \"\\U0001F600\",\n",
    "        r\";-*\\)\": \"\\U0001F609\",\n",
    "        r\":-*>\": \"\\U0001F606\",\n",
    "        r\":-*\\|\": \"\\U0001F610\",\n",
    "        r\":-*[Oo]\": \"\\U0001F62E\",\n",
    "        r\">:-*\\(\": \"\\U0001F620\",\n",
    "        r\":-*\\)|\\(:\": \"\\U0001F603\",\n",
    "        r\":-*\\(|\\):\": \"\\U0001F61E\",\n",
    "        r\":-*[/\\\\]\": \"\\U0001F615\",\n",
    "        r\":-*[PpbB]\": \"\\U0001F61B\",\n",
    "        r\";-*[PpbB]\": \"\\U0001F61C\"\n",
    "    }\n",
    "    \n",
    "    total = 0\n",
    "    for emoticon in emoticon2emoji:\n",
    "        nreplacements = np.sum(df.text.str.contains(emoticon).values)\n",
    "        total += nreplacements\n",
    "        print(\"{:10} -> {:>5} replaced {:6} times\".format(emoticon, emoticon2emoji[emoticon], nreplacements))\n",
    "        df.text = df.text.str.replace(emoticon, emoticon2emoji[emoticon])\n",
    "    print(\"{:3} replaced {} times\".format(\"ALL\", total))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split retweets into user content and retweeted content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cannot be called before functions within are defined \n",
    "def cleanRetweets(df):\n",
    "    \"\"\" Remove from the text column the retweet column and add to seperate column \"retweet\". \n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    nsplits = 0\n",
    "    nsplits += splitRetweets(df)\n",
    "    nsplits += splitQuotes(df) # Need to maintain that order\n",
    "    print(\"{} retweets processed\".format(nsplits))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitRetweets(df):\n",
    "    \"\"\" Extract retweets with the RT keyword\"\"\"\n",
    "    pattern = r\"\"\"(.*(?:\\W|^))(RT(?:\\ ?[\\\":‚Äú]|$).*) # Retweets with RT keyword\"\"\"\n",
    "    retweets = pd.DataFrame(df.text.str.extract(pattern, flags=re.X))\n",
    "    retweets.columns = [\"text\", \"retweet\"]\n",
    "    non_null_idxs = retweets.retweet.notnull()\n",
    "    df.loc[non_null_idxs,[\"text\"]] = retweets.text[non_null_idxs]\n",
    "    df[\"retweet\"] = retweets.retweet\n",
    "    return len(non_null_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def splitQuotes(df):\n",
    "    \"\"\" Extract retweets in quote format.\n",
    "    See http://support.gnip.com/articles/identifying-and-understanding-retweets.html\n",
    "    \"\"\"\n",
    "    pattern = r\"(.*?)((?:([\\\"\\'])|(?:(‚Äú))|‚Äò)\\s*hdl.*(?(3)\\3|(?(4)‚Äù|‚Äô)))(.*)\" #Pattern to match quote, possibly nested\n",
    "    retweets = pd.DataFrame(df.text.str.extract(pattern, flags=re.X)[[0,1,4]])\n",
    "    retweets.columns = [\"text_before\", \"retweet\", \"text_after\"]\n",
    "    non_null_idxs = retweets.retweet.notnull()\n",
    "    retweets[\"text\"] = retweets.loc[non_null_idxs, [\"text_before\", \"text_after\"]].apply(lambda x: \" \".join(x), axis=1)\n",
    "    df.loc[non_null_idxs,[\"text\"]] = retweets.text[non_null_idxs].copy()\n",
    "    df[\"retweet\"] = retweets.retweet.copy()\n",
    "    return len(retweets[non_null_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Text and Emoji and create two new columns for only text and only emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Wide UCS-4 build\n",
    "    highpoints = re.compile(u'['\n",
    "        u'\\U0001F300-\\U0001F64F'\n",
    "        u'\\U0001F680-\\U0001F6FF'\n",
    "        u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "        re.UNICODE)\n",
    "except re.error:\n",
    "    # Narrow UCS-2 build\n",
    "    highpoints = re.compile(u'('\n",
    "        u'\\ud83c[\\udf00-\\udfff]|'\n",
    "        u'\\ud83d[\\udc00-\\ude4f\\ude80-\\udeff]|'\n",
    "        u'[\\u2600-\\u26FF\\u2700-\\u27BF])+', \n",
    "        re.UNICODE)\n",
    "# Functions to check whether there's an emoji in the text, return 1 if true, 0 if false\n",
    "def is_emoji(text):\n",
    "    if highpoints.search(text):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def splitTextEmoji(df):\n",
    "    tok = happyfuntokenizing.TweetTokenizer(preserve_case=False)\n",
    "    def emojiExtract(sent):\n",
    "        return [word for word in tok.tokenize(sent) if is_emoji(word) == 1]\n",
    "\n",
    "    def textExtract(sent):\n",
    "        return ''.join([word for word in sent if is_emoji(word) == 0])\n",
    "\n",
    "    def addEmoji(df):\n",
    "        df['only_emoji'] = [emojiExtract(word) for word in df.text]\n",
    "\n",
    "    def addText(df):\n",
    "        df['only_text'] = [textExtract(word) for word in df.text]\n",
    "    \n",
    "    addText(df)\n",
    "    addEmoji(df)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Functions to clean non-english columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "punctuation = string.punctuation\n",
    "ex = ['‚Äú', '‚Äî', '‚Äô', ' Ô∏è', 'Ô∏è', '...', '‚Äù', '‚Ä¶', ' Óêí, Óêí, Óêí,', '?ÓêÇ', ' ÓêÖ', ' ‚É£', '‚àû', 'üÜí']\n",
    "for pun in [word for word in ex if word not in punctuation]:\n",
    "    punctuation += pun\n",
    "def isEnglish(list):\n",
    "    try:\n",
    "        [word.encode('ascii') for word in list if word not in punctuation]\n",
    "    except Exception:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "def cleanNonEnglish(df):\n",
    "    \"\"\" \n",
    "    \n",
    "    Needs to be applied after emoji splitting as emojis are considered non-english\n",
    "    \"\"\"\n",
    "    text_list = df['only_text'].values\n",
    "    english_Boolean = [isEnglish(sent) for sent in text_list]\n",
    "    print(\"{} number of tweets are not English\".format(len(english_Boolean) - sum(english_Boolean)))\n",
    "    return df[english_Boolean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save clean file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293672 handles replaced\n",
      "187643 urls replaced\n",
      ":-*\\(|\\):  ->     üòû replaced   4600 times\n",
      ":-*[/\\\\]   ->     üòï replaced   1572 times\n",
      ";-*[PpbB]  ->     üòú replaced    263 times\n",
      ":'\\(       ->     üò¢ replaced    264 times\n",
      ":-*\\|      ->     üòê replaced     70 times\n",
      ">:-*\\(     ->     üò† replaced      0 times\n",
      ":-*[Oo]    ->     üòÆ replaced    295 times\n",
      ":o\\)       ->     üêµ replaced      0 times\n",
      ":-*\\)|\\(:  ->     üòÉ replaced  12514 times\n",
      ";-*\\)      ->     üòâ replaced   2688 times\n",
      "<3         ->     ‚ù§ replaced      0 times\n",
      "8\\)        ->     üòé replaced     81 times\n",
      "</3        ->     üíî replaced      0 times\n",
      "=-*\\)      ->     üòÄ replaced    174 times\n",
      "D:         ->     üòß replaced    164 times\n",
      ":-*D       ->     üòÄ replaced   1218 times\n",
      ":-*\\*      ->     üíã replaced    238 times\n",
      ":-*>       ->     üòÜ replaced      0 times\n",
      ":-*[PpbB]  ->     üòõ replaced    960 times\n",
      "ALL replaced 25101 times\n",
      "834937 retweets processed\n",
      "19803 number of tweets are not English\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    clean_tweets_df = loader('./data/tweets_training.json')\n",
    "    clean_tweets_df = clean(clean_tweets_df)\n",
    "#     clean_tweets_df.to_json('./data/tweets_training_clean.json', force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_total_text():\n",
    "    tokenizer = TweetTokenizer()\n",
    "    total_text = clean_tweets_df.text.apply(lambda x: tokenizer.tokenize(x))\n",
    "    \n",
    "    stop_words = nltk.corpus.stopwords.words('english') + [\"http\", 'hdl', 'url'] \n",
    "    punctuation_words = list(set(string.punctuation)) + [\":\", \":/\"]\n",
    "\n",
    "    total_text = list(total_text)\n",
    "    total_text = [word for _list in total_text for word in _list if word not in stop_words and word not in punctuation_words]\n",
    "    \n",
    "    return total_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_text = tokenize_total_text()\n",
    "wordcost = dict((k, log((i+1)*log(len(total_text)))) for i,k in enumerate(total_text))\n",
    "maxword = max(len(x) for x in total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_hashtag(df):\n",
    "    def addHashTag(df):\n",
    "        df['only_HashTag'] = [re.findall(r\"(#\\w+)\", word) for word in df.text]\n",
    "\n",
    "    def is_hashtag(text):\n",
    "        if re.search(r\"(#\\w+)\", text):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def textEmojiExtract(sent):\n",
    "        tok = happyfuntokenizing.TweetTokenizer(preserve_case=False)\n",
    "        return ' '.join([word for word in tok.tokenize(sent) if is_hashtag(word) == 0])\n",
    "\n",
    "    def textHashtagSplit(sent):\n",
    "        tok = happyfuntokenizing.TweetTokenizer(preserve_case=True)\n",
    "        return ' '.join([word if is_hashtag(word) == 0 else apply_hashtag_text(word) for word in tok.tokenize(sent)])\n",
    "\n",
    "    def noHashtagText(df):\n",
    "        df['only_text_splithashtag'] = [textHashtagSplit(word) for word in df.only_text]\n",
    "    #     df['text_splithashtag'] = [textHashtagSplit(word) for word in df.text]\n",
    "        return\n",
    "\n",
    "    def infer_spaces(s):\n",
    "        \"\"\"Uses dynamic programming to infer the location of spaces in a string\n",
    "        without spaces.\"\"\"\n",
    "\n",
    "        # Build a cost dictionary, assuming Zipf's law and cost = -math.log(probability).\n",
    "\n",
    "        # Find the best match for the i first characters, assuming cost has\n",
    "        # been built for the i-1 first characters.\n",
    "        # Returns a pair (match_cost, match_length).\n",
    "        def best_match(i):\n",
    "            candidates = enumerate(reversed(cost[max(0, i-maxword):i]))\n",
    "            return min((c + wordcost.get(s[i-k-1:i], 9e999), k+1) for k,c in candidates)\n",
    "\n",
    "        # Build the cost array.\n",
    "        cost = [0]\n",
    "        for i in range(1,len(s)+1):\n",
    "            c,k = best_match(i)\n",
    "            cost.append(c)\n",
    "\n",
    "        # Backtrack to recover the minimal-cost string.\n",
    "        out = []\n",
    "        i = len(s)\n",
    "        while i>0:\n",
    "            c,k = best_match(i)\n",
    "            assert c == cost[i]\n",
    "            out.append(s[i-k:i])\n",
    "            i -= k\n",
    "\n",
    "        return list(reversed(out))\n",
    "\n",
    "    def apply_hashtag_split(_hashtag):\n",
    "        # for each hashtag in list of hashtags, split on # and take second item\n",
    "        item = [item.split('#')[1] for item in _hashtag if len(item) > 0]\n",
    "\n",
    "        # regex pattern\n",
    "        # (1) split on two caps or more, and only keep caps\n",
    "        # (2) split on exactly one cap or more, and keep trailing letters\n",
    "        pattern = r'([A-Z]{2,})|([A-Z]{1}[a-z]*)'\n",
    "\n",
    "        # loop through each item in list of hashtags\n",
    "        final_hashtags = []\n",
    "        for word in item:\n",
    "\n",
    "            # if len of word is 0, then there is no hashtag\n",
    "            if len(word) == 0:\n",
    "                final_hashtags.append(\"empty_hashtag\")\n",
    "\n",
    "            # use (1)) regex: funciton lowercase, as \"Treatlowercase\" can be treated as lowercase\n",
    "            elif word[0].isupper() and word[1:].islower():\n",
    "                final_hashtags.append(infer_spaces(word.lower()))\n",
    "\n",
    "            # use (1) regex: funciton lowercase\n",
    "            elif word.islower():\n",
    "                final_hashtags.append(infer_spaces(word))\n",
    "\n",
    "            # use (2) regex: customized uppercase\n",
    "            else:\n",
    "                final_hashtags.append(list(filter(None, re.split(pattern, word))))\n",
    "        return final_hashtags\n",
    "\n",
    "    def apply_hashtag_text(_hashtag):\n",
    "        word = _hashtag.split('#')[1] \n",
    "\n",
    "        # regex pattern\n",
    "        # (1) split on two caps or more, and only keep caps\n",
    "        # (2) split on exactly one cap or more, and keep trailing letters\n",
    "        pattern = r'([A-Z]{2,})|([A-Z]{1}[a-z]*)'\n",
    "\n",
    "        # if len of word is 0, then there is no hashtag\n",
    "        if len(word) == 0:\n",
    "            final_hashtags = \"\"\n",
    "\n",
    "        # use (1)) regex: funciton lowercase, as \"Treatlowercase\" can be treated as lowercase\n",
    "        elif word[0].isupper() and word[1:].islower():\n",
    "            final_hashtags =  infer_spaces(word.lower())\n",
    "\n",
    "        # use (1) regex: funciton lowercase\n",
    "        elif word.islower():\n",
    "            final_hashtags = infer_spaces(word)\n",
    "\n",
    "        # use (2) regex: customized uppercase\n",
    "        else:\n",
    "            final_hashtags = list(filter(None, re.split(pattern, word)))\n",
    "\n",
    "        joined_hashtags = ' '.join(final_hashtags)\n",
    "        return joined_hashtags\n",
    "    \n",
    "    addHashTag(df)\n",
    "    noHashtagText(df)\n",
    "    df[\"split_hashtag\"] = df.only_HashTag.apply(apply_hashtag_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_hashtag(clean_tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>retweet</th>\n",
       "      <th>only_emoji</th>\n",
       "      <th>only_HashTag</th>\n",
       "      <th>only_text_splithashtag</th>\n",
       "      <th>split_hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>380852618685210625</td>\n",
       "      <td>Ah, the ARC during the summer. Where one knows not if the groans are from strenuous exercise or the pain of hangovers past.</td>\n",
       "      <td>834886554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ah , the ARC during the summer . Where one knows not if the groans are from strenuous exercise or the pain of hangovers past .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>381957258436816896</td>\n",
       "      <td>I'm really obsessed with my toes bc I'm blessed with pretty feet. \\n\\nIs that conceited ? It's just my feet idk.</td>\n",
       "      <td>926232458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I'm really obsessed with my toes bc I'm blessed with pretty feet . Is that conceited ? It's just my feet idk .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>383360559250296832</td>\n",
       "      <td>Fucking another fire drill. I'm doneeee</td>\n",
       "      <td>50575737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Fucking another fire drill . I'm doneeee</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>384443607379243008</td>\n",
       "      <td>Some  hdl  reading for the flight. Oh, and thanks  hdl  for the in-flight music!  url</td>\n",
       "      <td>18095878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Some hdl reading for the flight . Oh , and thanks hdl for the in-flight music ! url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>381880837911748608</td>\n",
       "      <td>Yay for Fall!</td>\n",
       "      <td>15538455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Yay for Fall !</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>382659372649676800</td>\n",
       "      <td>hdl  yeahhh ROAD TRIP</td>\n",
       "      <td>77063592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl yeahhh ROAD TRIP</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>385855209102012416</td>\n",
       "      <td>Crepevine with  hdl   üòç  url</td>\n",
       "      <td>548146276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üòç]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Crepevine with hdl url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>384476775369039872</td>\n",
       "      <td>Well, that was a unfortunate time not to have a cigarette lighter.  Maybe I should just have one around even though I gave up smoking.</td>\n",
       "      <td>14622512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Well , that was a unfortunate time not to have a cigarette lighter . Maybe I should just have one around even though I gave up smoking .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>380408506068660225</td>\n",
       "      <td>Didn't wanna leave my room for 56 hours anyways ?? No prob!  url</td>\n",
       "      <td>622968626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Didn't wanna leave my room for 56 hours anyways ? ? No prob ! url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>383117742162726912</td>\n",
       "      <td>this girl actually made a birthday collage on Instagram fOR HERSELF</td>\n",
       "      <td>1462638157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>this girl actually made a birthday collage on Instagram fOR HERSELF</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>381165589693071360</td>\n",
       "      <td>Back on the court!!! ‚úåÔ∏è‚úåÔ∏è</td>\n",
       "      <td>192611656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[‚úå, ‚úå]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Back on the court ! ! ! Ô∏è Ô∏è</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>385102139363561472</td>\n",
       "      <td>hdl  no it was still in the same condition</td>\n",
       "      <td>467232664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl no it was still in the same condition</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>384166917663391744</td>\n",
       "      <td>I'm at Howl at the Moon -  hdl  (Universal City, CA)  url</td>\n",
       "      <td>470499795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I'm at Howl at the Moon - hdl ( Universal City , CA ) url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>385450615595220992</td>\n",
       "      <td>#SanLeandro , CA #IT #Job: web developer 5 at Wells Fargo  url  #Jobs #TweetMyJobs</td>\n",
       "      <td>108743075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#SanLeandro, #IT, #Job, #Jobs, #TweetMyJobs]</td>\n",
       "      <td>San Leandro , CA IT job : web developer 5 at Wells Fargo url jobs Tweet My Jobs</td>\n",
       "      <td>[[San, Leandro], [IT], [job], [jobs], [Tweet, My, Jobs]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>381638626037075968</td>\n",
       "      <td>#Syria'n #Christians may get pulled into #war | Codewit  url</td>\n",
       "      <td>21478415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#Syria, #Christians, #war]</td>\n",
       "      <td>syria ' n christians may get pulled into war | Codewit url</td>\n",
       "      <td>[[syria], [christians], [war]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>384082809230352384</td>\n",
       "      <td>hdl   hdl  thanks Craig!!!</td>\n",
       "      <td>200715240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl hdl thanks Craig ! ! !</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>382635619337244672</td>\n",
       "      <td>hdl  lol Can I send you a DM? It's embarrassing! For LG anyway! lol</td>\n",
       "      <td>1566977124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl lol Can I send you a DM ? It's embarrassing ! For LG anyway ! lol</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>380592603877474304</td>\n",
       "      <td>üíî</td>\n",
       "      <td>383886939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üíî]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>382973563944583168</td>\n",
       "      <td>I'm at Autodesk One McInnis  url</td>\n",
       "      <td>20207933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I'm at Autodesk One McInnis url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>378172925243047936</td>\n",
       "      <td>Every time this girl opens her mouth and says some crap about her life I just want to be like here‚Ä¶  url</td>\n",
       "      <td>70437300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Every time this girl opens her mouth and says some crap about her life I just want to be like here ‚Ä¶ url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>384873273604837376</td>\n",
       "      <td>Class is just making me sleeeepyyyüò¥üò¥üò¥üò©üò©</td>\n",
       "      <td>1915599596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üò¥, üò¥, üò¥, üò©, üò©]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Class is just making me sleeeepyyy</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>383465813736321024</td>\n",
       "      <td>\"Uh bitch. I saw you see me see you\" lmfaooooooo üòÇüò≠</td>\n",
       "      <td>340180132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üòÇ, üò≠]</td>\n",
       "      <td>[]</td>\n",
       "      <td>\" Uh bitch . I saw you see me see you \" lmfaooooooo</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>385804425333190656</td>\n",
       "      <td>Ur ex is asking me permission to talk to you again....this girl is crazy, u think I care?? üòÇ</td>\n",
       "      <td>1624386806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üòÇ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ur ex is asking me permission to talk to you again .... this girl is crazy , u think I care ? ?</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>385509243870126080</td>\n",
       "      <td>hdl  üòäüòÇüòÇüòÇüòÇüòÇüòõ</td>\n",
       "      <td>198009492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üòä, üòÇ, üòÇ, üòÇ, üòÇ, üòÇ, üòõ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>380907319279620097</td>\n",
       "      <td>hdl   hdl  go you even know what that means</td>\n",
       "      <td>269632047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl hdl go you even know what that means</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>379050209348575232</td>\n",
       "      <td>Lmfaooo you knew.</td>\n",
       "      <td>371077217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Lmfaooo you knew .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>378618680554188800</td>\n",
       "      <td>hdl   hdl  the \"BK11\"</td>\n",
       "      <td>246671118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl hdl the \" BK11 \"</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>383807266509828096</td>\n",
       "      <td>Oh sweet child @ Germany  url</td>\n",
       "      <td>28363528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Oh sweet child @ Germany url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>385614271297912832</td>\n",
       "      <td>Lol today during band we were playing with clay #booty @ Jefferson High School  url</td>\n",
       "      <td>489753212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#booty]</td>\n",
       "      <td>Lol today during band we were playing with clay booty @ Jefferson High School url</td>\n",
       "      <td>[[booty]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>382904380497752064</td>\n",
       "      <td>El q madruga Dios le ayuda</td>\n",
       "      <td>1881745010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>El q madruga Dios le ayuda</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>379334579163004929</td>\n",
       "      <td>I'm at AJ Auto Detailing (San Jose, CA)  url</td>\n",
       "      <td>14749080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I'm at AJ Auto Detailing ( San Jose , CA ) url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>385048651417935873</td>\n",
       "      <td>#life is a tricky thing</td>\n",
       "      <td>210750256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#life]</td>\n",
       "      <td>life is a tricky thing</td>\n",
       "      <td>[[life]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>378954780757864448</td>\n",
       "      <td>hdl   hdl   url</td>\n",
       "      <td>966766974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl hdl url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>378607344222867456</td>\n",
       "      <td>hdl  Sweet! I'll keep you posted.</td>\n",
       "      <td>18615506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl Sweet ! I'll keep you posted .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>380346331442597888</td>\n",
       "      <td>hdl  üòÇ</td>\n",
       "      <td>167063003</td>\n",
       "      <td>‚Äú hdl : #IfMyMomHadATwitter my tweets would be like  url ‚Äù</td>\n",
       "      <td>[üòÇ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>378930286806855680</td>\n",
       "      <td>hdl  dia tu samsung</td>\n",
       "      <td>73821102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl dia tu samsung</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>382732758570631168</td>\n",
       "      <td>hdl  lol leave that man alone, you can't be mad he's sticking to his guns. He's a homer</td>\n",
       "      <td>373407586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hdl lol leave that man alone , you can't be mad he's sticking to his guns . He's a homer</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>386023205288148992</td>\n",
       "      <td>Tired as hell... Hubby needs gas that shit, lol. I'm about to fall asleep. üòí</td>\n",
       "      <td>1400513376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[üòí]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tired as hell ... Hubby needs gas that shit , lol . I'm about to fall asleep .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>382296433321574400</td>\n",
       "      <td>Working hard at #oow13 exhibition ground. @ Moscone South  url</td>\n",
       "      <td>37445840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#oow13]</td>\n",
       "      <td>Working hard at oo w13 exhibition ground . @ Moscone South url</td>\n",
       "      <td>[[oo, w13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>384888222427279360</td>\n",
       "      <td>The start of the streak  url</td>\n",
       "      <td>598563532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>The start of the streak url</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  \\\n",
       "11  380852618685210625   \n",
       "12  381957258436816896   \n",
       "13  383360559250296832   \n",
       "14  384443607379243008   \n",
       "15  381880837911748608   \n",
       "16  382659372649676800   \n",
       "17  385855209102012416   \n",
       "18  384476775369039872   \n",
       "19  380408506068660225   \n",
       "20  383117742162726912   \n",
       "21  381165589693071360   \n",
       "22  385102139363561472   \n",
       "23  384166917663391744   \n",
       "24  385450615595220992   \n",
       "25  381638626037075968   \n",
       "26  384082809230352384   \n",
       "27  382635619337244672   \n",
       "28  380592603877474304   \n",
       "29  382973563944583168   \n",
       "30  378172925243047936   \n",
       "31  384873273604837376   \n",
       "32  383465813736321024   \n",
       "33  385804425333190656   \n",
       "34  385509243870126080   \n",
       "35  380907319279620097   \n",
       "36  379050209348575232   \n",
       "37  378618680554188800   \n",
       "38  383807266509828096   \n",
       "39  385614271297912832   \n",
       "40  382904380497752064   \n",
       "41  379334579163004929   \n",
       "42  385048651417935873   \n",
       "43  378954780757864448   \n",
       "44  378607344222867456   \n",
       "45  380346331442597888   \n",
       "46  378930286806855680   \n",
       "47  382732758570631168   \n",
       "48  386023205288148992   \n",
       "49  382296433321574400   \n",
       "50  384888222427279360   \n",
       "\n",
       "                                                                                                                                      text  \\\n",
       "11             Ah, the ARC during the summer. Where one knows not if the groans are from strenuous exercise or the pain of hangovers past.   \n",
       "12                        I'm really obsessed with my toes bc I'm blessed with pretty feet. \\n\\nIs that conceited ? It's just my feet idk.   \n",
       "13                                                                                                 Fucking another fire drill. I'm doneeee   \n",
       "14                                                  Some  hdl  reading for the flight. Oh, and thanks  hdl  for the in-flight music!  url    \n",
       "15                                                                                                                           Yay for Fall!   \n",
       "16                                                                                                                   hdl  yeahhh ROAD TRIP   \n",
       "17                                                                                                           Crepevine with  hdl   üòç  url    \n",
       "18  Well, that was a unfortunate time not to have a cigarette lighter.  Maybe I should just have one around even though I gave up smoking.   \n",
       "19                                                                       Didn't wanna leave my room for 56 hours anyways ?? No prob!  url    \n",
       "20                                                                     this girl actually made a birthday collage on Instagram fOR HERSELF   \n",
       "21                                                                                                               Back on the court!!! ‚úåÔ∏è‚úåÔ∏è   \n",
       "22                                                                                              hdl  no it was still in the same condition   \n",
       "23                                                                              I'm at Howl at the Moon -  hdl  (Universal City, CA)  url    \n",
       "24                                                      #SanLeandro , CA #IT #Job: web developer 5 at Wells Fargo  url  #Jobs #TweetMyJobs   \n",
       "25                                                                           #Syria'n #Christians may get pulled into #war | Codewit  url    \n",
       "26                                                                                                              hdl   hdl  thanks Craig!!!   \n",
       "27                                                                     hdl  lol Can I send you a DM? It's embarrassing! For LG anyway! lol   \n",
       "28                                                                                                                                       üíî   \n",
       "29                                                                                                       I'm at Autodesk One McInnis  url    \n",
       "30                               Every time this girl opens her mouth and says some crap about her life I just want to be like here‚Ä¶  url    \n",
       "31                                                                                                 Class is just making me sleeeepyyyüò¥üò¥üò¥üò©üò©   \n",
       "32                                                                                     \"Uh bitch. I saw you see me see you\" lmfaooooooo üòÇüò≠   \n",
       "33                                            Ur ex is asking me permission to talk to you again....this girl is crazy, u think I care?? üòÇ   \n",
       "34                                                                                                                            hdl  üòäüòÇüòÇüòÇüòÇüòÇüòõ   \n",
       "35                                                                                             hdl   hdl  go you even know what that means   \n",
       "36                                                                                                                       Lmfaooo you knew.   \n",
       "37                                                                                                                   hdl   hdl  the \"BK11\"   \n",
       "38                                                                                                          Oh sweet child @ Germany  url    \n",
       "39                                                    Lol today during band we were playing with clay #booty @ Jefferson High School  url    \n",
       "40                                                                                                              El q madruga Dios le ayuda   \n",
       "41                                                                                           I'm at AJ Auto Detailing (San Jose, CA)  url    \n",
       "42                                                                                                                 #life is a tricky thing   \n",
       "43                                                                                                                        hdl   hdl   url    \n",
       "44                                                                                                       hdl  Sweet! I'll keep you posted.   \n",
       "45                                                                                                                                  hdl  üòÇ   \n",
       "46                                                                                                                     hdl  dia tu samsung   \n",
       "47                                                 hdl  lol leave that man alone, you can't be mad he's sticking to his guns. He's a homer   \n",
       "48                                                            Tired as hell... Hubby needs gas that shit, lol. I'm about to fall asleep. üòí   \n",
       "49                                                                         Working hard at #oow13 exhibition ground. @ Moscone South  url    \n",
       "50                                                                                                           The start of the streak  url    \n",
       "\n",
       "       user_id                                                     retweet  \\\n",
       "11   834886554                                                         NaN   \n",
       "12   926232458                                                         NaN   \n",
       "13    50575737                                                         NaN   \n",
       "14    18095878                                                         NaN   \n",
       "15    15538455                                                         NaN   \n",
       "16    77063592                                                         NaN   \n",
       "17   548146276                                                         NaN   \n",
       "18    14622512                                                         NaN   \n",
       "19   622968626                                                         NaN   \n",
       "20  1462638157                                                         NaN   \n",
       "21   192611656                                                         NaN   \n",
       "22   467232664                                                         NaN   \n",
       "23   470499795                                                         NaN   \n",
       "24   108743075                                                         NaN   \n",
       "25    21478415                                                         NaN   \n",
       "26   200715240                                                         NaN   \n",
       "27  1566977124                                                         NaN   \n",
       "28   383886939                                                         NaN   \n",
       "29    20207933                                                         NaN   \n",
       "30    70437300                                                         NaN   \n",
       "31  1915599596                                                         NaN   \n",
       "32   340180132                                                         NaN   \n",
       "33  1624386806                                                         NaN   \n",
       "34   198009492                                                         NaN   \n",
       "35   269632047                                                         NaN   \n",
       "36   371077217                                                         NaN   \n",
       "37   246671118                                                         NaN   \n",
       "38    28363528                                                         NaN   \n",
       "39   489753212                                                         NaN   \n",
       "40  1881745010                                                         NaN   \n",
       "41    14749080                                                         NaN   \n",
       "42   210750256                                                         NaN   \n",
       "43   966766974                                                         NaN   \n",
       "44    18615506                                                         NaN   \n",
       "45   167063003  ‚Äú hdl : #IfMyMomHadATwitter my tweets would be like  url ‚Äù   \n",
       "46    73821102                                                         NaN   \n",
       "47   373407586                                                         NaN   \n",
       "48  1400513376                                                         NaN   \n",
       "49    37445840                                                         NaN   \n",
       "50   598563532                                                         NaN   \n",
       "\n",
       "               only_emoji                                   only_HashTag  \\\n",
       "11                     []                                             []   \n",
       "12                     []                                             []   \n",
       "13                     []                                             []   \n",
       "14                     []                                             []   \n",
       "15                     []                                             []   \n",
       "16                     []                                             []   \n",
       "17                    [üòç]                                             []   \n",
       "18                     []                                             []   \n",
       "19                     []                                             []   \n",
       "20                     []                                             []   \n",
       "21                 [‚úå, ‚úå]                                             []   \n",
       "22                     []                                             []   \n",
       "23                     []                                             []   \n",
       "24                     []  [#SanLeandro, #IT, #Job, #Jobs, #TweetMyJobs]   \n",
       "25                     []                    [#Syria, #Christians, #war]   \n",
       "26                     []                                             []   \n",
       "27                     []                                             []   \n",
       "28                    [üíî]                                             []   \n",
       "29                     []                                             []   \n",
       "30                     []                                             []   \n",
       "31        [üò¥, üò¥, üò¥, üò©, üò©]                                             []   \n",
       "32                 [üòÇ, üò≠]                                             []   \n",
       "33                    [üòÇ]                                             []   \n",
       "34  [üòä, üòÇ, üòÇ, üòÇ, üòÇ, üòÇ, üòõ]                                             []   \n",
       "35                     []                                             []   \n",
       "36                     []                                             []   \n",
       "37                     []                                             []   \n",
       "38                     []                                             []   \n",
       "39                     []                                       [#booty]   \n",
       "40                     []                                             []   \n",
       "41                     []                                             []   \n",
       "42                     []                                        [#life]   \n",
       "43                     []                                             []   \n",
       "44                     []                                             []   \n",
       "45                    [üòÇ]                                             []   \n",
       "46                     []                                             []   \n",
       "47                     []                                             []   \n",
       "48                    [üòí]                                             []   \n",
       "49                     []                                       [#oow13]   \n",
       "50                     []                                             []   \n",
       "\n",
       "                                                                                                                      only_text_splithashtag  \\\n",
       "11            Ah , the ARC during the summer . Where one knows not if the groans are from strenuous exercise or the pain of hangovers past .   \n",
       "12                            I'm really obsessed with my toes bc I'm blessed with pretty feet . Is that conceited ? It's just my feet idk .   \n",
       "13                                                                                                  Fucking another fire drill . I'm doneeee   \n",
       "14                                                       Some hdl reading for the flight . Oh , and thanks hdl for the in-flight music ! url   \n",
       "15                                                                                                                            Yay for Fall !   \n",
       "16                                                                                                                      hdl yeahhh ROAD TRIP   \n",
       "17                                                                                                                    Crepevine with hdl url   \n",
       "18  Well , that was a unfortunate time not to have a cigarette lighter . Maybe I should just have one around even though I gave up smoking .   \n",
       "19                                                                         Didn't wanna leave my room for 56 hours anyways ? ? No prob ! url   \n",
       "20                                                                       this girl actually made a birthday collage on Instagram fOR HERSELF   \n",
       "21                                                                                                               Back on the court ! ! ! Ô∏è Ô∏è   \n",
       "22                                                                                                 hdl no it was still in the same condition   \n",
       "23                                                                                 I'm at Howl at the Moon - hdl ( Universal City , CA ) url   \n",
       "24                                                           San Leandro , CA IT job : web developer 5 at Wells Fargo url jobs Tweet My Jobs   \n",
       "25                                                                                syria ' n christians may get pulled into war | Codewit url   \n",
       "26                                                                                                                hdl hdl thanks Craig ! ! !   \n",
       "27                                                                     hdl lol Can I send you a DM ? It's embarrassing ! For LG anyway ! lol   \n",
       "28                                                                                                                                             \n",
       "29                                                                                                           I'm at Autodesk One McInnis url   \n",
       "30                                  Every time this girl opens her mouth and says some crap about her life I just want to be like here ‚Ä¶ url   \n",
       "31                                                                                                        Class is just making me sleeeepyyy   \n",
       "32                                                                                       \" Uh bitch . I saw you see me see you \" lmfaooooooo   \n",
       "33                                           Ur ex is asking me permission to talk to you again .... this girl is crazy , u think I care ? ?   \n",
       "34                                                                                                                                       hdl   \n",
       "35                                                                                                  hdl hdl go you even know what that means   \n",
       "36                                                                                                                        Lmfaooo you knew .   \n",
       "37                                                                                                                      hdl hdl the \" BK11 \"   \n",
       "38                                                                                                              Oh sweet child @ Germany url   \n",
       "39                                                         Lol today during band we were playing with clay booty @ Jefferson High School url   \n",
       "40                                                                                                                El q madruga Dios le ayuda   \n",
       "41                                                                                            I'm at AJ Auto Detailing ( San Jose , CA ) url   \n",
       "42                                                                                                                    life is a tricky thing   \n",
       "43                                                                                                                               hdl hdl url   \n",
       "44                                                                                                        hdl Sweet ! I'll keep you posted .   \n",
       "45                                                                                                                                       hdl   \n",
       "46                                                                                                                        hdl dia tu samsung   \n",
       "47                                                  hdl lol leave that man alone , you can't be mad he's sticking to his guns . He's a homer   \n",
       "48                                                            Tired as hell ... Hubby needs gas that shit , lol . I'm about to fall asleep .   \n",
       "49                                                                            Working hard at oo w13 exhibition ground . @ Moscone South url   \n",
       "50                                                                                                               The start of the streak url   \n",
       "\n",
       "                                               split_hashtag  \n",
       "11                                                        []  \n",
       "12                                                        []  \n",
       "13                                                        []  \n",
       "14                                                        []  \n",
       "15                                                        []  \n",
       "16                                                        []  \n",
       "17                                                        []  \n",
       "18                                                        []  \n",
       "19                                                        []  \n",
       "20                                                        []  \n",
       "21                                                        []  \n",
       "22                                                        []  \n",
       "23                                                        []  \n",
       "24  [[San, Leandro], [IT], [job], [jobs], [Tweet, My, Jobs]]  \n",
       "25                            [[syria], [christians], [war]]  \n",
       "26                                                        []  \n",
       "27                                                        []  \n",
       "28                                                        []  \n",
       "29                                                        []  \n",
       "30                                                        []  \n",
       "31                                                        []  \n",
       "32                                                        []  \n",
       "33                                                        []  \n",
       "34                                                        []  \n",
       "35                                                        []  \n",
       "36                                                        []  \n",
       "37                                                        []  \n",
       "38                                                        []  \n",
       "39                                                 [[booty]]  \n",
       "40                                                        []  \n",
       "41                                                        []  \n",
       "42                                                  [[life]]  \n",
       "43                                                        []  \n",
       "44                                                        []  \n",
       "45                                                        []  \n",
       "46                                                        []  \n",
       "47                                                        []  \n",
       "48                                                        []  \n",
       "49                                               [[oo, w13]]  \n",
       "50                                                        []  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets_df = clean_tweets_df.drop(['lat','lng','only_text','timeStamp'], axis=1)\n",
    "clean_tweets_df[10:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_tweets_df.to_json('./data/tweets_training_clean.json', force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
