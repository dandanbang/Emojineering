{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import all necessary packages\n",
    "import json\n",
    "import re\n",
    "\n",
    "import nltk, string\n",
    "from nltk.collocations import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import *\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from happyfuntokenizing import Tokenizer\n",
    "\n",
    "import twitterclean as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/tweets_1M.json','r') as f:\n",
    "    tweet_df = DataFrame(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Clean Data (Handle, URL, Emoticon Conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367031 handles replaced\n",
      "227446 urls replaced\n",
      "ğŸ˜€   replaced    209 times\n",
      "ğŸ˜‰   replaced   3358 times\n",
      "ğŸ˜œ   replaced    329 times\n",
      "ğŸ˜†   replaced      0 times\n",
      "ğŸ˜   replaced    111 times\n",
      "ğŸ˜€   replaced   1533 times\n",
      "ğŸ˜   replaced     92 times\n",
      "ğŸ’”   replaced      0 times\n",
      "ğŸ˜   replaced   5760 times\n",
      "â¤   replaced      0 times\n",
      "ğŸ˜§   replaced    207 times\n",
      "ğŸ˜›   replaced   1166 times\n",
      "ğŸµ   replaced      7 times\n",
      "ğŸ˜    replaced      0 times\n",
      "ğŸ˜ƒ   replaced  15658 times\n",
      "ğŸ˜®   replaced    357 times\n",
      "ğŸ˜¢   replaced    339 times\n",
      "ğŸ’‹   replaced    287 times\n",
      "ğŸ˜•   replaced   7435 times\n",
      "ALL replaced 36848 times\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>text</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377652254096228352</td>\n",
       "      <td>37.446100</td>\n",
       "      <td>-121.883557</td>\n",
       "      <td>hdl  hey checkout the website:  url</td>\n",
       "      <td>Wed Sep 11 04:38:08 +0000 2013</td>\n",
       "      <td>224874450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>377652255346159616</td>\n",
       "      <td>34.087406</td>\n",
       "      <td>-117.462604</td>\n",
       "      <td>hdl  ğŸ˜ª</td>\n",
       "      <td>Wed Sep 11 04:38:08 +0000 2013</td>\n",
       "      <td>312179473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>377652262325456897</td>\n",
       "      <td>37.356131</td>\n",
       "      <td>-121.842867</td>\n",
       "      <td>i laugh a lot with that line</td>\n",
       "      <td>Wed Sep 11 04:38:10 +0000 2013</td>\n",
       "      <td>54351774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>377652264682655744</td>\n",
       "      <td>37.364664</td>\n",
       "      <td>-122.009629</td>\n",
       "      <td>sons of anarchy is back on woop woop</td>\n",
       "      <td>Wed Sep 11 04:38:11 +0000 2013</td>\n",
       "      <td>343219606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>377652271116722176</td>\n",
       "      <td>37.382600</td>\n",
       "      <td>-121.995000</td>\n",
       "      <td>Drinking a Fresh Squeezed IPA by  hdl  @ St. John's Bar &amp;amp; Grill â€”  url</td>\n",
       "      <td>Wed Sep 11 04:38:12 +0000 2013</td>\n",
       "      <td>1569395935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        lat         lng  \\\n",
       "0  377652254096228352  37.446100 -121.883557   \n",
       "1  377652255346159616  34.087406 -117.462604   \n",
       "2  377652262325456897  37.356131 -121.842867   \n",
       "3  377652264682655744  37.364664 -122.009629   \n",
       "4  377652271116722176  37.382600 -121.995000   \n",
       "\n",
       "                                                                          text  \\\n",
       "0                                         hdl  hey checkout the website:  url    \n",
       "1                                                                       hdl  ğŸ˜ª   \n",
       "2                                                 i laugh a lot with that line   \n",
       "3                                         sons of anarchy is back on woop woop   \n",
       "4  Drinking a Fresh Squeezed IPA by  hdl  @ St. John's Bar &amp; Grill â€”  url    \n",
       "\n",
       "                        timeStamp     user_id  \n",
       "0  Wed Sep 11 04:38:08 +0000 2013   224874450  \n",
       "1  Wed Sep 11 04:38:08 +0000 2013   312179473  \n",
       "2  Wed Sep 11 04:38:10 +0000 2013    54351774  \n",
       "3  Wed Sep 11 04:38:11 +0000 2013   343219606  \n",
       "4  Wed Sep 11 04:38:12 +0000 2013  1569395935  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df = tc.cleanHandle(tweet_df)\n",
    "tweet_df = tc.cleanURL(tweet_df)\n",
    "tweet_df = tc.convertEmoticon(tweet_df)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Emoji Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Wide UCS-4 build\n",
    "    highpoints = re.compile(u'['\n",
    "        u'\\U0001F300-\\U0001F64F'\n",
    "        u'\\U0001F680-\\U0001F6FF'\n",
    "        u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "        re.UNICODE)\n",
    "except re.error:\n",
    "    # Narrow UCS-2 build\n",
    "    highpoints = re.compile(u'('\n",
    "        u'\\ud83c[\\udf00-\\udfff]|'\n",
    "        u'\\ud83d[\\udc00-\\ude4f\\ude80-\\udeff]|'\n",
    "        u'[\\u2600-\\u26FF\\u2700-\\u27BF])+', \n",
    "        re.UNICODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Dataframe with Emojis Only (New Dataframe emoij_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emoji_list = []\n",
    "for index, value in enumerate(tweet_df.text):\n",
    "    if highpoints.search(value):\n",
    "        emoji_list.append((index, value))\n",
    "emoji_index = [x[0] for x in emoji_list]\n",
    "emoji_df = tweet_df.ix[emoji_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a user id so technically we could identify sets of tweets by users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** first stab at counting frequency of different emojis **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Add a new column that display just the emojis for the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>text</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>Emoji</th>\n",
       "      <th>only_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377652254096228352</td>\n",
       "      <td>37.446100</td>\n",
       "      <td>-121.883557</td>\n",
       "      <td>hdl  hey checkout the website:  url</td>\n",
       "      <td>Wed Sep 11 04:38:08 +0000 2013</td>\n",
       "      <td>224874450</td>\n",
       "      <td>[]</td>\n",
       "      <td>[hdl, hey, checkout, the, website, :, url]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>377652255346159616</td>\n",
       "      <td>34.087406</td>\n",
       "      <td>-117.462604</td>\n",
       "      <td>hdl  ğŸ˜ª</td>\n",
       "      <td>Wed Sep 11 04:38:08 +0000 2013</td>\n",
       "      <td>312179473</td>\n",
       "      <td>[ğŸ˜ª]</td>\n",
       "      <td>[hdl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>377652262325456897</td>\n",
       "      <td>37.356131</td>\n",
       "      <td>-121.842867</td>\n",
       "      <td>i laugh a lot with that line</td>\n",
       "      <td>Wed Sep 11 04:38:10 +0000 2013</td>\n",
       "      <td>54351774</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i, laugh, a, lot, with, that, line]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>377652264682655744</td>\n",
       "      <td>37.364664</td>\n",
       "      <td>-122.009629</td>\n",
       "      <td>sons of anarchy is back on woop woop</td>\n",
       "      <td>Wed Sep 11 04:38:11 +0000 2013</td>\n",
       "      <td>343219606</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sons, of, anarchy, is, back, on, woop, woop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>377652271116722176</td>\n",
       "      <td>37.382600</td>\n",
       "      <td>-121.995000</td>\n",
       "      <td>Drinking a Fresh Squeezed IPA by  hdl  @ St. John's Bar &amp;amp; Grill â€”  url</td>\n",
       "      <td>Wed Sep 11 04:38:12 +0000 2013</td>\n",
       "      <td>1569395935</td>\n",
       "      <td>[]</td>\n",
       "      <td>[drinking, a, fresh, squeezed, ipa, by, hdl, @, st, ., john's, bar, &amp;, amp, ;, grill, â€”, url]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>377652275147444224</td>\n",
       "      <td>37.756149</td>\n",
       "      <td>-122.152813</td>\n",
       "      <td>I have 8 am classes this quarter ... I need to get this sleep thing together</td>\n",
       "      <td>Wed Sep 11 04:38:13 +0000 2013</td>\n",
       "      <td>399164195</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i, have, 8, am, classes, this, quarter, ..., i, need, to, get, this, sleep, thing, together]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>377652275885654016</td>\n",
       "      <td>38.402054</td>\n",
       "      <td>-121.476074</td>\n",
       "      <td>Why is Milgrim's eyes always red af..?</td>\n",
       "      <td>Wed Sep 11 04:38:13 +0000 2013</td>\n",
       "      <td>170950783</td>\n",
       "      <td>[]</td>\n",
       "      <td>[why, is, milgrim's, eyes, always, red, af, .., ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>377652281480843264</td>\n",
       "      <td>34.080237</td>\n",
       "      <td>-118.390160</td>\n",
       "      <td>#FightOn! ğŸ˜› MT  hdl : Eh, you're down south. Lol RT â€œ hdl : I'm here for a few days! ğŸ˜ƒ  hdl   hdl â€</td>\n",
       "      <td>Wed Sep 11 04:38:15 +0000 2013</td>\n",
       "      <td>105560657</td>\n",
       "      <td>[ğŸ˜›, ğŸ˜ƒ]</td>\n",
       "      <td>[#fighton, !, mt, hdl, :, eh, ,, you're, down, south, ., lol, rt, â€œ, hdl, :, i'm, here, for, a, few, days, !, hdl, hdl, â€]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>377652282021933056</td>\n",
       "      <td>37.477945</td>\n",
       "      <td>-122.227526</td>\n",
       "      <td>Asked him what he did today and got a response like this \"I was being black\" daaaa fuck, #DumbBitch #GoAwayDen</td>\n",
       "      <td>Wed Sep 11 04:38:15 +0000 2013</td>\n",
       "      <td>330249663</td>\n",
       "      <td>[]</td>\n",
       "      <td>[asked, him, what, he, did, today, and, got, a, response, like, this, \", i, was, being, black, \", daaaa, fuck, ,, #dumbbitch, #goawayden]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>377652282844012544</td>\n",
       "      <td>37.274621</td>\n",
       "      <td>-121.742097</td>\n",
       "      <td>hdl  my moms just nosey lol</td>\n",
       "      <td>Wed Sep 11 04:38:15 +0000 2013</td>\n",
       "      <td>46575217</td>\n",
       "      <td>[]</td>\n",
       "      <td>[hdl, my, moms, just, nosey, lol]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        lat         lng  \\\n",
       "0  377652254096228352  37.446100 -121.883557   \n",
       "1  377652255346159616  34.087406 -117.462604   \n",
       "2  377652262325456897  37.356131 -121.842867   \n",
       "3  377652264682655744  37.364664 -122.009629   \n",
       "4  377652271116722176  37.382600 -121.995000   \n",
       "5  377652275147444224  37.756149 -122.152813   \n",
       "6  377652275885654016  38.402054 -121.476074   \n",
       "7  377652281480843264  34.080237 -118.390160   \n",
       "8  377652282021933056  37.477945 -122.227526   \n",
       "9  377652282844012544  37.274621 -121.742097   \n",
       "\n",
       "                                                                                                             text  \\\n",
       "0                                                                            hdl  hey checkout the website:  url    \n",
       "1                                                                                                          hdl  ğŸ˜ª   \n",
       "2                                                                                    i laugh a lot with that line   \n",
       "3                                                                            sons of anarchy is back on woop woop   \n",
       "4                                     Drinking a Fresh Squeezed IPA by  hdl  @ St. John's Bar &amp; Grill â€”  url    \n",
       "5                                    I have 8 am classes this quarter ... I need to get this sleep thing together   \n",
       "6                                                                          Why is Milgrim's eyes always red af..?   \n",
       "7             #FightOn! ğŸ˜› MT  hdl : Eh, you're down south. Lol RT â€œ hdl : I'm here for a few days! ğŸ˜ƒ  hdl   hdl â€   \n",
       "8  Asked him what he did today and got a response like this \"I was being black\" daaaa fuck, #DumbBitch #GoAwayDen   \n",
       "9                                                                                     hdl  my moms just nosey lol   \n",
       "\n",
       "                        timeStamp     user_id   Emoji  \\\n",
       "0  Wed Sep 11 04:38:08 +0000 2013   224874450      []   \n",
       "1  Wed Sep 11 04:38:08 +0000 2013   312179473     [ğŸ˜ª]   \n",
       "2  Wed Sep 11 04:38:10 +0000 2013    54351774      []   \n",
       "3  Wed Sep 11 04:38:11 +0000 2013   343219606      []   \n",
       "4  Wed Sep 11 04:38:12 +0000 2013  1569395935      []   \n",
       "5  Wed Sep 11 04:38:13 +0000 2013   399164195      []   \n",
       "6  Wed Sep 11 04:38:13 +0000 2013   170950783      []   \n",
       "7  Wed Sep 11 04:38:15 +0000 2013   105560657  [ğŸ˜›, ğŸ˜ƒ]   \n",
       "8  Wed Sep 11 04:38:15 +0000 2013   330249663      []   \n",
       "9  Wed Sep 11 04:38:15 +0000 2013    46575217      []   \n",
       "\n",
       "                                                                                                                                   only_Text  \n",
       "0                                                                                                 [hdl, hey, checkout, the, website, :, url]  \n",
       "1                                                                                                                                      [hdl]  \n",
       "2                                                                                                       [i, laugh, a, lot, with, that, line]  \n",
       "3                                                                                              [sons, of, anarchy, is, back, on, woop, woop]  \n",
       "4                                              [drinking, a, fresh, squeezed, ipa, by, hdl, @, st, ., john's, bar, &, amp, ;, grill, â€”, url]  \n",
       "5                                              [i, have, 8, am, classes, this, quarter, ..., i, need, to, get, this, sleep, thing, together]  \n",
       "6                                                                                         [why, is, milgrim's, eyes, always, red, af, .., ?]  \n",
       "7                 [#fighton, !, mt, hdl, :, eh, ,, you're, down, south, ., lol, rt, â€œ, hdl, :, i'm, here, for, a, few, days, !, hdl, hdl, â€]  \n",
       "8  [asked, him, what, he, did, today, and, got, a, response, like, this, \", i, was, being, black, \", daaaa, fuck, ,, #dumbbitch, #goawayden]  \n",
       "9                                                                                                          [hdl, my, moms, just, nosey, lol]  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emojiExtract(sent):\n",
    "    return [word for word in tok.tokenize(sent) if is_emoji(word) == 1]\n",
    "\n",
    "def textExtract(sent):\n",
    "    return [word for word in tok.tokenize(sent) if is_emoji(word) == 0]\n",
    "\n",
    "def addEmojiCol(df):\n",
    "    df['Emoji'] = [emojiExtract(word) for word in df.text]\n",
    "\n",
    "def addText(df):\n",
    "    df['only_Text'] = [textExtract(word) for word in df.text]\n",
    "    \n",
    "addEmojiCol(tweet_df)\n",
    "addText(tweet_df)\n",
    "tweet_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Count Emoji Per Text (1.12 Average Emoji/Text, 53.2 Average Text Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of functions for emoji search\n",
    "faces = re.compile(u'['\n",
    "        u'\\U0001F600-\\U0001F64F]',\n",
    "        re.UNICODE)\n",
    "# Function that takes a list of text and return text that contains just faces\n",
    "def just_face(text):\n",
    "    return (faces.findall(text))\n",
    "# Function that take a list of text and return text with just emojis\n",
    "def just_emojis(text):\n",
    "    return (highpoints.findall(text))\n",
    "# Function that a list of text and return the number of emojis in the text.\n",
    "def count_emojis(text):\n",
    "    return len(highpoints.findall(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>Emoji Count</th>\n",
       "      <th>Text Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.082520e+05</td>\n",
       "      <td>2.082520e+05</td>\n",
       "      <td>208252.000000</td>\n",
       "      <td>208252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.822541e+17</td>\n",
       "      <td>5.198651e+08</td>\n",
       "      <td>1.122659</td>\n",
       "      <td>53.161506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.378889e+15</td>\n",
       "      <td>4.612050e+08</td>\n",
       "      <td>0.603226</td>\n",
       "      <td>33.193435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.776523e+17</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.801828e+17</td>\n",
       "      <td>1.499460e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.823091e+17</td>\n",
       "      <td>3.852509e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.843753e+17</td>\n",
       "      <td>7.546697e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.863382e+17</td>\n",
       "      <td>1.934553e+09</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       user_id    Emoji Count    Text Length\n",
       "count  2.082520e+05  2.082520e+05  208252.000000  208252.000000\n",
       "mean   3.822541e+17  5.198651e+08       1.122659      53.161506\n",
       "std    2.378889e+15  4.612050e+08       0.603226      33.193435\n",
       "min    3.776523e+17  2.100000e+01       1.000000       1.000000\n",
       "25%    3.801828e+17  1.499460e+08       1.000000      27.000000\n",
       "50%    3.823091e+17  3.852509e+08       1.000000      46.000000\n",
       "75%    3.843753e+17  7.546697e+08       1.000000      75.000000\n",
       "max    3.863382e+17  1.934553e+09      70.000000     214.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_df[\"Emoji Count\"] = emoji_df[\"text\"].apply(count_emojis)\n",
    "emoji_df[\"Text Length\"] = emoji_df[\"text\"].apply(lambda x: len(x))\n",
    "emoji_df = emoji_df[['id', 'text', 'timeStamp', 'user_id', 'Emoji Count', 'Text Length']]\n",
    "emoji_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_df = emoji_df.reset_index(drop=True)\n",
    "emoji_array = [reset_df.loc[[index]].text.apply(just_emojis) for index in range(len(reset_df))]\n",
    "full_list = []\n",
    "for item in emoji_array:\n",
    "    for emoji in item:\n",
    "        for sinlge in emoji:\n",
    "            full_list.append(sinlge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_dict = defaultdict(int)\n",
    "for item in full_list:\n",
    "    full_dict[item] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30469 Unique Emoji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30469"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique(full_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜ƒ 7.055753972497274\n",
      "ğŸ˜• 3.5458414422891846\n",
      "ğŸ˜‚ 3.268247823948331\n",
      "â¤ 3.138219380226267\n",
      "ğŸ˜ 2.920935007164396\n",
      "ğŸ˜ 2.202784490686285\n",
      "ğŸ˜‰ 2.0162963279796404\n",
      "ğŸ˜’ 1.7801920485895764\n",
      "ğŸ˜ 1.5299728394533674\n",
      "â˜º 1.5060202313993027\n",
      "ğŸ‘Œ 1.4666695181676255\n",
      "ğŸ˜” 1.4251801792168353\n",
      "ğŸ˜Š 1.3854017408413353\n",
      "ğŸ˜­ 1.3700036356637226\n",
      "ğŸ˜˜ 1.2900190337689001\n",
      "ğŸ˜‚ğŸ˜‚ğŸ˜‚ 1.219016659894352\n",
      "ğŸ˜‚ğŸ˜‚ 1.1702559934985777\n",
      "ğŸ˜³ 1.0992536196240295\n",
      "ğŸ˜ 1.093693192754336\n",
      "ğŸ˜© 1.007292713702175\n",
      "ğŸ’• 0.8862464980003849\n",
      "ğŸ˜€ 0.8242263521461108\n",
      "ğŸ™Œ 0.7378258730939499\n",
      "âœŒ 0.7245663936354498\n",
      "ğŸ’ 0.6894929318419983\n",
      "â™« 0.628755961419192\n",
      "ğŸ˜› 0.6270450608439018\n",
      "ğŸ˜‹ 0.6210569088303856\n",
      "ğŸ˜Œ 0.6210569088303856\n",
      "ğŸ˜‘ 0.6005261019269017\n",
      "ğŸ¶ 0.5923993241942728\n",
      "ğŸ™ 0.5530486109625954\n",
      "ğŸ˜ 0.5513377103873052\n",
      "ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ 0.5393614063602729\n",
      "ğŸ˜œ 0.4474005004384183\n",
      "â™¥ 0.4388459975619667\n",
      "ğŸ‘ 0.4379905472743215\n",
      "ğŸ˜¢ 0.4354241964113861\n",
      "ğŸ‘ 0.4277251438225796\n",
      "ğŸ˜ 0.40505571119998296\n",
      "ğŸ˜ğŸ˜ğŸ˜ 0.3605722962424346\n",
      "ğŸ˜„ 0.34218011505806367\n",
      "â™¡ 0.3400414893389508\n",
      "ğŸ™ˆ 0.3246433841613379\n",
      "ğŸ’‹ 0.32164930815457987\n",
      "ğŸ˜´ 0.3036848521140315\n",
      "ğŸ˜ğŸ˜ 0.30069077610727346\n",
      "âœ‹ 0.2938471738061122\n",
      "ğŸ˜¡ 0.29299172351846703\n",
      "ğŸ˜« 0.29299172351846703\n"
     ]
    }
   ],
   "source": [
    "for item in sorted(full_dict.items(), key=lambda x:x[1], reverse=True)[:50]:\n",
    "    print(item[0], (float(item[1])/len(full_list))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji Face Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets with emojis 233795\n",
      "number of tweets with faces  208252\n",
      "percentage of tweets with emojis with faces 89.1%\n"
     ]
    }
   ],
   "source": [
    "face_array = [reset_df.loc[[index]].text.apply(just_face) for index in range(len(reset_df))]\n",
    "\n",
    "face_list = []\n",
    "for item in face_array:\n",
    "    for emoji in item:\n",
    "        for sinlge in emoji:\n",
    "            face_list.append(sinlge)\n",
    "\n",
    "print(\"number of tweets with emojis {0}\".format(len(full_list)))\n",
    "print(\"number of tweets with faces  {0}\".format(len(face_array)))\n",
    "print(\"percentage of tweets with emojis with faces {0}%\".format(round((float(len(face_array))/len(full_list)*100),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_dict = defaultdict(int)\n",
    "for item in face_list:\n",
    "    face_dict[item] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜‚ 21.143737034581576\n",
      "ğŸ˜ 8.991210248294445\n",
      "ğŸ˜­ 7.4484056545264\n",
      "ğŸ˜ƒ 7.385957783528305\n",
      "ğŸ˜˜ 4.1878568831668765\n",
      "ğŸ˜• 3.733185055283475\n",
      "ğŸ˜ 3.2336020872987015\n",
      "ğŸ˜ 3.092025064693428\n",
      "ğŸ˜Š 2.989371030176009\n",
      "ğŸ˜’ 2.965846147265767\n",
      "ğŸ˜© 2.8405226801257513\n",
      "ğŸ˜ 2.748134049060074\n",
      "ğŸ˜‰ 2.5116020445261875\n",
      "ğŸ˜” 2.3631814196197523\n",
      "ğŸ™Œ 2.2836245428687523\n",
      "ğŸ˜³ 2.1458970465578817\n",
      "ğŸ™ 1.4585427404349964\n",
      "ğŸ˜‹ 1.3712868110951901\n",
      "ğŸ˜‘ 1.1758164203682713\n",
      "ğŸ˜Œ 1.1621292157659489\n",
      "ğŸ˜ 1.1240616779657393\n",
      "ğŸ˜¡ 1.0466434269338525\n",
      "ğŸ˜´ 0.9739301524840137\n",
      "ğŸ™ˆ 0.967514275326675\n",
      "ğŸ˜€ 0.9516884450052396\n",
      "ğŸ˜± 0.9178981586432557\n",
      "ğŸ˜« 0.8888128488633203\n",
      "ğŸ˜› 0.872987018541885\n",
      "ğŸ˜œ 0.8250818024337562\n",
      "ğŸ˜„ 0.8118223229752561\n",
      "ğŸ˜¢ 0.7861588143459013\n",
      "ğŸ˜· 0.7630616565794821\n",
      "ğŸ™Š 0.7442417502512886\n",
      "ğŸ˜ 0.6099360550909985\n",
      "ğŸ˜¤ 0.5184028743129665\n",
      "ğŸ˜ˆ 0.5012938685600633\n",
      "ğŸ˜ª 0.494450266258902\n",
      "ğŸ˜ 0.48332941251951494\n",
      "ğŸ˜– 0.4444064244316602\n",
      "ğŸ˜£ 0.44312324900019245\n",
      "ğŸ™‹ 0.43328557069227314\n",
      "ğŸ˜… 0.4221647169528861\n",
      "ğŸ˜¬ 0.3840971791526765\n",
      "ğŸ˜“ 0.3550118693727411\n",
      "ğŸ˜  0.3537286939412734\n",
      "ğŸ™… 0.34731281678393466\n",
      "ğŸ˜† 0.335764237900725\n",
      "ğŸ˜» 0.32378793387369276\n",
      "ğŸ˜° 0.27374409204645095\n",
      "ğŸ˜š 0.26989456575204773\n"
     ]
    }
   ],
   "source": [
    "for item in sorted(face_dict.items(), key=lambda x:x[1], reverse=True)[:50]:\n",
    "    print(item[0], (float(item[1])/len(full_list))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Emoji vs no Emoji (20% Text has Emojis, 15% has face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Functions to check whether it's emoji or face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to check whether there's an emoji in the text, return 1 if true, 0 if false\n",
    "def is_emoji(text):\n",
    "    if highpoints.search(text):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# Functions to check whether there's a face emoji in the text, return 1 if true, 0 if false\n",
    "def is_face(text):\n",
    "    if faces.search(text):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>text</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_emoji</th>\n",
       "      <th>is_face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377652254096228352</td>\n",
       "      <td>37.446100</td>\n",
       "      <td>-121.883557</td>\n",
       "      <td>hdl  hey checkout the website:  url</td>\n",
       "      <td>Wed Sep 11 04:38:08 +0000 2013</td>\n",
       "      <td>224874450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>377652255346159616</td>\n",
       "      <td>34.087406</td>\n",
       "      <td>-117.462604</td>\n",
       "      <td>hdl  ğŸ˜ª</td>\n",
       "      <td>Wed Sep 11 04:38:08 +0000 2013</td>\n",
       "      <td>312179473</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>377652262325456897</td>\n",
       "      <td>37.356131</td>\n",
       "      <td>-121.842867</td>\n",
       "      <td>i laugh a lot with that line</td>\n",
       "      <td>Wed Sep 11 04:38:10 +0000 2013</td>\n",
       "      <td>54351774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>377652264682655744</td>\n",
       "      <td>37.364664</td>\n",
       "      <td>-122.009629</td>\n",
       "      <td>sons of anarchy is back on woop woop</td>\n",
       "      <td>Wed Sep 11 04:38:11 +0000 2013</td>\n",
       "      <td>343219606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>377652271116722176</td>\n",
       "      <td>37.382600</td>\n",
       "      <td>-121.995000</td>\n",
       "      <td>Drinking a Fresh Squeezed IPA by  hdl  @ St. John's Bar &amp;amp; Grill â€”  url</td>\n",
       "      <td>Wed Sep 11 04:38:12 +0000 2013</td>\n",
       "      <td>1569395935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        lat         lng  \\\n",
       "0  377652254096228352  37.446100 -121.883557   \n",
       "1  377652255346159616  34.087406 -117.462604   \n",
       "2  377652262325456897  37.356131 -121.842867   \n",
       "3  377652264682655744  37.364664 -122.009629   \n",
       "4  377652271116722176  37.382600 -121.995000   \n",
       "\n",
       "                                                                          text  \\\n",
       "0                                         hdl  hey checkout the website:  url    \n",
       "1                                                                       hdl  ğŸ˜ª   \n",
       "2                                                 i laugh a lot with that line   \n",
       "3                                         sons of anarchy is back on woop woop   \n",
       "4  Drinking a Fresh Squeezed IPA by  hdl  @ St. John's Bar &amp; Grill â€”  url    \n",
       "\n",
       "                        timeStamp     user_id  is_emoji  is_face  \n",
       "0  Wed Sep 11 04:38:08 +0000 2013   224874450         0        0  \n",
       "1  Wed Sep 11 04:38:08 +0000 2013   312179473         1        1  \n",
       "2  Wed Sep 11 04:38:10 +0000 2013    54351774         0        0  \n",
       "3  Wed Sep 11 04:38:11 +0000 2013   343219606         0        0  \n",
       "4  Wed Sep 11 04:38:12 +0000 2013  1569395935         0        0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df[\"is_emoji\"] = tweet_df.text.apply(is_emoji)\n",
    "tweet_df[\"is_face\"] = tweet_df.text.apply(is_face)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_emoji</th>\n",
       "      <th>is_face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.822416e+17</td>\n",
       "      <td>37.241980</td>\n",
       "      <td>-121.533430</td>\n",
       "      <td>4.961052e+09</td>\n",
       "      <td>0.208252</td>\n",
       "      <td>0.154146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.370783e+15</td>\n",
       "      <td>1.333404</td>\n",
       "      <td>1.542418</td>\n",
       "      <td>4.503597e+12</td>\n",
       "      <td>0.406058</td>\n",
       "      <td>0.361089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.776523e+17</td>\n",
       "      <td>12.983300</td>\n",
       "      <td>-170.296751</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.801867e+17</td>\n",
       "      <td>37.320896</td>\n",
       "      <td>-122.350934</td>\n",
       "      <td>7.382110e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.822777e+17</td>\n",
       "      <td>37.656377</td>\n",
       "      <td>-122.043733</td>\n",
       "      <td>3.188787e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.843437e+17</td>\n",
       "      <td>37.790622</td>\n",
       "      <td>-121.785433</td>\n",
       "      <td>6.229686e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.887526e+17</td>\n",
       "      <td>57.170120</td>\n",
       "      <td>77.583300</td>\n",
       "      <td>4.503597e+15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id             lat             lng       user_id  \\\n",
       "count  1.000000e+06  1000000.000000  1000000.000000  1.000000e+06   \n",
       "mean   3.822416e+17       37.241980     -121.533430  4.961052e+09   \n",
       "std    2.370783e+15        1.333404        1.542418  4.503597e+12   \n",
       "min    3.776523e+17       12.983300     -170.296751  1.200000e+01   \n",
       "25%    3.801867e+17       37.320896     -122.350934  7.382110e+07   \n",
       "50%    3.822777e+17       37.656377     -122.043733  3.188787e+08   \n",
       "75%    3.843437e+17       37.790622     -121.785433  6.229686e+08   \n",
       "max    3.887526e+17       57.170120       77.583300  4.503597e+15   \n",
       "\n",
       "             is_emoji         is_face  \n",
       "count  1000000.000000  1000000.000000  \n",
       "mean         0.208252        0.154146  \n",
       "std          0.406058        0.361089  \n",
       "min          0.000000        0.000000  \n",
       "25%          0.000000        0.000000  \n",
       "50%          0.000000        0.000000  \n",
       "75%          0.000000        0.000000  \n",
       "max          1.000000        1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Take a look at the imported tokenizer and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tok = Tokenizer(preserve_case=False)\n",
    "samples = (\n",
    "    u\"RT @ #happyfuncoding: this is a typical Twitter tweetğŸ˜–\",\n",
    "    u\"ğŸ˜‚ğŸ˜‚ğŸ˜‚ RT @Yours_Truly3x: Bitch brush yoo mouth; other Web oddities can be an &aacute;cute <em class='grumpy'>pain</em> >:(\",\n",
    "    u\"Yay my cat is cuddlingğŸ”« with me tonightâ¤ +1 (800) 123-4567, (800) 123-4567, and 123-4567 are treated as words despite their whitespace.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RT @ #happyfuncoding: this is a typical Twitter tweetğŸ˜–\n",
      "['rt', '@', '#happyfuncoding', ':', 'this', 'is', 'a', 'typical', 'twitter', 'tweet', 'ğŸ˜–']\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ˜‚ğŸ˜‚ğŸ˜‚ RT @Yours_Truly3x: Bitch brush yoo mouth; other Web oddities can be an &aacute;cute <em class='grumpy'>pain</em> >:(\n",
      "['ğŸ˜‚', 'ğŸ˜‚', 'ğŸ˜‚', 'rt', '@yours_truly3x', ':', 'bitch', 'brush', 'yoo', 'mouth', ';', 'other', 'web', 'oddities', 'can', 'be', 'an', '&', 'aacute', ';', 'cute', \"<em class='grumpy'>\", 'pain', '</em>', '>:(']\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Yay my cat is cuddlingğŸ”« with me tonightâ¤ +1 (800) 123-4567, (800) 123-4567, and 123-4567 are treated as words despite their whitespace.\n",
      "['yay', 'my', 'cat', 'is', 'cuddling', 'ğŸ”«', 'with', 'me', 'tonight', 'â¤', '+1 (800) 123-4567', ',', '(800) 123-4567', ',', 'and', '123-4567', 'are', 'treated', 'as', 'words', 'despite', 'their', 'whitespace', '.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in samples:\n",
    "        print(\"======================================================================\")\n",
    "        print(s)\n",
    "        tokenized = tok.tokenize(s)\n",
    "        print(list(tokenized))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigrams Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hdl', 'hey', 'checkout', 'the', 'website', ':', 'url'], ['hdl', 'ğŸ˜ª'], ['i', 'laugh', 'a', 'lot', 'with', 'that', 'line'], ['sons', 'of', 'anarchy', 'is', 'back', 'on', 'woop', 'woop'], ['drinking', 'a', 'fresh', 'squeezed', 'ipa', 'by', 'hdl', '@', 'st', '.', \"john's\", 'bar', '&', 'amp', ';', 'grill', 'â€”', 'url'], ['i', 'have', '8', 'am', 'classes', 'this', 'quarter', '...', 'i', 'need', 'to', 'get', 'this', 'sleep', 'thing', 'together'], ['why', 'is', \"milgrim's\", 'eyes', 'always', 'red', 'af', '..', '?'], ['#fighton', '!', 'ğŸ˜›', 'mt', 'hdl', ':', 'eh', ',', \"you're\", 'down', 'south', '.', 'lol', 'rt', 'â€œ', 'hdl', ':', \"i'm\", 'here', 'for', 'a', 'few', 'days', '!', 'ğŸ˜ƒ', 'hdl', 'hdl', 'â€'], ['asked', 'him', 'what', 'he', 'did', 'today', 'and', 'got', 'a', 'response', 'like', 'this', '\"', 'i', 'was', 'being', 'black', '\"', 'daaaa', 'fuck', ',', '#dumbbitch', '#goawayden'], ['hdl', 'my', 'moms', 'just', 'nosey', 'lol']]\n"
     ]
    }
   ],
   "source": [
    "tok = Tokenizer(preserve_case=False)\n",
    "text_list = list(tweet_df.text)\n",
    "tokenized = [list(tok.tokenize(item)) for item in text_list]\n",
    "print(tokenized[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english') + [\"http\", 'hdl', 'url'] \n",
    "punctuation_words = list(set(string.punctuation)) + [\":\", \":/\"]\n",
    "\n",
    "def real_unigrams(text):\n",
    "    real_unigrams = [word for sent in text for word in sent if word.lower() not in stop_words and word not in punctuation_words and is_emoji(word) == 1] \n",
    "    real_unigrams_freq = nltk.FreqDist(real_unigrams)\n",
    "    top_unigrams = real_unigrams_freq.most_common(100)\n",
    "    return top_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ğŸ˜‚', 49433),\n",
       " ('ğŸ˜', 21021),\n",
       " ('ğŸ˜­', 17414),\n",
       " ('ğŸ˜ƒ', 17272),\n",
       " ('â¤', 13025),\n",
       " ('ğŸ˜˜', 9791),\n",
       " ('ğŸ˜•', 8727),\n",
       " ('ğŸ‘Œ', 8540),\n",
       " ('ğŸ˜', 7558),\n",
       " ('ğŸ˜', 7229),\n",
       " ('ğŸ˜Š', 6989),\n",
       " ('ğŸ˜’', 6934),\n",
       " ('ğŸ’•', 6650),\n",
       " ('ğŸ˜©', 6641),\n",
       " ('ğŸ˜', 6425),\n",
       " ('ğŸ‘', 5917),\n",
       " ('ğŸ˜‰', 5874),\n",
       " ('â˜º', 5581),\n",
       " ('ğŸ˜”', 5525),\n",
       " ('ğŸ™Œ', 5339),\n",
       " ('ğŸ˜³', 5017),\n",
       " ('ğŸ¶', 3603),\n",
       " ('ğŸ™', 3410),\n",
       " ('ğŸ˜‹', 3206),\n",
       " ('ğŸ‘', 3179),\n",
       " ('ğŸ’', 2892),\n",
       " ('ğŸ‰', 2848),\n",
       " ('âœŒ', 2814),\n",
       " ('ğŸ˜‘', 2749),\n",
       " ('ğŸ˜Œ', 2717),\n",
       " ('ğŸ˜', 2628),\n",
       " ('ğŸ˜¡', 2447),\n",
       " ('ğŸ˜´', 2277),\n",
       " ('ğŸ™ˆ', 2262),\n",
       " ('ğŸ˜€', 2225),\n",
       " ('ğŸ˜±', 2146),\n",
       " ('ğŸ’™', 2125),\n",
       " ('ğŸ’›', 2120),\n",
       " ('â™¥', 2101),\n",
       " ('ğŸ˜«', 2078),\n",
       " ('ğŸ˜›', 2040),\n",
       " ('ğŸ”«', 2008),\n",
       " ('ğŸ˜œ', 1929),\n",
       " ('ğŸ˜„', 1898),\n",
       " ('ğŸ’‹', 1837),\n",
       " ('ğŸ˜¢', 1834),\n",
       " ('ğŸ˜·', 1784),\n",
       " ('ğŸ™Š', 1740),\n",
       " ('â™¡', 1673),\n",
       " ('ğŸ’œ', 1597),\n",
       " ('ğŸ’”', 1539),\n",
       " ('âœ‹', 1507),\n",
       " ('ğŸ‘Š', 1484),\n",
       " ('â™«', 1473),\n",
       " ('ğŸ’š', 1438),\n",
       " ('âœ¨', 1430),\n",
       " ('ğŸ˜', 1426),\n",
       " ('ğŸ”¥', 1338),\n",
       " ('ğŸ’—', 1330),\n",
       " ('ğŸ’¦', 1266),\n",
       " ('ğŸ’¯', 1238),\n",
       " ('ğŸˆ', 1231),\n",
       " ('ğŸ˜¤', 1212),\n",
       " ('ğŸ’ƒ', 1207),\n",
       " ('ğŸ’ª', 1181),\n",
       " ('ğŸ˜ˆ', 1172),\n",
       " ('ğŸ’–', 1165),\n",
       " ('ğŸ˜ª', 1156),\n",
       " ('ğŸ˜', 1130),\n",
       " ('ğŸ’˜', 1049),\n",
       " ('ğŸ˜–', 1039),\n",
       " ('ğŸ˜£', 1036),\n",
       " ('ğŸ’€', 1025),\n",
       " ('ğŸ™‹', 1013),\n",
       " ('ğŸ˜…', 987),\n",
       " ('ğŸ‘¯', 937),\n",
       " ('ğŸ‘‹', 936),\n",
       " ('ğŸ’¨', 915),\n",
       " ('âœŠ', 900),\n",
       " ('ğŸ˜¬', 898),\n",
       " ('ğŸ‘', 875),\n",
       " ('â˜€', 855),\n",
       " ('ğŸˆ', 848),\n",
       " ('âš¾', 843),\n",
       " ('ğŸ’¤', 837),\n",
       " ('ğŸ˜“', 830),\n",
       " ('ğŸ˜ ', 827),\n",
       " ('ğŸ’', 821),\n",
       " ('ğŸ‘€', 821),\n",
       " ('ğŸ»', 813),\n",
       " ('ğŸ™…', 812),\n",
       " ('ğŸ§', 789),\n",
       " ('ğŸ˜†', 785),\n",
       " ('ğŸ˜»', 757),\n",
       " ('ğŸƒ', 755),\n",
       " ('ğŸ’°', 730),\n",
       " ('â˜•', 726),\n",
       " ('ğŸ‘»', 698),\n",
       " ('ğŸ•', 650),\n",
       " ('ğŸ˜°', 640)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_unigrams(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_tokenized = [list(tok.tokenize(item)) for item in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bigrams(text):\n",
    "    all_bigrams = [nltk.bigrams(sent) for sent in text]\n",
    "    all_bigrams = [pair for _list in all_bigrams for pair in list(_list) \\\n",
    "                   if pair[0] not in stop_words and pair[1] not in stop_words \\\n",
    "                  and pair[0] not in punctuation_words and pair[1] not in punctuation_words\n",
    "                  and is_emoji(pair[0]) == 1 and is_emoji(pair[1]) == 1 \n",
    "                  and pair[0] != pair[1]]\n",
    "    \n",
    "    bi_freq = nltk.FreqDist(all_bigrams)\n",
    "    top_bigrams = bi_freq.most_common(100)\n",
    "    return top_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ğŸ˜‚', 'ğŸ˜­'), 1546),\n",
       " (('ğŸ˜­', 'ğŸ˜‚'), 1089),\n",
       " (('ğŸ˜', 'ğŸ˜˜'), 638),\n",
       " (('ğŸ˜', 'â¤'), 418),\n",
       " (('ğŸ˜˜', 'â¤'), 397),\n",
       " (('ğŸ˜‚', 'ğŸ‘'), 386),\n",
       " (('ğŸ’š', 'ğŸ’›'), 339),\n",
       " (('ğŸ˜‚', 'ğŸ‘Œ'), 322),\n",
       " (('ğŸ‰', 'ğŸŠ'), 300),\n",
       " (('ğŸƒ', 'ğŸ‘»'), 298),\n",
       " (('ğŸ˜˜', 'ğŸ˜'), 287),\n",
       " (('ğŸ˜©', 'ğŸ˜­'), 287),\n",
       " (('ğŸ˜', 'ğŸ‘Œ'), 261),\n",
       " (('ğŸ˜', 'ğŸ’•'), 249),\n",
       " (('ğŸ˜³', 'ğŸ˜‚'), 233),\n",
       " (('ğŸ˜˜', 'ğŸ’•'), 233),\n",
       " (('ğŸ‰', 'ğŸˆ'), 218),\n",
       " (('ğŸ˜', 'ğŸ˜­'), 216),\n",
       " (('ğŸ˜­', 'ğŸ˜©'), 206),\n",
       " (('ğŸ˜', 'ğŸ‘Œ'), 203),\n",
       " (('ğŸ˜­', 'ğŸ˜'), 203),\n",
       " (('ğŸ’›', 'ğŸ’š'), 196),\n",
       " (('ğŸ’™', 'ğŸ’›'), 188),\n",
       " (('ğŸŠ', 'ğŸ‰'), 185),\n",
       " (('ğŸ˜©', 'ğŸ˜‚'), 178),\n",
       " (('ğŸ˜', 'ğŸ™Œ'), 176),\n",
       " (('ğŸ˜', 'ğŸ˜‚'), 174),\n",
       " (('ğŸ˜­', 'ğŸ’”'), 174),\n",
       " (('ğŸ’›', 'â¤'), 170),\n",
       " (('ğŸ˜­', 'â¤'), 170),\n",
       " (('ğŸ˜Š', 'ğŸ˜˜'), 164),\n",
       " (('â¤', 'ğŸ˜˜'), 162),\n",
       " (('ğŸ’›', 'ğŸ’™'), 159),\n",
       " (('â™¡', 'â™¥'), 155),\n",
       " (('ğŸ˜«', 'ğŸ˜­'), 154),\n",
       " (('ğŸ˜‚', 'ğŸ˜˜'), 154),\n",
       " (('â¤', 'ğŸ’›'), 152),\n",
       " (('ğŸ˜Š', 'â¤'), 152),\n",
       " (('ğŸ‰', 'ğŸ'), 150),\n",
       " (('ğŸ˜‚', 'ğŸ˜©'), 147),\n",
       " (('ğŸ˜', 'ğŸ˜‹'), 147),\n",
       " (('ğŸ˜', 'â˜º'), 146),\n",
       " (('ğŸ˜‚', 'ğŸ˜'), 143),\n",
       " (('ğŸ‘Š', 'ğŸ’¢'), 143),\n",
       " (('ğŸƒ', 'ğŸ‚'), 142),\n",
       " (('ğŸ™', 'ğŸ™Œ'), 140),\n",
       " (('ğŸ˜©', 'ğŸ˜«'), 140),\n",
       " (('ğŸ˜Š', 'ğŸ‘Œ'), 138),\n",
       " (('ğŸ‘', 'ğŸ‘Œ'), 135),\n",
       " (('ğŸ‘Œ', 'ğŸ‘'), 129),\n",
       " (('â™¥', 'â™¡'), 129),\n",
       " (('ğŸ˜Š', 'â˜º'), 129),\n",
       " (('ğŸ˜‚', 'ğŸ˜'), 127),\n",
       " (('ğŸ˜', 'ğŸ˜˜'), 124),\n",
       " (('ğŸ™Œ', 'ğŸ™'), 121),\n",
       " (('ğŸ‘Œ', 'ğŸ˜‚'), 117),\n",
       " (('ğŸ’•', 'ğŸ˜˜'), 115),\n",
       " (('ğŸ˜Š', 'ğŸ’•'), 114),\n",
       " (('ğŸ˜Œ', 'ğŸ‘Œ'), 111),\n",
       " (('ğŸ˜‚', 'â¤'), 110),\n",
       " (('ğŸ˜³', 'ğŸ˜'), 108),\n",
       " (('ğŸ˜', 'ğŸ˜‚'), 107),\n",
       " (('ğŸ˜­', 'ğŸ’•'), 106),\n",
       " (('ğŸ', 'ğŸ‰'), 106),\n",
       " (('ğŸ‘Œ', 'ğŸ˜'), 106),\n",
       " (('ğŸ’™', 'â¤'), 105),\n",
       " (('ğŸ˜', 'ğŸ‘Œ'), 104),\n",
       " (('ğŸ‘Œ', 'ğŸ˜'), 104),\n",
       " (('ğŸ˜’', 'ğŸ˜‚'), 104),\n",
       " (('â¤', 'ğŸ˜'), 103),\n",
       " (('ğŸ™Œ', 'ğŸ˜'), 102),\n",
       " (('ğŸ‘»', 'ğŸƒ'), 101),\n",
       " (('ğŸ™Œ', 'ğŸ‘Œ'), 101),\n",
       " (('ğŸŠ', 'ğŸˆ'), 100),\n",
       " (('ğŸ˜¡', 'ğŸ˜¤'), 100),\n",
       " (('ğŸ’™', 'ğŸ’œ'), 97),\n",
       " (('ğŸˆ', 'ğŸ‰'), 97),\n",
       " (('ğŸ˜', 'ğŸ˜'), 96),\n",
       " (('ğŸ˜‚', 'ğŸ™Œ'), 96),\n",
       " (('ğŸ‘', 'ğŸ‘Œ'), 95),\n",
       " (('ğŸ˜‚', 'âœ‹'), 94),\n",
       " (('ğŸ˜‰', 'ğŸ˜˜'), 94),\n",
       " (('ğŸ˜', 'ğŸ˜‰'), 94),\n",
       " (('ğŸ‘', 'ğŸ™Œ'), 93),\n",
       " (('ğŸ˜’', 'ğŸ˜”'), 93),\n",
       " (('ğŸ˜”', 'ğŸ’”'), 93),\n",
       " (('ğŸ˜­', 'ğŸ˜«'), 93),\n",
       " (('ğŸ˜´', 'ğŸ’¤'), 92),\n",
       " (('ğŸ‚', 'ğŸƒ'), 92),\n",
       " (('â˜º', 'ğŸ˜˜'), 92),\n",
       " (('ğŸ”', 'ğŸŸ'), 92),\n",
       " (('ğŸ§', 'ğŸ¶'), 91),\n",
       " (('ğŸ‘…', 'ğŸ’¦'), 90),\n",
       " (('ğŸ™ˆ', 'ğŸ™‰'), 90),\n",
       " (('ğŸ‘Œ', 'â¤'), 90),\n",
       " (('ğŸ™ˆ', 'ğŸ™Š'), 90),\n",
       " (('ğŸ‘', 'ğŸ˜‚'), 89),\n",
       " (('ğŸ', 'ğŸ‚'), 88),\n",
       " (('ğŸ’›', 'ğŸˆ'), 87),\n",
       " (('ğŸ‚', 'ğŸ'), 87)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams(bigram_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hdl  hey checkout the website:  url   hdl  ğŸ˜ª i laugh a lot with that line sons of anarchy is back o'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_joined = \" \".join(tweet_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "def collocation_bigrams(text):    \n",
    "    finder = BigramCollocationFinder.from_words(text)\n",
    "    finder.apply_freq_filter(9)\n",
    "    bigram_coll = (finder.nbest(bigram_measures.pmi, 500))\n",
    "    return bigram_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collocation_bigrams = collocation_bigrams(text_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ğŸŒ–', 'ğŸŒ—'),\n",
       " ('ğŸŒ’', 'ğŸŒ“'),\n",
       " ('ğŸŒ—', 'ğŸŒ˜'),\n",
       " ('ğŸŒ“', 'ğŸŒ”'),\n",
       " ('ğŸ’·', 'ğŸ’¶'),\n",
       " ('ğŸŒ', 'ğŸŒ'),\n",
       " ('ğŸš‹', 'ğŸš‹'),\n",
       " ('ğŸ”»', 'ğŸ”º'),\n",
       " ('ğŸ”º', 'ğŸ”»'),\n",
       " ('ğŸ', 'ğŸ'),\n",
       " ('ğŸŒ‘', 'ğŸŒ’'),\n",
       " ('ğŸš©', 'ğŸš©'),\n",
       " ('ğŸŒ•', 'ğŸŒ–'),\n",
       " ('â•', 'â•'),\n",
       " ('ğŸˆ', 'ğŸˆ'),\n",
       " ('ğŸ“¢', 'ğŸ“¢'),\n",
       " ('ğŸ™', 'ğŸ˜'),\n",
       " ('ğŸ¡', 'ğŸ '),\n",
       " ('ğŸ“¦', 'ğŸ“¦'),\n",
       " ('ğŸ’ˆ', 'ğŸ’ˆ'),\n",
       " ('ğŸŒ”', 'ğŸŒ•'),\n",
       " ('ğŸ’º', 'ğŸ’º'),\n",
       " ('ğŸ¯', 'ğŸ¯'),\n",
       " ('ğŸ–', 'ğŸ–'),\n",
       " ('ğŸœ', 'ğŸœ'),\n",
       " ('ğŸ²', 'ğŸ¢'),\n",
       " ('âšª', 'âšª'),\n",
       " ('ğŸ”•', 'ğŸ”•'),\n",
       " ('ğŸ¹', 'ğŸ¹'),\n",
       " ('ğŸš½', 'ğŸš½'),\n",
       " ('ğŸ‘', 'ğŸ‘'),\n",
       " ('ğŸ””', 'ğŸ””'),\n",
       " ('ğŸ”´', 'ğŸ”µ'),\n",
       " ('ğŸ”¶', 'ğŸ”·'),\n",
       " ('ğŸ…', 'ğŸ„'),\n",
       " ('ğŸ…', 'ğŸŒ½'),\n",
       " ('ğŸ”µ', 'ğŸ”´'),\n",
       " ('â“', 'â“'),\n",
       " ('ğŸ¼', 'ğŸ¼'),\n",
       " ('ğŸ”', 'ğŸ”'),\n",
       " ('ğŸš“', 'ğŸš”'),\n",
       " ('ğŸ¼', 'ğŸ¼'),\n",
       " ('ğŸ', 'ğŸ'),\n",
       " ('ğŸ—', 'ğŸ–'),\n",
       " ('ğŸ¢', 'ğŸ¢'),\n",
       " ('ğŸ¸', 'ğŸ¸'),\n",
       " ('ğŸ‹', 'ğŸ‹'),\n",
       " ('ğŸ“²', 'ğŸ“²'),\n",
       " ('ğŸµ', 'ğŸµ'),\n",
       " ('ğŸ½', 'ğŸ½'),\n",
       " ('ğŸ', 'ğŸ'),\n",
       " ('ğŸ”’', 'ğŸ”’'),\n",
       " ('ğŸš£', 'ğŸš£'),\n",
       " ('ğŸš”', 'ğŸš¨'),\n",
       " ('ğŸ‘£', 'ğŸ‘£'),\n",
       " ('ğŸ““', 'ğŸ““'),\n",
       " ('ğŸ', 'ğŸŠ'),\n",
       " ('âŒ', 'âŒ'),\n",
       " ('ğŸ‘Ÿ', 'ğŸ‘'),\n",
       " ('ğŸ‘', 'ğŸ‘Ÿ'),\n",
       " ('ğŸ±', 'ğŸ£'),\n",
       " ('ğŸ‘¾', 'ğŸ‘¾'),\n",
       " ('ğŸ­', 'ğŸ¬'),\n",
       " ('ğŸ‰', 'ğŸ‰'),\n",
       " ('ğŸ‘‡', 'ğŸ‘‡'),\n",
       " ('ğŸ ', 'ğŸŸ'),\n",
       " ('ğŸ”¶', 'âš«'),\n",
       " ('ğŸ¤', 'ğŸ¤'),\n",
       " ('ğŸ„', 'ğŸ…'),\n",
       " ('ğŸ“', 'ğŸ“'),\n",
       " ('ğŸ', 'ğŸ'),\n",
       " ('ğŸµ', 'ğŸ’'),\n",
       " ('ğŸš¿', 'ğŸš¿'),\n",
       " ('ğŸ', 'ğŸ'),\n",
       " ('ğŸ¢', 'ğŸ¡'),\n",
       " ('ğŸ°', 'ğŸ°'),\n",
       " ('âš ', 'âš '),\n",
       " ('ğŸŒŒ', 'ğŸŒ '),\n",
       " ('ğŸ£', 'ğŸ™'),\n",
       " ('ğŸ’²', 'ğŸ’²'),\n",
       " ('ğŸ¢', 'ğŸ¢'),\n",
       " ('ğŸ’', 'ğŸµ'),\n",
       " ('ğŸ‘²', 'ğŸ‘²'),\n",
       " ('ğŸ‘´', 'ğŸ‘µ'),\n",
       " ('ğŸ€', 'ğŸ€'),\n",
       " ('ğŸ', 'ğŸ›'),\n",
       " ('ğŸŒ¿', 'ğŸŒ¿'),\n",
       " ('ğŸ§', 'ğŸ¨'),\n",
       " ('ğŸ¨', 'ğŸ§'),\n",
       " ('ğŸ«', 'ğŸ«'),\n",
       " ('ğŸ™', 'ğŸ™'),\n",
       " ('ğŸ¾', 'ğŸ¾'),\n",
       " ('ğŸ–', 'ğŸ'),\n",
       " ('ğŸ„', 'ğŸ„'),\n",
       " ('â™ª', 'â™ª'),\n",
       " ('ğŸ†', 'ğŸ†'),\n",
       " ('ğŸ¬', 'ğŸ¬'),\n",
       " ('ğŸ£', 'ğŸ±'),\n",
       " ('ğŸ¬', 'ğŸ­'),\n",
       " ('ğŸ‘°', 'ğŸ©'),\n",
       " ('ğŸŒ', 'ğŸŒ'),\n",
       " ('ğŸ¡', 'ğŸ¢'),\n",
       " ('ğŸ“º', 'ğŸ“º'),\n",
       " ('ğŸ’§', 'ğŸ’§'),\n",
       " ('ğŸ·', 'ğŸ½'),\n",
       " ('ğŸ›', 'ğŸ¤'),\n",
       " ('ğŸš¨', 'ğŸš“'),\n",
       " ('ğŸ”', 'ğŸŸ'),\n",
       " ('ğŸ”®', 'ğŸ”®'),\n",
       " ('ğŸ’µ', 'ğŸ’·'),\n",
       " ('â˜†', 'â˜†'),\n",
       " ('ğŸ³', 'ğŸ'),\n",
       " ('â˜…', 'â˜…'),\n",
       " ('â›½', 'â›½'),\n",
       " ('ğŸ˜', 'ğŸ˜'),\n",
       " ('ğŸª', 'ğŸª'),\n",
       " ('ğŸ‘³', 'ğŸ‘³'),\n",
       " ('ğŸ†', 'ğŸ…'),\n",
       " ('ğŸ‘†', 'ğŸ‘†'),\n",
       " ('ğŸ‘¹', 'ğŸ‘¹'),\n",
       " ('ğŸ”´', 'ğŸ”´'),\n",
       " ('ğŸš—', 'ğŸš•'),\n",
       " ('ğŸš“', 'ğŸš“'),\n",
       " ('ğŸš¨', 'ğŸš¨'),\n",
       " ('ğŸ³', 'ğŸ‹'),\n",
       " ('ğŸŒµ', 'ğŸŒµ'),\n",
       " ('ğŸ“š', 'ğŸ“–'),\n",
       " ('ğŸ’´', 'ğŸ’µ'),\n",
       " ('ğŸŒˆ', 'ğŸŒˆ'),\n",
       " ('ğŸ’', 'ğŸ‡'),\n",
       " ('ğŸ©', 'ğŸ©'),\n",
       " ('ğŸ˜º', 'ğŸ˜º'),\n",
       " ('ğŸ‘ˆ', 'ğŸ‘ˆ'),\n",
       " ('ğŸ©', 'ğŸ©'),\n",
       " ('ğŸš“', 'ğŸš¨'),\n",
       " ('âœ', 'ğŸ““'),\n",
       " ('ğŸ‡', 'ğŸ‡'),\n",
       " ('ğŸ„', 'ğŸ„'),\n",
       " ('ğŸ´', 'ğŸ´'),\n",
       " ('ğŸ‘—', 'ğŸ‘ '),\n",
       " ('ğŸ“', 'ğŸ‘'),\n",
       " ('ğŸŒ¼', 'ğŸŒ¼'),\n",
       " ('ğŸ‡', 'ğŸ‰')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pair for pair in collocation_bigrams if is_emoji(pair[0]) == 1 and is_emoji(pair[1]) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Future Work:\n",
    "- look at unigram, bigram, collocations for 1) all text, 2) just text, 3) just emojis, 4) just faces\n",
    "- POS tag and pull out nouns, adjectives, and verbs\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Clean Non-English Language"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
