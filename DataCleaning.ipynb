{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning steps:\n",
    "- replace @ handles with: hdl (chose a word with no punctuation so no extra step is needed to process, hdl = handle)\n",
    "- replace urls by: url\n",
    "- replace emoticons with corresponding emojis\n",
    "\n",
    "\n",
    "For all of these, first check what is the prevalence and if it is worth the effort. \n",
    "\n",
    "Ideas:\n",
    "- split hashtags into words\n",
    "    - Some people seperate words in hashtags with capitals. Make it much easier to seperate. \n",
    "- replace contractions\n",
    "- spellchecking\n",
    "- what does quoted messages mean? Someone quoting somebody else? Should we consider this text or remove it? \n",
    "- there are some smileys that are still in punctuation and not in unicode, eg :-P, :-)\n",
    "- Tweets not in english\n",
    "- Character ngram will probably be more efficient due to the really low quality of speach\n",
    "- Retweets have two formats:\n",
    "    - Either finish with RT &lt;content of retweet>\n",
    "    - OR \"&lt;content of retweet>\" &lt;content of tweet>\n",
    "    - Can also have mutliple embedings with â€œ for second level. E.g. : \n",
    "\"@letwerkaaaaa: â€œ@Palmira_0: HAHA WHEN I WAS LITTLE I WAS FAT AS FUCK:joy:â€ Same I was so fat that they thought my vagina was a dick\" LMFAO\n",
    "    - For now will leave them here. We might have to consider while training if it is retweeted content or original content. Actually impacts the single response rate, ie when people just add an emoji to a tweet (as in the emoji is the sole content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 140\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/tweets_training.json','r') as f:\n",
    "    tweets_df = pd.DataFrame(json.load(f))\n",
    "clean_tweets_df = pd.DataFrame(tweets_df[\"text\"])\n",
    "# del tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace @ handles with hdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No \"hdl\" words for confusion in the txt. Good replacement name. \n",
    "\n",
    "Best to replace handles with \"\\ hdl\\ \", so for tokenization it will be easier to identify as a word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293672 handles replaced\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676076</th>\n",
       "      <td>hdl  I forgot to tell you I can't do it because I have soccer practice ğŸ˜¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794937</th>\n",
       "      <td>I love the song Junk By Paul MCCartney ! Its so nice !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691481</th>\n",
       "      <td>hdl  yes just let me know when you can!! Love you! ğŸ˜˜ğŸ˜˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249271</th>\n",
       "      <td>I'm at Hillsdale Caltrain Station -  hdl  (San Mateo, CA) http://t.co/vKAJdDqPLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747414</th>\n",
       "      <td>hdl  I died at this tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112751</th>\n",
       "      <td>hdl   hdl   hdl  The great thing is that the stuff the Pokemon &amp;amp; Sonic fanbases come up with makes that look sane and tasteful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184431</th>\n",
       "      <td>500 words now time for a snack break and bathroom break lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540456</th>\n",
       "      <td>I'm not feeling that white smoke tho , we should of had black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207285</th>\n",
       "      <td>If only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53473</th>\n",
       "      <td>Sharks player was giving me an autograph after the game and told me I was wearing the wrong team's jersey. Go  hdl !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                        text\n",
       "676076                                                              hdl  I forgot to tell you I can't do it because I have soccer practice ğŸ˜¨\n",
       "794937                                                                                I love the song Junk By Paul MCCartney ! Its so nice !\n",
       "691481                                                                                 hdl  yes just let me know when you can!! Love you! ğŸ˜˜ğŸ˜˜\n",
       "249271                                                      I'm at Hillsdale Caltrain Station -  hdl  (San Mateo, CA) http://t.co/vKAJdDqPLY\n",
       "747414                                                                                                             hdl  I died at this tweet\n",
       "112751   hdl   hdl   hdl  The great thing is that the stuff the Pokemon &amp; Sonic fanbases come up with makes that look sane and tasteful.\n",
       "184431                                                                           500 words now time for a snack break and bathroom break lol\n",
       "540456                                                                         I'm not feeling that white smoke tho , we should of had black\n",
       "207285                                                                                                                               If only\n",
       "53473                   Sharks player was giving me an autograph after the game and told me I was wearing the wrong team's jersey. Go  hdl !"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"@[a-zA-Z0-9_]{1,15}\" #from http://kagan.mactane.org/blog/2009/09/22/what-characters-are-allowed-in-twitter-usernames/\n",
    "print(\"{} handles replaced\".format(np.sum(clean_tweets_df.text.str.contains(pattern).values)))\n",
    "clean_tweets_df.text = clean_tweets_df.text.str.replace(pattern, \" hdl \")\n",
    "clean_tweets_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace URLs with url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URLs are quiet well formed and are generally at the end of tweets. No risk of engulfing in the cleaning some more text after the url.\n",
    "\n",
    "keyword url is used only 4 times in dataset, no risk of confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182254 urls replaced\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>591190</th>\n",
       "      <td>But idgaf lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589389</th>\n",
       "      <td>The dumb stuff we do after studying in the library for 3 hours. @ J. Paul L. Library  url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741933</th>\n",
       "      <td>hdl   hdl  I'm on it!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348670</th>\n",
       "      <td>I needa brush up on my math skills.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205760</th>\n",
       "      <td>After years of getting bugged into making an Instagram, I finally made one ahahah. Follow me GioC415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727679</th>\n",
       "      <td>I just woke Taylor up just to tell her we're going to BWW tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761952</th>\n",
       "      <td>Yeah me and Julissa skip class to come to valley fair because YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161563</th>\n",
       "      <td>hdl  preordered it the second it was available, even tho I was in class ^.^  url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68202</th>\n",
       "      <td>Girls varsity water polo at the half SF 7-VC 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735805</th>\n",
       "      <td>I'm at San Francisco, CA (San Francisco, CA) w/ 5 others  url</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        text\n",
       "591190                                                                                         But idgaf lol\n",
       "589389            The dumb stuff we do after studying in the library for 3 hours. @ J. Paul L. Library  url \n",
       "741933                                                                                 hdl   hdl  I'm on it!\n",
       "348670                                                                   I needa brush up on my math skills.\n",
       "205760  After years of getting bugged into making an Instagram, I finally made one ahahah. Follow me GioC415\n",
       "727679                                     I just woke Taylor up just to tell her we're going to BWW tonight\n",
       "761952                                    Yeah me and Julissa skip class to come to valley fair because YOLO\n",
       "161563                     hdl  preordered it the second it was available, even tho I was in class ^.^  url \n",
       "68202                                                         Girls varsity water polo at the half SF 7-VC 3\n",
       "735805                                        I'm at San Francisco, CA (San Francisco, CA) w/ 5 others  url "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"http://\\S+\"\n",
    "print(\"{} urls replaced\".format(np.sum(clean_tweets_df.text.str.contains(pattern).values)))\n",
    "clean_tweets_df.text = clean_tweets_df.text.str.replace(pattern, \" url \")\n",
    "clean_tweets_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert emoticons to emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Based on:\n",
    "# https://slack.zendesk.com/hc/en-us/articles/202931348-Emoji-and-emoticons\n",
    "# http://unicodey.com/emoji-data/table.htm\n",
    "# http://www.unicode.org/emoji/charts/emoji-list.html\n",
    "\n",
    "emoticon2emoji = {\n",
    "    r\"<3\": \"\\u2764\",\n",
    "    r\"</3\": \"\\U0001F494\",\n",
    "    r\"8\\)\": \"\\U0001F60E\",\n",
    "    r\"D:\": \"\\U0001F627\",\n",
    "    r\":'\\(\": \"\\U0001F622\",\n",
    "    r\":o\\)\": \"\\U0001F435\",\n",
    "    r\":-*\\*\": \"\\U0001F48B\",\n",
    "    r\"=-*\\)\": \"\\U0001F600\",\n",
    "    r\":-*D\": \"\\U0001F600\",\n",
    "    r\";-*\\)\": \"\\U0001F609\",\n",
    "    r\":-*>\": \"\\U0001F606\",\n",
    "    r\":-*\\|\": \"\\U0001F610\",\n",
    "    r\":-*[Oo]\": \"\\U0001F62E\",\n",
    "    r\">:-*\\(\": \"\\U0001F620\",\n",
    "    r\":-*\\)|\\(:\": \"\\U0001F603\",\n",
    "    r\":-*\\(|\\):\": \"\\U0001F61E\",\n",
    "    r\":-*[/\\\\]\": \"\\U0001F615\",\n",
    "    r\":-*[PpbB]\": \"\\U0001F61B\",\n",
    "    r\";-*[PpbB]\": \"\\U0001F61C\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":'\\(       ->     ğŸ˜¢\n",
      ":-*\\*      ->     ğŸ’‹\n",
      ":-*D       ->     ğŸ˜€\n",
      ";-*\\)      ->     ğŸ˜‰\n",
      ":-*\\)|\\(:  ->     ğŸ˜ƒ\n",
      "D:         ->     ğŸ˜§\n",
      ":-*[PpbB]  ->     ğŸ˜›\n",
      ":-*[Oo]    ->     ğŸ˜®\n",
      ">:-*\\(     ->     ğŸ˜ \n",
      "<3         ->     â¤\n",
      "8\\)        ->     ğŸ˜\n",
      ":-*\\|      ->     ğŸ˜\n",
      "</3        ->     ğŸ’”\n",
      ":-*[/\\\\]   ->     ğŸ˜•\n",
      ";-*[PpbB]  ->     ğŸ˜œ\n",
      ":o\\)       ->     ğŸµ\n",
      ":-*\\(|\\):  ->     ğŸ˜\n",
      ":-*>       ->     ğŸ˜†\n",
      "=-*\\)      ->     ğŸ˜€\n"
     ]
    }
   ],
   "source": [
    "for emoticon in emoticon2emoji:\n",
    "    print(\"{:10} -> {:>5}\".format(emoticon, emoticon2emoji[emoticon]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜¢   replaced    264 times\n",
      "ğŸ’‹   replaced    236 times\n",
      "ğŸ˜€   replaced   1221 times\n",
      "ğŸ˜‰   replaced   2689 times\n",
      "ğŸ˜ƒ   replaced  12555 times\n",
      "ğŸ˜§   replaced    161 times\n",
      "ğŸ˜›   replaced    961 times\n",
      "ğŸ˜®   replaced    295 times\n",
      "ğŸ˜    replaced      0 times\n",
      "â¤   replaced      0 times\n",
      "ğŸ˜   replaced     84 times\n",
      "ğŸ˜   replaced     70 times\n",
      "ğŸ’”   replaced      0 times\n",
      "ğŸ˜•   replaced   5939 times\n",
      "ğŸ˜œ   replaced    263 times\n",
      "ğŸµ   replaced      0 times\n",
      "ğŸ˜   replaced   4557 times\n",
      "ğŸ˜†   replaced      0 times\n",
      "ğŸ˜€   replaced    176 times\n",
      "ALL replaced 29471 times\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for emoticon in emoticon2emoji:\n",
    "    nreplacements = np.sum(clean_tweets_df.text.str.contains(emoticon).values)\n",
    "    total += nreplacements\n",
    "    print(\"{:3} replaced {:6} times\".format(emoticon2emoji[emoticon], nreplacements))\n",
    "    clean_tweets_df.text = clean_tweets_df.text.str.replace(emoticon, emoticon2emoji[emoticon])\n",
    "print(\"{:3} replaced {} times\".format(\"ALL\", total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40126 retweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518928</th>\n",
       "      <td>ğŸ˜â€œ hdl : PERFECT!!!  url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711525</th>\n",
       "      <td>RT  hdl : Crochet Storage Basket Pattern: Free and Easy  url  via  hdl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273890</th>\n",
       "      <td>LIFE RT  hdl : Gator bootsğŸ‘¢ with a pimped out Gucci suitğŸ‘” ain't got no jawbğŸ’¼, but I stay sharpğŸ”ª #StillFly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486359</th>\n",
       "      <td>\" hdl : â€œ hdl : CONCORD!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!â€ Yeeeeeee\" is full of RAIDER FANS, CUHZ THEY KNO WSSUP!! OAKLAND!!!!! Cuhah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205832</th>\n",
       "      <td>â€œ hdl : I love how LAURA MARAVILLA can tweet but not replyâ€ ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97106</th>\n",
       "      <td>Lmao at Melos RT rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606491</th>\n",
       "      <td>â€œ hdl : I fainted upon entry to the new pink store.â€ It's time for an intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509515</th>\n",
       "      <td>!! ğŸ’ƒRT  hdl  The amount of time I've spent discussing the Phillip Lim for Target collection with  hdl  is sick.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468119</th>\n",
       "      <td>â€œ hdl : I was welcomed home by the best!ğŸ’œ Î‘Î¦ #latepost #lovemynewhome  url  you're the cutest ğŸ˜˜ AOE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727469</th>\n",
       "      <td>\" hdl : #InitialsOfSomeoneSpecial ..  url \\nSO Fucking true amen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       text\n",
       "518928                                                                                                            ğŸ˜â€œ hdl : PERFECT!!!  url \n",
       "711525                                                              RT  hdl : Crochet Storage Basket Pattern: Free and Easy  url  via  hdl \n",
       "273890                            LIFE RT  hdl : Gator bootsğŸ‘¢ with a pimped out Gucci suitğŸ‘” ain't got no jawbğŸ’¼, but I stay sharpğŸ”ª #StillFly\n",
       "486359  \" hdl : â€œ hdl : CONCORD!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!â€ Yeeeeeee\" is full of RAIDER FANS, CUHZ THEY KNO WSSUP!! OAKLAND!!!!! Cuhah\n",
       "205832                                                                 â€œ hdl : I love how LAURA MARAVILLA can tweet but not replyâ€ ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
       "97106                                                                                                                   Lmao at Melos RT rn\n",
       "606491                                                   â€œ hdl : I fainted upon entry to the new pink store.â€ It's time for an intervention\n",
       "509515                      !! ğŸ’ƒRT  hdl  The amount of time I've spent discussing the Phillip Lim for Target collection with  hdl  is sick.\n",
       "468119                                  â€œ hdl : I was welcomed home by the best!ğŸ’œ Î‘Î¦ #latepost #lovemynewhome  url  you're the cutest ğŸ˜˜ AOE\n",
       "727469                                                                     \" hdl : #InitialsOfSomeoneSpecial ..  url \\nSO Fucking true amen"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"\"\"(?:\\W|^)RT(?:[ \\\":â€œ]|$)| # Retweets with RT keyword\n",
    "            [\\\"â€œ]\\s*hdl                # Retweets with quotes\"\"\"\n",
    "temp = clean_tweets_df.text.str.contains(pattern, flags=re.X)\n",
    "print(\"There are {} retweets\".format(np.sum(temp.values)))\n",
    "clean_tweets_df[temp].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Twitter hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
