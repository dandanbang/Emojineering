{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning steps:\n",
    "- replace @ handles with: hdl (chose a word with no punctuation so no extra step is needed to process, hdl = handle)\n",
    "- replace urls by: url\n",
    "- replace emoticons with corresponding emojis\n",
    "\n",
    "\n",
    "For all of these, first check what is the prevalence and if it is worth the effort. \n",
    "\n",
    "Ideas:\n",
    "- split hashtags into words\n",
    "    - Some people seperate words in hashtags with capitals. Make it much easier to seperate. \n",
    "- replace contractions\n",
    "- spellchecking\n",
    "- what does quoted messages mean? Someone quoting somebody else? Should we consider this text or remove it? \n",
    "- there are some smileys that are still in punctuation and not in unicode, eg :-P, :-)\n",
    "- Tweets not in english\n",
    "- Character ngram will probably be more efficient due to the really low quality of speach\n",
    "- Retweets have two formats:\n",
    "    - Either finish with RT &lt;content of retweet>\n",
    "    - OR \"&lt;content of retweet>\" &lt;content of tweet>\n",
    "    - Can also have mutliple embedings with ‚Äú for second level. E.g. : \n",
    "\"@letwerkaaaaa: ‚Äú@Palmira_0: HAHA WHEN I WAS LITTLE I WAS FAT AS FUCK:joy:‚Äù Same I was so fat that they thought my vagina was a dick\" LMFAO\n",
    "    - For now will leave them here. We might have to consider while training if it is retweeted content or original content. Actually impacts the single response rate, ie when people just add an emoji to a tweet (as in the emoji is the sole content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 140\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/tweets_training.json','r') as f:\n",
    "    tweets_df = pd.DataFrame(json.load(f))\n",
    "clean_tweets_df = pd.DataFrame(tweets_df[\"text\"])\n",
    "# del tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace @ handles with hdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No \"hdl\" words for confusion in the txt. Good replacement name. \n",
    "\n",
    "Best to replace handles with \"\\ hdl\\ \", so for tokenization it will be easier to identify as a word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293672 handles replaced\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478549</th>\n",
       "      <td>Nice use of the round about haha \"Eyewitness video of the #CapitolHill car chase that ended in gunfire: http://t.co/LbNO5PAeo1\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215754</th>\n",
       "      <td>Oh my shit  hdl  ... Goodbye Goodbye video is... Omg. Unf. Perf. Isisksnsjosidka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30306</th>\n",
       "      <td>I just saw it :/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342311</th>\n",
       "      <td>Closing apps in the new iOS is super neat!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358082</th>\n",
       "      <td>I'm never gonna change , I'll always be right there üíõ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341272</th>\n",
       "      <td>All the move in signs are up... I guess it's that time of year again. #ucsc  hdl  #bananaslugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167839</th>\n",
       "      <td>Game time #FightOn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452020</th>\n",
       "      <td>hdl  thankyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287165</th>\n",
       "      <td>Attending the service experience conference from  hdl  (@ Omni San Francisco Hotel -  hdl ) [pic]: http://t.co/fIR1FIEHM6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123900</th>\n",
       "      <td>RIDE OR DIE #N.E. #Noevidence #Bear-Chi #DameSmash #E-Time #Cheddar #Hollywood #2-TAll #G-Money #RY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                   text\n",
       "478549  Nice use of the round about haha \"Eyewitness video of the #CapitolHill car chase that ended in gunfire: http://t.co/LbNO5PAeo1\"\n",
       "215754                                                 Oh my shit  hdl  ... Goodbye Goodbye video is... Omg. Unf. Perf. Isisksnsjosidka\n",
       "30306                                                                                                                  I just saw it :/\n",
       "342311                                                                                       Closing apps in the new iOS is super neat!\n",
       "358082                                                                            I'm never gonna change , I'll always be right there üíõ\n",
       "341272                                   All the move in signs are up... I guess it's that time of year again. #ucsc  hdl  #bananaslugs\n",
       "167839                                                                                                               Game time #FightOn\n",
       "452020                                                                                                                    hdl  thankyou\n",
       "287165        Attending the service experience conference from  hdl  (@ Omni San Francisco Hotel -  hdl ) [pic]: http://t.co/fIR1FIEHM6\n",
       "123900                              RIDE OR DIE #N.E. #Noevidence #Bear-Chi #DameSmash #E-Time #Cheddar #Hollywood #2-TAll #G-Money #RY"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanHandle(df):\n",
    "    \"\"\" Replace in-place handles with hdl keyword\n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    pattern = r\"@[a-zA-Z0-9_]{1,15}\" #from http://kagan.mactane.org/blog/2009/09/22/what-characters-are-allowed-in-twitter-usernames/\n",
    "    print(\"{} handles replaced\".format(np.sum(df.text.str.contains(pattern).values)))\n",
    "    df.text = df.text.str.replace(pattern, \" hdl \")\n",
    "    return\n",
    "\n",
    "cleanHandle(clean_tweets_df)\n",
    "clean_tweets_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace URLs with url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URLs are quiet well formed and are generally at the end of tweets. No risk of engulfing in the cleaning some more text after the url.\n",
    "\n",
    "keyword url is used only 4 times in dataset, no risk of confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182254 urls replaced\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294459</th>\n",
       "      <td>I'm hella bored at home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653921</th>\n",
       "      <td>It was nice to share today's Tweets now its time to lay down and sleep. May angels sing you all to rest,good night Tweetie pies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489917</th>\n",
       "      <td>Sparkly rainbow fiber optics @ Computer History Museum  url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689649</th>\n",
       "      <td>Dayger ready \\n#JelloShots  url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770700</th>\n",
       "      <td>üòÇüòÇ Odaly and Kaylind are hilarious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453521</th>\n",
       "      <td>hdl  wat lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786294</th>\n",
       "      <td>This is probably the 4th time this week she went to work late. Like, her work etiquette makes me mad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687653</th>\n",
       "      <td>hdl  Jons # is 510 277 2352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388198</th>\n",
       "      <td>hdl  we could eat BK in the shower.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43002</th>\n",
       "      <td>hdl  you saw that too?üò®</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                   text\n",
       "294459                                                                                                          I'm hella bored at home\n",
       "653921  It was nice to share today's Tweets now its time to lay down and sleep. May angels sing you all to rest,good night Tweetie pies\n",
       "489917                                                                     Sparkly rainbow fiber optics @ Computer History Museum  url \n",
       "689649                                                                                                 Dayger ready \\n#JelloShots  url \n",
       "770700                                                                                               üòÇüòÇ Odaly and Kaylind are hilarious\n",
       "453521                                                                                                                     hdl  wat lol\n",
       "786294                            This is probably the 4th time this week she went to work late. Like, her work etiquette makes me mad.\n",
       "687653                                                                                                      hdl  Jons # is 510 277 2352\n",
       "388198                                                                                              hdl  we could eat BK in the shower.\n",
       "43002                                                                                                           hdl  you saw that too?üò®"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanURL(df):\n",
    "    \"\"\" Replace in-place URLs with url keyword\n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    pattern = r\"http://\\S+\"\n",
    "    print(\"{} urls replaced\".format(np.sum(clean_tweets_df.text.str.contains(pattern).values)))\n",
    "    df.text = df.text.str.replace(pattern, \" url \")\n",
    "    return\n",
    "\n",
    "cleanURL(clean_tweets_df)\n",
    "clean_tweets_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert emoticons to emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-*\\)|\\(:  ->     üòÉ replaced      0 times\n",
      ":-*[Oo]    ->     üòÆ replaced      0 times\n",
      ":-*\\(|\\):  ->     üòû replaced      0 times\n",
      ":o\\)       ->     üêµ replaced      0 times\n",
      ":-*[PpbB]  ->     üòõ replaced      0 times\n",
      ";-*\\)      ->     üòâ replaced      0 times\n",
      ":-*\\*      ->     üíã replaced      0 times\n",
      ":'\\(       ->     üò¢ replaced      0 times\n",
      ":-*D       ->     üòÄ replaced      0 times\n",
      "=-*\\)      ->     üòÄ replaced      0 times\n",
      "8\\)        ->     üòé replaced      0 times\n",
      ";-*[PpbB]  ->     üòú replaced      0 times\n",
      "</3        ->     üíî replaced      0 times\n",
      ":-*>       ->     üòÜ replaced      0 times\n",
      "D:         ->     üòß replaced      0 times\n",
      "<3         ->     ‚ù§ replaced      0 times\n",
      ":-*\\|      ->     üòê replaced      0 times\n",
      ">:-*\\(     ->     üò† replaced      0 times\n",
      ":-*[/\\\\]   ->     üòï replaced      0 times\n",
      "ALL replaced 0 times\n"
     ]
    }
   ],
   "source": [
    "# Based on:\n",
    "# https://slack.zendesk.com/hc/en-us/articles/202931348-Emoji-and-emoticons\n",
    "# http://unicodey.com/emoji-data/table.htm\n",
    "# http://www.unicode.org/emoji/charts/emoji-list.html\n",
    "\n",
    "def convertEmoticon(df):\n",
    "    \"\"\" Replace in-place common emoticons to emojis.\n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    emoticon2emoji = {\n",
    "        r\"<3\": \"\\u2764\",\n",
    "        r\"</3\": \"\\U0001F494\",\n",
    "        r\"8\\)\": \"\\U0001F60E\",\n",
    "        r\"D:\": \"\\U0001F627\",\n",
    "        r\":'\\(\": \"\\U0001F622\",\n",
    "        r\":o\\)\": \"\\U0001F435\",\n",
    "        r\":-*\\*\": \"\\U0001F48B\",\n",
    "        r\"=-*\\)\": \"\\U0001F600\",\n",
    "        r\":-*D\": \"\\U0001F600\",\n",
    "        r\";-*\\)\": \"\\U0001F609\",\n",
    "        r\":-*>\": \"\\U0001F606\",\n",
    "        r\":-*\\|\": \"\\U0001F610\",\n",
    "        r\":-*[Oo]\": \"\\U0001F62E\",\n",
    "        r\">:-*\\(\": \"\\U0001F620\",\n",
    "        r\":-*\\)|\\(:\": \"\\U0001F603\",\n",
    "        r\":-*\\(|\\):\": \"\\U0001F61E\",\n",
    "        r\":-*[/\\\\]\": \"\\U0001F615\",\n",
    "        r\":-*[PpbB]\": \"\\U0001F61B\",\n",
    "        r\";-*[PpbB]\": \"\\U0001F61C\"\n",
    "    }\n",
    "    \n",
    "#     for emoticon in emoticon2emoji:\n",
    "#         print(\"{:10} -> {:>5}\".format(emoticon, emoticon2emoji[emoticon]))\n",
    "    \n",
    "    total = 0\n",
    "    for emoticon in emoticon2emoji:\n",
    "        nreplacements = np.sum(df.text.str.contains(emoticon).values)\n",
    "        total += nreplacements\n",
    "        print(\"{:10} -> {:>5} replaced {:6} times\".format(emoticon, emoticon2emoji[emoticon], nreplacements))\n",
    "        df.text = df.text.str.replace(emoticon, emoticon2emoji[emoticon])\n",
    "    print(\"{:3} replaced {} times\".format(\"ALL\", total))\n",
    "    return\n",
    "\n",
    "convertEmoticon(clean_tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40126 retweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518928</th>\n",
       "      <td>üòç‚Äú hdl : PERFECT!!!  url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711525</th>\n",
       "      <td>RT  hdl : Crochet Storage Basket Pattern: Free and Easy  url  via  hdl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273890</th>\n",
       "      <td>LIFE RT  hdl : Gator bootsüë¢ with a pimped out Gucci suitüëî ain't got no jawbüíº, but I stay sharpüî™ #StillFly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486359</th>\n",
       "      <td>\" hdl : ‚Äú hdl : CONCORD!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!‚Äù Yeeeeeee\" is full of RAIDER FANS, CUHZ THEY KNO WSSUP!! OAKLAND!!!!! Cuhah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205832</th>\n",
       "      <td>‚Äú hdl : I love how LAURA MARAVILLA can tweet but not reply‚Äù üëèüëèüëèüëèüëèüëèüëèüëè</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97106</th>\n",
       "      <td>Lmao at Melos RT rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606491</th>\n",
       "      <td>‚Äú hdl : I fainted upon entry to the new pink store.‚Äù It's time for an intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509515</th>\n",
       "      <td>!! üíÉRT  hdl  The amount of time I've spent discussing the Phillip Lim for Target collection with  hdl  is sick.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468119</th>\n",
       "      <td>‚Äú hdl : I was welcomed home by the best!üíú ŒëŒ¶ #latepost #lovemynewhome  url  you're the cutest üòò AOE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727469</th>\n",
       "      <td>\" hdl : #InitialsOfSomeoneSpecial ..  url \\nSO Fucking true amen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       text\n",
       "518928                                                                                                            üòç‚Äú hdl : PERFECT!!!  url \n",
       "711525                                                              RT  hdl : Crochet Storage Basket Pattern: Free and Easy  url  via  hdl \n",
       "273890                            LIFE RT  hdl : Gator bootsüë¢ with a pimped out Gucci suitüëî ain't got no jawbüíº, but I stay sharpüî™ #StillFly\n",
       "486359  \" hdl : ‚Äú hdl : CONCORD!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!‚Äù Yeeeeeee\" is full of RAIDER FANS, CUHZ THEY KNO WSSUP!! OAKLAND!!!!! Cuhah\n",
       "205832                                                                 ‚Äú hdl : I love how LAURA MARAVILLA can tweet but not reply‚Äù üëèüëèüëèüëèüëèüëèüëèüëè\n",
       "97106                                                                                                                   Lmao at Melos RT rn\n",
       "606491                                                   ‚Äú hdl : I fainted upon entry to the new pink store.‚Äù It's time for an intervention\n",
       "509515                      !! üíÉRT  hdl  The amount of time I've spent discussing the Phillip Lim for Target collection with  hdl  is sick.\n",
       "468119                                  ‚Äú hdl : I was welcomed home by the best!üíú ŒëŒ¶ #latepost #lovemynewhome  url  you're the cutest üòò AOE\n",
       "727469                                                                     \" hdl : #InitialsOfSomeoneSpecial ..  url \\nSO Fucking true amen"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"\"\"(?:\\W|^)RT(?:[ \\\":‚Äú]|$)| # Retweets with RT keyword\n",
    "            [\\\"‚Äú]\\s*hdl                # Retweets with quotes\"\"\"\n",
    "temp = clean_tweets_df.text.str.contains(pattern, flags=re.X)\n",
    "print(\"There are {} retweets\".format(np.sum(temp.values)))\n",
    "clean_tweets_df[temp].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Twitter hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Functions to extract only emoji or only text from input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emojiExtract(sent):\n",
    "    return [word for word in tok.tokenize(sent) if is_emoji(word) == 1]\n",
    "\n",
    "def textExtract(sent):\n",
    "    return [word for word in tok.tokenize(sent) if is_emoji(word) == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Functions to Create Two New Columns [Text Only] & [Emoji Only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textEmojiOnly(df):\n",
    "    df['Emoji'] = [emojiExtract(word) for word in df.text]\n",
    "    df['only_Text'] = [textExtract(word) for word in df.text]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
