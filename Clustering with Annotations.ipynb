{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose \n",
    "\n",
    "The purpose of the notebook is to use annotatoins (and possibly description) of each emoji to intelligently cluster emojis\n",
    "* use webscraping csv file to get dataframe with emoji, annotation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Packages **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import packages work bitch please meow\n",
    "# meow meow\n",
    "# meow\n",
    "import nltk, re\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.data import find\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import data_cleaning_hr as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Function to convert the text file into a list of 1) titles 2) descriptions 3) annotations **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/emoji_webscraped_expanded.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>byteCode</th>\n",
       "      <th>byteCode1</th>\n",
       "      <th>byteCode2</th>\n",
       "      <th>descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[face, grin, person]</td>\n",
       "      <td>U+1F600</td>\n",
       "      <td>\\U0001F600</td>\n",
       "      <td></td>\n",
       "      <td>grinning face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[eye, face, grin, person, smile]</td>\n",
       "      <td>U+1F601</td>\n",
       "      <td>\\U0001F601</td>\n",
       "      <td></td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[bright, cool, eye, eyewear, face, glasses, pe...</td>\n",
       "      <td>U+1F60E</td>\n",
       "      <td>\\U0001F60E</td>\n",
       "      <td></td>\n",
       "      <td>smiling face with sunglasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[gua pi mao, hat, man, person]</td>\n",
       "      <td>U+1F472</td>\n",
       "      <td>\\U0001F472</td>\n",
       "      <td></td>\n",
       "      <td>man with gua pi mao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>[chinese, ideograph, secret, symbol, word]</td>\n",
       "      <td>U+3299</td>\n",
       "      <td>\\U00003299</td>\n",
       "      <td></td>\n",
       "      <td>circled ideograph secret</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            annotations byteCode   byteCode1  \\\n",
       "0                                  [face, grin, person]  U+1F600  \\U0001F600   \n",
       "1                      [eye, face, grin, person, smile]  U+1F601  \\U0001F601   \n",
       "10    [bright, cool, eye, eyewear, face, glasses, pe...  U+1F60E  \\U0001F60E   \n",
       "100                      [gua pi mao, hat, man, person]  U+1F472  \\U0001F472   \n",
       "1000         [chinese, ideograph, secret, symbol, word]   U+3299  \\U00003299   \n",
       "\n",
       "     byteCode2                     descriptions  \n",
       "0                                 grinning face  \n",
       "1               grinning face with smiling eyes  \n",
       "10                 smiling face with sunglasses  \n",
       "100                         man with gua pi mao  \n",
       "1000                   circled ideograph secret  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*keep old script just in case!!!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def convert_scraped_txt(txt):\n",
    "#     with open(\"data/emoji_webscraped_expanded.json\") as f_in:\n",
    "# #     with open(\"emoji_webscraped.txt\") as f_in:\n",
    "#         titles = []\n",
    "#         descriptions = []\n",
    "#         annotations = []\n",
    "#         for line in f_in:\n",
    "#             line = line.strip()\n",
    "#             temp = line.split(\", \")\n",
    "#             titles.append(temp[0])\n",
    "#             descriptions.append(temp[1])\n",
    "#             annotations.append(temp[2:len(temp)])\n",
    "#         return titles, descriptions, annotations\n",
    "\n",
    "# titles, descriptions, annotations = convert_scraped_txt(\"emoji_webscraped.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# d = {'titles' : (titles),\n",
    "#      'annotations' : (annotations),\n",
    "#      'descriptions': (descriptions)}\n",
    "# df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(df.titles.iloc[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# p = re.compile('(\\+)')\n",
    "# df.titles = df.titles.apply(lambda x: p.sub('000', x) if len(x) >= 7 else p.sub('',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df[12:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('\\U0000263A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for item in df.titles:\n",
    "#     print(bytes(\"\\\\{0}\".format(item), 'ascii').decode('unicode-escape'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subset Dataframe to only annotations which either contain face or person**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def subset_annotations(_df):\n",
    "    list_titles = [list(item) for item in list(_df)]\n",
    "    index_face_person = [index for index,value in enumerate(list_titles) if 'face' in value] # or 'person' in value]\n",
    "    # print(len(index_face_person))\n",
    "    df_face_person = df.iloc[index_face_person]\n",
    "    # print(df_face_person.shape)\n",
    "    # df_face_person.head()\n",
    "    return df_face_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_face_person = subset_annotations(df.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>byteCode</th>\n",
       "      <th>byteCode1</th>\n",
       "      <th>byteCode2</th>\n",
       "      <th>descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[face, grin, person]</td>\n",
       "      <td>U+1F600</td>\n",
       "      <td>\\U0001F600</td>\n",
       "      <td></td>\n",
       "      <td>grinning face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[eye, face, grin, person, smile]</td>\n",
       "      <td>U+1F601</td>\n",
       "      <td>\\U0001F601</td>\n",
       "      <td></td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[bright, cool, eye, eyewear, face, glasses, pe...</td>\n",
       "      <td>U+1F60E</td>\n",
       "      <td>\\U0001F60E</td>\n",
       "      <td></td>\n",
       "      <td>smiling face with sunglasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>[aid, cross, face, hat, helmet, person]</td>\n",
       "      <td>U+26D1</td>\n",
       "      <td>\\U000026D1</td>\n",
       "      <td></td>\n",
       "      <td>helmet with white cross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>[angel, baby, face, fairy tale, fantasy, person]</td>\n",
       "      <td>U+1F47C</td>\n",
       "      <td>\\U0001F47C</td>\n",
       "      <td></td>\n",
       "      <td>baby angel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           annotations byteCode   byteCode1  \\\n",
       "0                                 [face, grin, person]  U+1F600  \\U0001F600   \n",
       "1                     [eye, face, grin, person, smile]  U+1F601  \\U0001F601   \n",
       "10   [bright, cool, eye, eyewear, face, glasses, pe...  U+1F60E  \\U0001F60E   \n",
       "103            [aid, cross, face, hat, helmet, person]   U+26D1  \\U000026D1   \n",
       "108   [angel, baby, face, fairy tale, fantasy, person]  U+1F47C  \\U0001F47C   \n",
       "\n",
       "    byteCode2                     descriptions  \n",
       "0                                grinning face  \n",
       "1              grinning face with smiling eyes  \n",
       "10                smiling face with sunglasses  \n",
       "103                    helmet with white cross  \n",
       "108                                 baby angel  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_face_person.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** return list of all annotations and the fifty top annotations **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_list(annotations, _common=100):\n",
    "    stop_words = stopwords.words('english')\n",
    "    total_list = [word for item in list(annotations) for word in item if word not in stop_words]\n",
    "    top_list = nltk.FreqDist(total_list).most_common(_common)\n",
    "    return total_list, top_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_list, top_list = word_list(df_face_person.annotations, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total_list[:10], top_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** return list of fifty top words without frequency rate **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_justwords(top_list):\n",
    "    top_words = [item[0] for item in top_list]\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_justwords = top_justwords(top_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(columns=top_justwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "top_justwords_array = [(top_justwords) for i in range(df_face_person.shape[0])]\n",
    "# df_face_person['top_words'] = 1\n",
    "df_face_person['top_words'] = pd.Series(top_justwords_array, index=df_face_person.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_face_person.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(121, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# something = [list(pd.Series(item).isin(df_face_person.annotations)) for item in df_face_person.top_words]\n",
    "\n",
    "df_face_person['top_binary'] = [list(pd.Series(item).isin(list(df_face_person.annotations)[index])) for index, item in enumerate(df_face_person.top_words)]\n",
    "df_face_person = df_face_person.reset_index(drop=True)\n",
    "df_face_person.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 50)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features = list(df_face_person.top_binary)\n",
    "\n",
    "df_features = pd.DataFrame(data_features, columns=top_justwords)\n",
    "df_features = df_features.astype(int)\n",
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_face_person, df_features], axis=1, join_axes=[df_face_person.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 57)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>byteCode</th>\n",
       "      <th>byteCode1</th>\n",
       "      <th>byteCode2</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_binary</th>\n",
       "      <th>face</th>\n",
       "      <th>person</th>\n",
       "      <th>nature</th>\n",
       "      <th>...</th>\n",
       "      <th>quarter</th>\n",
       "      <th>sun</th>\n",
       "      <th>japanese</th>\n",
       "      <th>speak</th>\n",
       "      <th>angel</th>\n",
       "      <th>alien</th>\n",
       "      <th>joy</th>\n",
       "      <th>fearful</th>\n",
       "      <th>tired</th>\n",
       "      <th>pig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[face, grin, person]</td>\n",
       "      <td>U+1F600</td>\n",
       "      <td>\\U0001F600</td>\n",
       "      <td></td>\n",
       "      <td>grinning face</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, False, False, False...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[eye, face, grin, person, smile]</td>\n",
       "      <td>U+1F601</td>\n",
       "      <td>\\U0001F601</td>\n",
       "      <td></td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, True, True, False, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bright, cool, eye, eyewear, face, glasses, pe...</td>\n",
       "      <td>U+1F60E</td>\n",
       "      <td>\\U0001F60E</td>\n",
       "      <td></td>\n",
       "      <td>smiling face with sunglasses</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, True, True, False, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[aid, cross, face, hat, helmet, person]</td>\n",
       "      <td>U+26D1</td>\n",
       "      <td>\\U000026D1</td>\n",
       "      <td></td>\n",
       "      <td>helmet with white cross</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, False, False, False...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[angel, baby, face, fairy tale, fantasy, person]</td>\n",
       "      <td>U+1F47C</td>\n",
       "      <td>\\U0001F47C</td>\n",
       "      <td></td>\n",
       "      <td>baby angel</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, False, False, True,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         annotations byteCode   byteCode1  \\\n",
       "0                               [face, grin, person]  U+1F600  \\U0001F600   \n",
       "1                   [eye, face, grin, person, smile]  U+1F601  \\U0001F601   \n",
       "2  [bright, cool, eye, eyewear, face, glasses, pe...  U+1F60E  \\U0001F60E   \n",
       "3            [aid, cross, face, hat, helmet, person]   U+26D1  \\U000026D1   \n",
       "4   [angel, baby, face, fairy tale, fantasy, person]  U+1F47C  \\U0001F47C   \n",
       "\n",
       "  byteCode2                     descriptions  \\\n",
       "0                              grinning face   \n",
       "1            grinning face with smiling eyes   \n",
       "2               smiling face with sunglasses   \n",
       "3                    helmet with white cross   \n",
       "4                                 baby angel   \n",
       "\n",
       "                                           top_words  \\\n",
       "0  [face, person, nature, animal, smile, eye, fai...   \n",
       "1  [face, person, nature, animal, smile, eye, fai...   \n",
       "2  [face, person, nature, animal, smile, eye, fai...   \n",
       "3  [face, person, nature, animal, smile, eye, fai...   \n",
       "4  [face, person, nature, animal, smile, eye, fai...   \n",
       "\n",
       "                                          top_binary  face  person  nature  \\\n",
       "0  [True, True, False, False, False, False, False...     1       1       0   \n",
       "1  [True, True, False, False, True, True, False, ...     1       1       0   \n",
       "2  [True, True, False, False, True, True, False, ...     1       1       0   \n",
       "3  [True, True, False, False, False, False, False...     1       1       0   \n",
       "4  [True, True, False, False, False, False, True,...     1       1       0   \n",
       "\n",
       "  ...   quarter  sun  japanese  speak  angel  alien  joy  fearful  tired  pig  \n",
       "0 ...         0    0         0      0      0      0    0        0      0    0  \n",
       "1 ...         0    0         0      0      0      0    0        0      0    0  \n",
       "2 ...         0    1         0      0      0      0    0        0      0    0  \n",
       "3 ...         0    0         0      0      0      0    0        0      0    0  \n",
       "4 ...         0    0         0      0      1      0    0        0      0    0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_face_person['top_binary_num'] = None\n",
    "\n",
    "# for index in range((df_face_person.shape)[0]):\n",
    "#     temp = []\n",
    "#     for boolean in df_face_person['top_binary'][index]:\n",
    "#         if boolean==True:\n",
    "#             temp.append(1)\n",
    "#         else:\n",
    "#             temp.append(0)\n",
    "#     df_face_person['top_binary_num'][index] = temp\n",
    "\n",
    "# # for index, _list in enumerate(df_face_person['top_binary']):\n",
    "# #     temp = []\n",
    "# #     for boolean in _list:\n",
    "# #         if boolean==True:\n",
    "# #             temp.append(1)\n",
    "# #         else:\n",
    "# #             temp.append(0)\n",
    "# #     df_face_person['top_binary_num'][index] = temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Notes from John:**\n",
    "count vectorizer on annoations descriptions\n",
    "clustering with binary data, possibly asocaition rules\n",
    "tfidf\n",
    "feature vector\n",
    "k_means on either full vector (or on lower dimensional space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:\n",
      " [1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 4 4 1 4 2 4 4 4 4 1 4 4 4 1 4 4 4\n",
      " 1 4 4 1 4 4 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 0 1 0 0 1 4 1 1 1 1 1 1 1 1 1 1 1 3 3 1 3 3 3 1 3 3 3 1 4 2 1 2 2 1\n",
      " 2 2 2 2 2 2 4 4 1 4], \n",
      " cluster centers:\n",
      " [[  1.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   1.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   8.00000000e-01   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   4.00000000e-01   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    4.00000000e-01   2.00000000e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   4.00000000e+00]\n",
      " [  1.00000000e+00   9.86301370e-01  -3.88578059e-16   5.55111512e-17\n",
      "    1.64383562e-01   1.36986301e-01   5.55111512e-17   1.23287671e-01\n",
      "   -9.71445147e-17   2.73972603e-02  -9.71445147e-17   9.58904110e-02\n",
      "   -1.38777878e-17   1.36986301e-02   1.36986301e-02   4.10958904e-02\n",
      "    5.47945205e-02  -4.85722573e-17   6.24500451e-17   5.47945205e-02\n",
      "    6.24500451e-17   6.24500451e-17   2.73972603e-02   4.10958904e-02\n",
      "    4.10958904e-02   2.73972603e-02   2.73972603e-02   2.73972603e-02\n",
      "    2.42861287e-17   2.73972603e-02   2.42861287e-17   2.42861287e-17\n",
      "    2.42861287e-17   4.10958904e-02   1.36986301e-02   2.73972603e-02\n",
      "    3.12250226e-17   1.36986301e-02   2.73972603e-02   1.36986301e-02\n",
      "    3.12250226e-17   1.36986301e-02   3.12250226e-17   1.36986301e-02\n",
      "    3.12250226e-17   3.12250226e-17   1.36986301e-02   2.73972603e-02\n",
      "    2.73972603e-02   3.12250226e-17  -6.66133815e-16]\n",
      " [  1.00000000e+00   0.00000000e+00   1.00000000e+00   1.00000000e+00\n",
      "    4.00000000e-01   3.00000000e-01  -1.38777878e-17   1.00000000e-01\n",
      "    1.00000000e+00   1.38777878e-17   1.38777878e-17   1.00000000e-01\n",
      "   -1.38777878e-17  -1.38777878e-17   0.00000000e+00   2.00000000e-01\n",
      "    1.00000000e-01   6.93889390e-18   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e-01   1.00000000e-01   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e-01   1.00000000e-01   1.00000000e-01\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e-01\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e-01   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00]\n",
      " [  1.00000000e+00   1.00000000e+00   2.00000000e-01   5.55111512e-17\n",
      "    2.00000000e-01   0.00000000e+00   1.00000000e+00   1.38777878e-17\n",
      "    1.38777878e-17   6.00000000e-01   9.00000000e-01   0.00000000e+00\n",
      "    2.00000000e-01  -1.38777878e-17   0.00000000e+00   6.93889390e-18\n",
      "    6.93889390e-18   5.00000000e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    2.00000000e-01   1.00000000e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   2.00000000e-01   0.00000000e+00\n",
      "    2.00000000e-01   2.00000000e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   5.20000000e+00]\n",
      " [  1.00000000e+00  -4.44089210e-16   1.00000000e+00   9.13043478e-01\n",
      "    2.77555756e-17   0.00000000e+00   4.34782609e-02   4.16333634e-17\n",
      "    4.16333634e-17   4.34782609e-02   1.38777878e-17   0.00000000e+00\n",
      "   -2.08166817e-17   4.34782609e-02  -2.77555756e-17   2.08166817e-17\n",
      "    2.08166817e-17   2.08166817e-17   0.00000000e+00   0.00000000e+00\n",
      "    1.73913043e-01   1.30434783e-01  -1.38777878e-17  -1.38777878e-17\n",
      "   -1.38777878e-17  -1.38777878e-17  -1.38777878e-17  -1.38777878e-17\n",
      "    1.30434783e-01  -1.38777878e-17   1.30434783e-01   1.30434783e-01\n",
      "    1.30434783e-01  -1.38777878e-17  -1.38777878e-17   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.34782609e-02\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   8.69565217e-02   2.13043478e+00]],\n",
      "  unique labels:\n",
      " [0 1 2 3 4]\n",
      "[(0, array([ 1. ,  0. ,  1. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
      "        0. ,  1. ,  1. ,  1. ,  0. ,  0. ,  0. ,  0.8,  0. ,  0. ,  0. ,\n",
      "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
      "        0. ,  0.4,  0. ,  0. ,  0. ,  0. ,  0. ,  0.4,  0.2,  0. ,  0. ,\n",
      "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  4. ])), (1, array([  1.00000000e+00,   9.86301370e-01,  -3.88578059e-16,\n",
      "         5.55111512e-17,   1.64383562e-01,   1.36986301e-01,\n",
      "         5.55111512e-17,   1.23287671e-01,  -9.71445147e-17,\n",
      "         2.73972603e-02,  -9.71445147e-17,   9.58904110e-02,\n",
      "        -1.38777878e-17,   1.36986301e-02,   1.36986301e-02,\n",
      "         4.10958904e-02,   5.47945205e-02,  -4.85722573e-17,\n",
      "         6.24500451e-17,   5.47945205e-02,   6.24500451e-17,\n",
      "         6.24500451e-17,   2.73972603e-02,   4.10958904e-02,\n",
      "         4.10958904e-02,   2.73972603e-02,   2.73972603e-02,\n",
      "         2.73972603e-02,   2.42861287e-17,   2.73972603e-02,\n",
      "         2.42861287e-17,   2.42861287e-17,   2.42861287e-17,\n",
      "         4.10958904e-02,   1.36986301e-02,   2.73972603e-02,\n",
      "         3.12250226e-17,   1.36986301e-02,   2.73972603e-02,\n",
      "         1.36986301e-02,   3.12250226e-17,   1.36986301e-02,\n",
      "         3.12250226e-17,   1.36986301e-02,   3.12250226e-17,\n",
      "         3.12250226e-17,   1.36986301e-02,   2.73972603e-02,\n",
      "         2.73972603e-02,   3.12250226e-17,  -6.66133815e-16])), (2, array([  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
      "         1.00000000e+00,   4.00000000e-01,   3.00000000e-01,\n",
      "        -1.38777878e-17,   1.00000000e-01,   1.00000000e+00,\n",
      "         1.38777878e-17,   1.38777878e-17,   1.00000000e-01,\n",
      "        -1.38777878e-17,  -1.38777878e-17,   0.00000000e+00,\n",
      "         2.00000000e-01,   1.00000000e-01,   6.93889390e-18,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         1.00000000e-01,   1.00000000e-01,   0.00000000e+00,\n",
      "         0.00000000e+00,   1.00000000e-01,   1.00000000e-01,\n",
      "         1.00000000e-01,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         1.00000000e-01,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   1.00000000e-01,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   1.00000000e+00])), (3, array([  1.00000000e+00,   1.00000000e+00,   2.00000000e-01,\n",
      "         5.55111512e-17,   2.00000000e-01,   0.00000000e+00,\n",
      "         1.00000000e+00,   1.38777878e-17,   1.38777878e-17,\n",
      "         6.00000000e-01,   9.00000000e-01,   0.00000000e+00,\n",
      "         2.00000000e-01,  -1.38777878e-17,   0.00000000e+00,\n",
      "         6.93889390e-18,   6.93889390e-18,   5.00000000e-01,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   1.00000000e-01,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         2.00000000e-01,   1.00000000e-01,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         2.00000000e-01,   0.00000000e+00,   2.00000000e-01,\n",
      "         2.00000000e-01,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   5.20000000e+00])), (4, array([  1.00000000e+00,  -4.44089210e-16,   1.00000000e+00,\n",
      "         9.13043478e-01,   2.77555756e-17,   0.00000000e+00,\n",
      "         4.34782609e-02,   4.16333634e-17,   4.16333634e-17,\n",
      "         4.34782609e-02,   1.38777878e-17,   0.00000000e+00,\n",
      "        -2.08166817e-17,   4.34782609e-02,  -2.77555756e-17,\n",
      "         2.08166817e-17,   2.08166817e-17,   2.08166817e-17,\n",
      "         0.00000000e+00,   0.00000000e+00,   1.73913043e-01,\n",
      "         1.30434783e-01,  -1.38777878e-17,  -1.38777878e-17,\n",
      "        -1.38777878e-17,  -1.38777878e-17,  -1.38777878e-17,\n",
      "        -1.38777878e-17,   1.30434783e-01,  -1.38777878e-17,\n",
      "         1.30434783e-01,   1.30434783e-01,   1.30434783e-01,\n",
      "        -1.38777878e-17,  -1.38777878e-17,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   4.34782609e-02,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   8.69565217e-02,   2.13043478e+00]))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def Clustering(df_combined, n_clusters=5):\n",
    "    _X = np.array(df_combined.ix[:,7:(df_combined.shape)[1]])\n",
    "    k_means = KMeans(init='k-means++', n_clusters= n_clusters, n_init=20)\n",
    "    k_means.fit(_X)\n",
    "    k_means_labels = k_means.labels_\n",
    "    k_means_cluster_centers = k_means.cluster_centers_\n",
    "    k_means_labels_unique = np.unique(k_means_labels)\n",
    "    ft = (k_means_labels, k_means_cluster_centers, k_means_labels_unique)\n",
    "    labels = np.array(k_means_labels_unique)\n",
    "    location = np.array(k_means_cluster_centers)\n",
    "    labels_location = list(zip(labels, location))\n",
    "    # person_df['cluster_label'] = pd.DataFrame(k_means_labels)\n",
    "    print (\"labels:\\n %s, \\n cluster centers:\\n %s,\\n  unique labels:\\n %s\" % ft)\n",
    "    print(labels_location)\n",
    "    return k_means_labels\n",
    "\n",
    "k_means_labels = Clustering(df_combined, n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 58)\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "print(df_combined.shape)\n",
    "print(len(k_means_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_combined['k_means'] = list(k_means_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: None, 1: None, 2: None, 3: None, 4: None}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = list(k_means_labels)\n",
    "dict_grouping = dict.fromkeys(unique_labels)\n",
    "dict_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = df_combined[['k_means','byteCode1']]\n",
    "subset = subset.values.tolist()\n",
    "# subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_grouping = defaultdict(list)\n",
    "for key, date in subset:\n",
    "    dict_grouping[key].append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dict(dict_grouping))\n",
    "\n",
    "# df_dict_grouping = pd.DataFrame(dict_grouping)\n",
    "\n",
    "# df_dict_grouping.to_json(\"k_means_clustering.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ğŸŒšğŸŒ›ğŸŒœğŸŒğŸŒ\n",
      "\n",
      "1\n",
      "ğŸ˜€ğŸ˜ğŸ˜â›‘ğŸ˜ğŸ˜˜ğŸ—£ğŸ˜—ğŸ˜™ğŸ˜šâ˜ºğŸ‘€ğŸ™‚ğŸ¤—ğŸ˜‚ğŸ¤”ğŸ˜ğŸ˜‘ğŸ˜¶ğŸ™„ğŸ˜ğŸ˜£ğŸ˜¥ğŸ˜®ğŸ¤ğŸ˜ƒğŸ˜¯ğŸ˜ªğŸ˜«ğŸ˜´ğŸ˜ŒğŸ¤“ğŸ˜›ğŸ˜œğŸ˜â˜¹ğŸ˜„ğŸ™ğŸ˜’ğŸ˜“ğŸ˜”ğŸ˜•ğŸ˜–ğŸ™ƒğŸ˜·ğŸ¤’ğŸ¤•ğŸ˜…ğŸ¤‘ğŸ˜²ğŸ˜ğŸ˜ŸğŸ˜¤ğŸ˜¢ğŸ˜­ğŸ˜¦ğŸ˜§ğŸ˜¨ğŸ˜†ğŸ˜©ğŸ˜¬ğŸ˜°ğŸ˜±ğŸ˜³ğŸ˜µğŸ˜¡ğŸ˜ ğŸ˜‰â˜ ğŸ¤–ğŸ˜ŠğŸ—¿ğŸ˜‹\n",
      "\n",
      "2\n",
      "ğŸ±ğŸ˜ºğŸ˜¸ğŸ˜¹ğŸ˜»ğŸ˜¼ğŸ˜½ğŸ™€ğŸ˜¿ğŸ˜¾\n",
      "\n",
      "3\n",
      "ğŸ‘¼ğŸ˜‡ğŸ˜ˆğŸ‘¿ğŸ‘¹ğŸ‘ºğŸ’€ğŸ‘»ğŸ‘½ğŸ‘¾\n",
      "\n",
      "4\n",
      "ğŸµğŸ¶ğŸºğŸ¦ğŸ¯ğŸ´ğŸ¦„ğŸ®ğŸ·ğŸ½ğŸ­ğŸ¹ğŸ°ğŸ»ğŸ¼ğŸ¸ğŸ²ğŸ³ğŸŒ¬ğŸ’©ğŸ™ˆğŸ™‰ğŸ™Š\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in dict_grouping.items():\n",
    "    print(key)\n",
    "    for _emoji in value:\n",
    "        print(bytes(\"{0}\".format(_emoji), 'ascii').decode('unicode-escape'), end=\"\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "#     emojis = list(map(lambda x: bytes(\"{}{}\".format(*x), 'ascii').decode('unicode-escape'), zip(list(emojis_df.byteCode1), list(emojis_df.byteCode2))))\n",
    "#     for emoji in emojis:\n",
    "#         print(emoji, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_tweets_df = tc.loader('./data/tweets_training.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>text</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>383560784879833088</td>\n",
       "      <td>37.369106</td>\n",
       "      <td>-121.998494</td>\n",
       "      <td>I'm at SEPTEMBERâ™¥ (Sunnyvale, CA) http://t.co/ICHmlfq3FR</td>\n",
       "      <td>Fri Sep 27 11:56:31 +0000 2013</td>\n",
       "      <td>47880944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>385148713460453376</td>\n",
       "      <td>37.002203</td>\n",
       "      <td>-122.058052</td>\n",
       "      <td>oops. fell asleep in the library. class started at 2.</td>\n",
       "      <td>Tue Oct 01 21:06:23 +0000 2013</td>\n",
       "      <td>259008472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>380062755639676928</td>\n",
       "      <td>37.438669</td>\n",
       "      <td>-121.879072</td>\n",
       "      <td>@nteimoorian you told me your birthday yourself 2chainz lol</td>\n",
       "      <td>Tue Sep 17 20:16:36 +0000 2013</td>\n",
       "      <td>630468267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>384797380198928384</td>\n",
       "      <td>37.299621</td>\n",
       "      <td>-121.982024</td>\n",
       "      <td>She throw it back like Thursday</td>\n",
       "      <td>Mon Sep 30 21:50:19 +0000 2013</td>\n",
       "      <td>272108001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>383691693767143425</td>\n",
       "      <td>39.137889</td>\n",
       "      <td>-121.658646</td>\n",
       "      <td>Not ready for this exam</td>\n",
       "      <td>Fri Sep 27 20:36:43 +0000 2013</td>\n",
       "      <td>790458278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        lat         lng  \\\n",
       "0  383560784879833088  37.369106 -121.998494   \n",
       "1  385148713460453376  37.002203 -122.058052   \n",
       "2  380062755639676928  37.438669 -121.879072   \n",
       "3  384797380198928384  37.299621 -121.982024   \n",
       "4  383691693767143425  39.137889 -121.658646   \n",
       "\n",
       "                                                          text  \\\n",
       "0     I'm at SEPTEMBERâ™¥ (Sunnyvale, CA) http://t.co/ICHmlfq3FR   \n",
       "1        oops. fell asleep in the library. class started at 2.   \n",
       "2  @nteimoorian you told me your birthday yourself 2chainz lol   \n",
       "3                              She throw it back like Thursday   \n",
       "4                                      Not ready for this exam   \n",
       "\n",
       "                        timeStamp    user_id  \n",
       "0  Fri Sep 27 11:56:31 +0000 2013   47880944  \n",
       "1  Tue Oct 01 21:06:23 +0000 2013  259008472  \n",
       "2  Tue Sep 17 20:16:36 +0000 2013  630468267  \n",
       "3  Mon Sep 30 21:50:19 +0000 2013  272108001  \n",
       "4  Fri Sep 27 20:36:43 +0000 2013  790458278  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df = pd.DataFrame(clean_tweets_df)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜€ğŸ˜ğŸ˜â›‘ğŸ‘¼ğŸ˜ğŸ˜˜ğŸ—£ğŸ˜—ğŸ˜™ğŸ˜šâ˜ºğŸ‘€ğŸ™‚ğŸ¤—ğŸ˜‡ğŸ˜‚ğŸ¤”ğŸ˜ğŸ˜‘ğŸµğŸ¶ğŸ˜¶ğŸºğŸ±ğŸ¦ğŸ¯ğŸ´ğŸ¦„ğŸ™„ğŸ®ğŸ·ğŸ½ğŸ˜ğŸ­ğŸ¹ğŸ°ğŸ˜£ğŸ»ğŸ¼ğŸ˜¥ğŸ¸ğŸ²ğŸ˜®ğŸ³ğŸ¤ğŸ˜ƒğŸ˜¯ğŸ˜ªğŸ˜«ğŸ˜´ğŸ˜ŒğŸ¤“ğŸ˜›ğŸ˜œğŸ˜â˜¹ğŸ˜„ğŸ™ğŸ˜’ğŸ˜“ğŸ˜”ğŸ˜•ğŸ˜–ğŸ™ƒğŸ˜·ğŸ¤’ğŸ¤•ğŸ˜…ğŸ¤‘ğŸ˜²ğŸ˜ğŸ˜ŸğŸ˜¤ğŸ˜¢ğŸŒšğŸŒ›ğŸŒœğŸ˜­ğŸŒğŸŒğŸ˜¦ğŸŒ¬ğŸ˜§ğŸ˜¨ğŸ˜†ğŸ˜©ğŸ˜¬ğŸ˜°ğŸ˜±ğŸ˜³ğŸ˜µğŸ˜¡ğŸ˜ ğŸ˜ˆğŸ‘¿ğŸ˜‰ğŸ‘¹ğŸ‘ºğŸ’€â˜ ğŸ‘»ğŸ‘½ğŸ‘¾ğŸ¤–ğŸ’©ğŸ˜ºğŸ˜ŠğŸ˜¸ğŸ˜¹ğŸ—¿ğŸ˜»ğŸ˜¼ğŸ˜½ğŸ™€ğŸ˜¿ğŸ˜¾ğŸ™ˆğŸ™‰ğŸ˜‹ğŸ™Š"
     ]
    }
   ],
   "source": [
    "emojis = list(map(lambda x: bytes(\"{}{}\".format(*x), 'ascii').decode('unicode-escape'), zip(list(df_face_person.byteCode1), list(df_face_person.byteCode2))))\n",
    "for emoji in emojis:\n",
    "    print(emoji, end=\"\")\n",
    "\n",
    "# faces_bytecodes = df_face_person.byteCode1\n",
    "# faces_bytecodes = [item for item in list(faces_bytecodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜€ğŸ˜ğŸ˜â›‘ğŸ‘¼ğŸ˜ğŸ˜˜ğŸ—£ğŸ˜—ğŸ˜™ğŸ˜šâ˜ºğŸ‘€ğŸ™‚ğŸ¤—ğŸ˜‡ğŸ˜‚ğŸ¤”ğŸ˜ğŸ˜‘ğŸµğŸ¶ğŸ˜¶ğŸºğŸ±ğŸ¦ğŸ¯ğŸ´ğŸ¦„ğŸ™„ğŸ®ğŸ·ğŸ½ğŸ˜ğŸ­ğŸ¹ğŸ°ğŸ˜£ğŸ»ğŸ¼ğŸ˜¥ğŸ¸ğŸ²ğŸ˜®ğŸ³ğŸ¤ğŸ˜ƒğŸ˜¯ğŸ˜ªğŸ˜«ğŸ˜´ğŸ˜ŒğŸ¤“ğŸ˜›ğŸ˜œğŸ˜â˜¹ğŸ˜„ğŸ™ğŸ˜’ğŸ˜“ğŸ˜”ğŸ˜•ğŸ˜–ğŸ™ƒğŸ˜·ğŸ¤’ğŸ¤•ğŸ˜…ğŸ¤‘ğŸ˜²ğŸ˜ğŸ˜ŸğŸ˜¤ğŸ˜¢ğŸŒšğŸŒ›ğŸŒœğŸ˜­ğŸŒğŸŒğŸ˜¦ğŸŒ¬ğŸ˜§ğŸ˜¨ğŸ˜†ğŸ˜©ğŸ˜¬ğŸ˜°ğŸ˜±ğŸ˜³ğŸ˜µğŸ˜¡ğŸ˜ ğŸ˜ˆğŸ‘¿ğŸ˜‰ğŸ‘¹ğŸ‘ºğŸ’€â˜ ğŸ‘»ğŸ‘½ğŸ‘¾ğŸ¤–ğŸ’©ğŸ˜ºğŸ˜ŠğŸ˜¸ğŸ˜¹ğŸ—¿ğŸ˜»ğŸ˜¼ğŸ˜½ğŸ™€ğŸ˜¿ğŸ˜¾ğŸ™ˆğŸ™‰ğŸ˜‹ğŸ™Š"
     ]
    }
   ],
   "source": [
    "for item in list(faces_bytecodes):\n",
    "    print(bytes(\"{0}\".format(item), 'ascii').decode('unicode-escape'), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     # Wide UCS-4 build\n",
    "#     highpoints = re.compile(u'['\n",
    "#         u'\\U0001F300-\\U0001F64F'\n",
    "#         u'\\U0001F680-\\U0001F6FF'\n",
    "#         u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "#         re.UNICODE)\n",
    "# except re.error:\n",
    "#     # Narrow UCS-2 build\n",
    "#     highpoints = re.compile(u'('\n",
    "#         u'\\ud83c[\\udf00-\\udfff]|'\n",
    "#         u'\\ud83d[\\udc00-\\ude4f\\ude80-\\udeff]|'\n",
    "#         u'[\\u2600-\\u26FF\\u2700-\\u27BF])+', \n",
    "#         re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# emoji_list = []\n",
    "# for index, value in enumerate(tweet_df.text):\n",
    "#     if highpoints.search(value):\n",
    "#         emoji_list.append((index, value))\n",
    "# emoji_index = [x[0] for x in emoji_list]\n",
    "# emoji_df = tweet_df.ix[emoji_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# emoji_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of functions for emoji search\n",
    "faces = re.compile(u'['\n",
    "        u'\\U0001F600-\\U0001F64F]',\n",
    "        re.UNICODE)\n",
    "\n",
    "# emojis_faces = list(faces_bytecodes)\n",
    "# emojis_faces = '|'.join(emojis_faces)\n",
    "# faces = re.compile(u'['u'(%)]'%emojis_faces, re.UNICODE)\n",
    "\n",
    "# faces = re.compile(u'[{}].format(faces_bytecodes)',\n",
    "#         re.UNICODE)\n",
    "\n",
    "# Function that takes a list of text and return text that contains just faces\n",
    "def just_face(text):\n",
    "    return (faces.findall(text))\n",
    "# Function that take a list of text and return text with just emojis\n",
    "def just_emojis(text):\n",
    "    return (highpoints.findall(text))\n",
    "# Function that a list of text and return the number of emojis in the text.\n",
    "def count_emojis(text):\n",
    "    return len(highpoints.findall(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜€\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ğŸ˜€', 'ğŸ˜€']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\U0001F600')\n",
    "just_face('\\U0001F600 hello \\U0001F600 bitchin fun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>Emoji Count</th>\n",
       "      <th>Text Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>383560784879833088</td>\n",
       "      <td>I'm at SEPTEMBERâ™¥ (Sunnyvale, CA) http://t.co/ICHmlfq3FR</td>\n",
       "      <td>Fri Sep 27 11:56:31 +0000 2013</td>\n",
       "      <td>47880944</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>378697562275840000</td>\n",
       "      <td>You guys!!! Help a friend out and follow one if my good friends new accounts? She follows back!!! :D @kyootniall ğŸ’• RT PLEASE</td>\n",
       "      <td>Sat Sep 14 01:51:49 +0000 2013</td>\n",
       "      <td>1062328976</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>381268490469904384</td>\n",
       "      <td>@donnariguero not funny! Sad ğŸ˜ğŸ˜­ bye money ğŸ’¸. Now you have to drive me places Donna</td>\n",
       "      <td>Sat Sep 21 04:07:46 +0000 2013</td>\n",
       "      <td>29075313</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>385855209102012416</td>\n",
       "      <td>Crepevine with @Kkeellyycc_  ğŸ˜ http://t.co/8B0gqgmQWZ</td>\n",
       "      <td>Thu Oct 03 19:53:45 +0000 2013</td>\n",
       "      <td>548146276</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>381165589693071360</td>\n",
       "      <td>Back on the court!!! âœŒï¸âœŒï¸</td>\n",
       "      <td>Fri Sep 20 21:18:52 +0000 2013</td>\n",
       "      <td>192611656</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  \\\n",
       "0   383560784879833088   \n",
       "5   378697562275840000   \n",
       "7   381268490469904384   \n",
       "17  385855209102012416   \n",
       "21  381165589693071360   \n",
       "\n",
       "                                                                                                                            text  \\\n",
       "0                                                                       I'm at SEPTEMBERâ™¥ (Sunnyvale, CA) http://t.co/ICHmlfq3FR   \n",
       "5   You guys!!! Help a friend out and follow one if my good friends new accounts? She follows back!!! :D @kyootniall ğŸ’• RT PLEASE   \n",
       "7                                             @donnariguero not funny! Sad ğŸ˜ğŸ˜­ bye money ğŸ’¸. Now you have to drive me places Donna   \n",
       "17                                                                         Crepevine with @Kkeellyycc_  ğŸ˜ http://t.co/8B0gqgmQWZ   \n",
       "21                                                                                                     Back on the court!!! âœŒï¸âœŒï¸   \n",
       "\n",
       "                         timeStamp     user_id  Emoji Count  Text Length  \n",
       "0   Fri Sep 27 11:56:31 +0000 2013    47880944            1           56  \n",
       "5   Sat Sep 14 01:51:49 +0000 2013  1062328976            1          124  \n",
       "7   Sat Sep 21 04:07:46 +0000 2013    29075313            2           82  \n",
       "17  Thu Oct 03 19:53:45 +0000 2013   548146276            1           53  \n",
       "21  Fri Sep 20 21:18:52 +0000 2013   192611656            2           25  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_df[\"Emoji Count\"] = emoji_df[\"text\"].apply(count_emojis)\n",
    "emoji_df[\"Text Length\"] = emoji_df[\"text\"].apply(lambda x: len(x))\n",
    "emoji_df = emoji_df[['id', 'text', 'timeStamp', 'user_id', 'Emoji Count', 'Text Length']]\n",
    "emoji_df.describe()\n",
    "emoji_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_df = emoji_df.reset_index(drop=True)\n",
    "emoji_array = [reset_df.loc[[index]].text.apply(just_emojis) for index in range(len(reset_df))]\n",
    "full_list = []\n",
    "for item in emoji_array:\n",
    "    for emoji in item:\n",
    "        for sinlge in emoji:\n",
    "            full_list.append(sinlge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸ’•'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# full_dict = defaultdict(int)\n",
    "# for item in full_list:\n",
    "#     full_dict[item] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for item in sorted(full_dict.items(), key=lambda x:x[1], reverse=True)[:50]:\n",
    "#     print(item[0], (float(item[1])/len(full_list))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_array = [reset_df.loc[[index]].text.apply(just_face) for index in range(len(reset_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    []\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets with emojis 157728\n",
      "number of tweets with faces  139576\n",
      "percentage of tweets with emojis with faces 88.5%\n"
     ]
    }
   ],
   "source": [
    "face_array = [reset_df.loc[[index]].text.apply(just_face) for index in range(len(reset_df))]\n",
    "\n",
    "face_list = []\n",
    "for item in face_array:\n",
    "    for emoji in item:\n",
    "        for sinlge in emoji:\n",
    "            face_list.append(sinlge)\n",
    "\n",
    "print(\"number of tweets with emojis {0}\".format(len(full_list)))\n",
    "print(\"number of tweets with faces  {0}\".format(len(face_array)))\n",
    "print(\"percentage of tweets with emojis with faces {0}%\".format(round((float(len(face_array))/len(full_list)*100),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_dict = defaultdict(int)\n",
    "for item in face_list:\n",
    "    face_dict[item] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    []\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in sorted(face_dict.items(), key=lambda x:x[1], reverse=True)[:50]:\n",
    "    print(item[0], (float(item[1])/len(full_list))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>titles</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_binary</th>\n",
       "      <th>face</th>\n",
       "      <th>person</th>\n",
       "      <th>nature</th>\n",
       "      <th>animal</th>\n",
       "      <th>smile</th>\n",
       "      <th>...</th>\n",
       "      <th>quarter</th>\n",
       "      <th>wink</th>\n",
       "      <th>mad</th>\n",
       "      <th>pig</th>\n",
       "      <th>pouting</th>\n",
       "      <th>speak</th>\n",
       "      <th>fear</th>\n",
       "      <th>disappointed</th>\n",
       "      <th>alien</th>\n",
       "      <th>k_means</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[face, grin, person]</td>\n",
       "      <td>grinning face</td>\n",
       "      <td>U+1F600</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, False, False, False...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[eye, face, grin, person, smile]</td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "      <td>U+1F601</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, True, True, False, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[face, joy, person, tear]</td>\n",
       "      <td>face with tears of joy</td>\n",
       "      <td>U+1F602</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, False, False, False...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[face, mouth, open, person, smile]</td>\n",
       "      <td>smiling face with open mouth</td>\n",
       "      <td>U+1F603</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, True, False, False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[eye, face, mouth, open, person, smile]</td>\n",
       "      <td>smiling face with open mouth and smiling eyes</td>\n",
       "      <td>U+1F604</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, True, True, False, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               annotations  \\\n",
       "0                     [face, grin, person]   \n",
       "1         [eye, face, grin, person, smile]   \n",
       "2                [face, joy, person, tear]   \n",
       "3       [face, mouth, open, person, smile]   \n",
       "4  [eye, face, mouth, open, person, smile]   \n",
       "\n",
       "                                    descriptions   titles  \\\n",
       "0                                  grinning face  U+1F600   \n",
       "1                grinning face with smiling eyes  U+1F601   \n",
       "2                         face with tears of joy  U+1F602   \n",
       "3                   smiling face with open mouth  U+1F603   \n",
       "4  smiling face with open mouth and smiling eyes  U+1F604   \n",
       "\n",
       "                                           top_words  \\\n",
       "0  [face, person, nature, animal, smile, eye, fai...   \n",
       "1  [face, person, nature, animal, smile, eye, fai...   \n",
       "2  [face, person, nature, animal, smile, eye, fai...   \n",
       "3  [face, person, nature, animal, smile, eye, fai...   \n",
       "4  [face, person, nature, animal, smile, eye, fai...   \n",
       "\n",
       "                                          top_binary  face  person  nature  \\\n",
       "0  [True, True, False, False, False, False, False...     1       1       0   \n",
       "1  [True, True, False, False, True, True, False, ...     1       1       0   \n",
       "2  [True, True, False, False, False, False, False...     1       1       0   \n",
       "3  [True, True, False, False, True, False, False,...     1       1       0   \n",
       "4  [True, True, False, False, True, True, False, ...     1       1       0   \n",
       "\n",
       "   animal  smile   ...     quarter  wink  mad  pig  pouting  speak  fear  \\\n",
       "0       0      0   ...           0     0    0    0        0      0     0   \n",
       "1       0      1   ...           0     0    0    0        0      0     0   \n",
       "2       0      0   ...           0     0    0    0        0      0     0   \n",
       "3       0      1   ...           0     0    0    0        0      0     0   \n",
       "4       0      1   ...           0     0    0    0        0      0     0   \n",
       "\n",
       "   disappointed  alien  k_means  \n",
       "0             0      0        1  \n",
       "1             0      0        0  \n",
       "2             0      0        1  \n",
       "3             0      0        0  \n",
       "4             0      0        0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts= df_combined.annotations\n",
    "\n",
    "#create a Gensim dictionary from the texts\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "#remove extremes (similar to the min/max df step used when creating the tf-idf matrix)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.8)\n",
    "\n",
    "#convert the dictionary to a bag of words corpus for reference\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x10c301898>"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 20.3 ms, total: 12.7 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%time lda = models.LdaModel(corpus, num_topics=10, \\\n",
    "                            id2word=dictionary, \\\n",
    "                            update_every=5, \\\n",
    "                            chunksize=10000, \\\n",
    "                            passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.160*person + 0.054*tear + 0.054*body + 0.054*sad + 0.054*cry + 0.037*monster + 0.037*tongue + 0.037*wink + 0.037*death + 0.037*skull'),\n",
       " (1,\n",
       "  '0.220*person + 0.084*mouth + 0.074*smile + 0.067*open + 0.034*eye + 0.026*frown + 0.026*sweat + 0.026*cold + 0.026*heart + 0.017*mad'),\n",
       " (2,\n",
       "  '0.085*grin + 0.065*person + 0.030*surprised + 0.030*moyai + 0.030*statue + 0.030*travel + 0.030*stunned + 0.030*hushed + 0.030*place + 0.030*horse'),\n",
       " (3,\n",
       "  '0.142*person + 0.127*eye + 0.091*kiss + 0.070*smile + 0.020*horrible + 0.020*taste + 0.020*injury + 0.020*bandage + 0.020*hurt + 0.020*blush'),\n",
       " (4,\n",
       "  '0.226*nature + 0.183*animal + 0.074*cat + 0.045*weather + 0.037*place + 0.037*space + 0.030*moon + 0.030*pet + 0.015*quarter + 0.015*pig'),\n",
       " (5,\n",
       "  '0.167*person + 0.098*fairy tale + 0.088*fantasy + 0.059*monster + 0.049*creature + 0.030*smile + 0.021*nature + 0.020*alien + 0.020*extraterrestrial + 0.020*ufo'),\n",
       " (6,\n",
       "  '0.130*person + 0.034*tired + 0.034*joy + 0.034*tear + 0.021*nature + 0.018*weary + 0.018*delicious + 0.018*um + 0.018*food + 0.018*yum'),\n",
       " (7,\n",
       "  '0.097*animal + 0.097*nature + 0.063*monkey + 0.048*forbidden + 0.048*prohibited + 0.048*not + 0.048*evil + 0.048*no + 0.048*gesture + 0.017*speak'),\n",
       " (8,\n",
       "  '0.102*person + 0.069*sick + 0.036*cold + 0.036*doctor + 0.036*mask + 0.036*medicine + 0.036*triumph + 0.036*won + 0.003*ill + 0.003*thermometer'),\n",
       " (9,\n",
       "  '0.159*person + 0.045*disappointed + 0.045*relieved + 0.024*sleep + 0.024*fearful + 0.024*fear + 0.024*scared + 0.024*head + 0.024*silhouette + 0.024*speaking')]"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('person', 0.15961170571365257),\n",
       "   ('tear', 0.054049528870208134),\n",
       "   ('body', 0.054048960919355127),\n",
       "   ('sad', 0.054048889347755584),\n",
       "   ('cry', 0.054048889347755501),\n",
       "   ('monster', 0.036613954044276337),\n",
       "   ('tongue', 0.036613914152601776),\n",
       "   ('wink', 0.036613820149575593),\n",
       "   ('death', 0.03661380121855598),\n",
       "   ('skull', 0.036613801218555647),\n",
       "   ('eye', 0.036612959518771401),\n",
       "   ('sob', 0.019178667725240899),\n",
       "   ('joke', 0.019178667725222757),\n",
       "   ('rolling', 0.019178667690230852),\n",
       "   ('eyes', 0.019178667690229384),\n",
       "   ('fairy tale', 0.019178116009641769),\n",
       "   ('crossbones', 0.0017580003381538812),\n",
       "   ('cat', 0.0017436440999485186),\n",
       "   ('animal', 0.0017435659004636809),\n",
       "   ('nature', 0.0017435561814640567)]),\n",
       " (1,\n",
       "  [('person', 0.21984458527397097),\n",
       "   ('mouth', 0.08379984779038116),\n",
       "   ('smile', 0.07404616692994731),\n",
       "   ('open', 0.06720580127213728),\n",
       "   ('eye', 0.034035309510224009),\n",
       "   ('frown', 0.02572075675343655),\n",
       "   ('sweat', 0.025720709808085301),\n",
       "   ('cold', 0.025720547266088682),\n",
       "   ('heart', 0.025720537191618636),\n",
       "   ('mad', 0.017423737483722172),\n",
       "   ('angry', 0.017423737483721825),\n",
       "   ('love', 0.017423632530453106),\n",
       "   ('sun', 0.0091268631066823633),\n",
       "   ('cool', 0.0091267201568181883),\n",
       "   ('glasses', 0.00912672015681802),\n",
       "   ('sunglasses', 0.0091267201568180131),\n",
       "   ('eyewear', 0.0091267201568179905),\n",
       "   ('laugh', 0.0091267201401104853),\n",
       "   ('satisfied', 0.0091267201401103327),\n",
       "   ('red', 0.0091267201401010346)]),\n",
       " (2,\n",
       "  [('grin', 0.084746774143314552),\n",
       "   ('person', 0.064572201712389615),\n",
       "   ('surprised', 0.030089059776987458),\n",
       "   ('moyai', 0.030088572850363267),\n",
       "   ('statue', 0.030088572850363232),\n",
       "   ('travel', 0.030088572850362066),\n",
       "   ('stunned', 0.030088572850265113),\n",
       "   ('hushed', 0.030088572850263146),\n",
       "   ('place', 0.030088543707117579),\n",
       "   ('horse', 0.03008775091281737),\n",
       "   ('japanese', 0.030087611930109892),\n",
       "   ('goblin', 0.030087439428520574),\n",
       "   ('pouting', 0.030087357886824723),\n",
       "   ('ghost', 0.030085703460120791),\n",
       "   ('creature', 0.0027356057239091326),\n",
       "   ('smile', 0.0027355715588191724),\n",
       "   ('monster', 0.0027355556610013771),\n",
       "   ('cat', 0.0027354796459144346),\n",
       "   ('fantasy', 0.0027354749388370752),\n",
       "   ('eye', 0.002735469122882707)]),\n",
       " (3,\n",
       "  [('person', 0.14221855939471745),\n",
       "   ('eye', 0.12683444192750293),\n",
       "   ('kiss', 0.091132984991636065),\n",
       "   ('smile', 0.069781185189414299),\n",
       "   ('horrible', 0.01965617263121576),\n",
       "   ('taste', 0.01965617263121475),\n",
       "   ('injury', 0.019656172618583975),\n",
       "   ('bandage', 0.019656172618582452),\n",
       "   ('hurt', 0.019656172618581717),\n",
       "   ('blush', 0.019656172618574556),\n",
       "   ('deadpan', 0.019656172596336105),\n",
       "   ('neutral', 0.019656172596335984),\n",
       "   ('tongue', 0.019656076301156841),\n",
       "   ('blow', 0.019655966488822632),\n",
       "   ('cloud', 0.019655966488822129),\n",
       "   ('wind', 0.019655966488822001),\n",
       "   ('tiger', 0.01965534578759285),\n",
       "   ('closed', 0.0017904820789899102),\n",
       "   ('grin', 0.0017876603129742669),\n",
       "   ('weather', 0.0017873028145806316)]),\n",
       " (4,\n",
       "  [('nature', 0.2257671586044703),\n",
       "   ('animal', 0.18311482165201837),\n",
       "   ('cat', 0.074192705494055156),\n",
       "   ('weather', 0.044809569104233234),\n",
       "   ('place', 0.037463763118964044),\n",
       "   ('space', 0.037463762109121619),\n",
       "   ('moon', 0.030117932939587023),\n",
       "   ('pet', 0.030117799260049535),\n",
       "   ('quarter', 0.015426258316803384),\n",
       "   ('pig', 0.015426258259801489),\n",
       "   ('bright', 0.01542622933365969),\n",
       "   ('smile', 0.010802319075541125),\n",
       "   ('full', 0.0080804210058587501),\n",
       "   ('time', 0.0080804209997534533),\n",
       "   ('oh', 0.0080804209997349385),\n",
       "   ('wry', 0.0080804209997151731),\n",
       "   ('ironic', 0.0080804209997148574),\n",
       "   ('bunny', 0.008080420991008844),\n",
       "   ('rabbit', 0.008080420991008485),\n",
       "   ('whale', 0.0080804209774389159)]),\n",
       " (5,\n",
       "  [('person', 0.16662037824052489),\n",
       "   ('fairy tale', 0.09761325276175771),\n",
       "   ('fantasy', 0.087948375100906417),\n",
       "   ('monster', 0.058954447380910761),\n",
       "   ('creature', 0.04928963598663462),\n",
       "   ('smile', 0.029960083848906204),\n",
       "   ('nature', 0.02058099149375035),\n",
       "   ('alien', 0.020295798719329024),\n",
       "   ('extraterrestrial', 0.020295798719328895),\n",
       "   ('ufo', 0.020295798719328736),\n",
       "   ('angel', 0.020295798704943056),\n",
       "   ('space', 0.02029578974659263),\n",
       "   ('innocent', 0.010631132638542609),\n",
       "   ('halo', 0.010631132638542151),\n",
       "   ('devil', 0.010631132623913157),\n",
       "   ('baby', 0.010631132623913121),\n",
       "   ('imp', 0.010631132623912909),\n",
       "   ('horns', 0.010631132623895746),\n",
       "   ('totally', 0.010631132610537697),\n",
       "   ('astonished', 0.010631132610537145)]),\n",
       " (6,\n",
       "  [('person', 0.12961449204980413),\n",
       "   ('tired', 0.033603965732115874),\n",
       "   ('joy', 0.033603758199839309),\n",
       "   ('tear', 0.033603170681963834),\n",
       "   ('nature', 0.020691780918927899),\n",
       "   ('weary', 0.017602180052301603),\n",
       "   ('delicious', 0.017602077459703536),\n",
       "   ('um', 0.017602077459703245),\n",
       "   ('food', 0.017602077459703103),\n",
       "   ('yum', 0.017602077459703089),\n",
       "   ('savouring', 0.017602077459702367),\n",
       "   ('dung', 0.017602077459702031),\n",
       "   ('comic', 0.017602077459701902),\n",
       "   ('poo', 0.017602077459701736),\n",
       "   ('poop', 0.017602077459701465),\n",
       "   ('object', 0.017602077459701347),\n",
       "   ('munch', 0.017602077453942541),\n",
       "   ('scream', 0.017602077453941947),\n",
       "   ('nerd', 0.017602077410306831),\n",
       "   ('geek', 0.017602077410303858)]),\n",
       " (7,\n",
       "  [('animal', 0.097071418127065517),\n",
       "   ('nature', 0.096624016941751975),\n",
       "   ('monkey', 0.063452799552206549),\n",
       "   ('forbidden', 0.04797650702899145),\n",
       "   ('prohibited', 0.047976507028990818),\n",
       "   ('not', 0.047976507028990659),\n",
       "   ('evil', 0.047976507028990464),\n",
       "   ('no', 0.047976507028990367),\n",
       "   ('gesture', 0.047976507028988938),\n",
       "   ('speak', 0.017023926962466417),\n",
       "   ('hear', 0.017023921832616341),\n",
       "   ('see', 0.017023921832616123),\n",
       "   ('aid', 0.01702392180806429),\n",
       "   ('helmet', 0.01702392180806387),\n",
       "   ('cross', 0.017023921808063641),\n",
       "   ('hat', 0.017023921808063416),\n",
       "   ('bear', 0.017023921772933895),\n",
       "   ('wolf', 0.017023921772931837),\n",
       "   ('dog', 0.017023118306665568),\n",
       "   ('person', 0.017014235458569449)]),\n",
       " (8,\n",
       "  [('person', 0.10231330087946473),\n",
       "   ('sick', 0.069305437138151835),\n",
       "   ('cold', 0.036303568217175827),\n",
       "   ('doctor', 0.036302921642493699),\n",
       "   ('mask', 0.036302921642493061),\n",
       "   ('medicine', 0.036302921642492957),\n",
       "   ('triumph', 0.036302921603908307),\n",
       "   ('won', 0.036302921603907315),\n",
       "   ('ill', 0.0033072354354876854),\n",
       "   ('thermometer', 0.0033072354354872174),\n",
       "   ('crossbones', 0.0033002659171159333),\n",
       "   ('robot', 0.0033002659169178009),\n",
       "   ('sun', 0.0033002657654221485),\n",
       "   ('closed', 0.0033002657635020009),\n",
       "   ('dragon', 0.0033002657435838574),\n",
       "   ('frog', 0.0033002657435177913),\n",
       "   ('tiger', 0.0033002657334190331),\n",
       "   ('smile', 0.0033002657273352803),\n",
       "   ('pouting', 0.0033002657212202005),\n",
       "   ('grimace', 0.0033002657174593351)]),\n",
       " (9,\n",
       "  [('person', 0.1586079801262899),\n",
       "   ('disappointed', 0.045074817579757814),\n",
       "   ('relieved', 0.045074812281148603),\n",
       "   ('sleep', 0.02361098955695437),\n",
       "   ('fearful', 0.023610640562253309),\n",
       "   ('fear', 0.023610640562252108),\n",
       "   ('scared', 0.023610640562251487),\n",
       "   ('head', 0.023610618771388266),\n",
       "   ('silhouette', 0.023610618771388068),\n",
       "   ('speaking', 0.023610618771387877),\n",
       "   ('whew', 0.023610618759052279),\n",
       "   ('thinking', 0.023610618689280313),\n",
       "   ('speak', 0.023610611665470998),\n",
       "   ('cow', 0.023609793355208266),\n",
       "   ('panda', 0.023609793354680404),\n",
       "   ('unicorn', 0.023609793354377333),\n",
       "   ('ogre', 0.023609627369657465),\n",
       "   ('japanese', 0.023609483659396885),\n",
       "   ('hamster', 0.023609286826465372),\n",
       "   ('animal', 0.0021466333418621118)])]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_matrix = lda.show_topics(formatted=False, num_words=20)\n",
    "topics_matrix\n",
    "# topics_matrix = np.array(topics_matrix)\n",
    "\n",
    "# topic_words = topics_matrix[:,:,1]\n",
    "# for i in topic_words:\n",
    "#     print([str(word) for word in i])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, LabeledSentence, Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledSentence(words=['face', 'grin', 'person'], tags=['grinning face']),\n",
       " LabeledSentence(words=['eye', 'face', 'grin', 'person', 'smile'], tags=['grinning face with smiling eyes']),\n",
       " LabeledSentence(words=['face', 'joy', 'person', 'tear'], tags=['face with tears of joy']),\n",
       " LabeledSentence(words=['face', 'mouth', 'open', 'person', 'smile'], tags=['smiling face with open mouth']),\n",
       " LabeledSentence(words=['eye', 'face', 'mouth', 'open', 'person', 'smile'], tags=['smiling face with open mouth and smiling eyes']),\n",
       " LabeledSentence(words=['cold', 'face', 'open', 'person', 'smile', 'sweat'], tags=['smiling face with open mouth and cold sweat']),\n",
       " LabeledSentence(words=['face', 'laugh', 'mouth', 'open', 'person', 'satisfied', 'smile'], tags=['smiling face with open mouth and tightly-closed eyes']),\n",
       " LabeledSentence(words=['face', 'person', 'wink'], tags=['winking face']),\n",
       " LabeledSentence(words=['blush', 'eye', 'face', 'person', 'smile'], tags=['smiling face with smiling eyes']),\n",
       " LabeledSentence(words=['delicious', 'face', 'food', 'person', 'savouring', 'smile', 'um', 'yum'], tags=['face savouring delicious food']),\n",
       " LabeledSentence(words=['bright', 'cool', 'eye', 'eyewear', 'face', 'glasses', 'person', 'smile', 'sun', 'sunglasses', 'weather'], tags=['smiling face with sunglasses']),\n",
       " LabeledSentence(words=['eye', 'face', 'heart', 'love', 'person', 'smile'], tags=['smiling face with heart-shaped eyes']),\n",
       " LabeledSentence(words=['face', 'heart', 'kiss', 'person'], tags=['face throwing a kiss']),\n",
       " LabeledSentence(words=['face', 'kiss', 'person'], tags=['kissing face']),\n",
       " LabeledSentence(words=['eye', 'face', 'kiss', 'person', 'smile'], tags=['kissing face with smiling eyes']),\n",
       " LabeledSentence(words=['closed', 'eye', 'face', 'kiss', 'person'], tags=['kissing face with closed eyes']),\n",
       " LabeledSentence(words=['face', 'outlined', 'person', 'relaxed', 'smile'], tags=['white smiling face']),\n",
       " LabeledSentence(words=['face', 'person', 'smile'], tags=['slightly smiling face']),\n",
       " LabeledSentence(words=['face', 'hug', 'hugging', 'person'], tags=['hugging face']),\n",
       " LabeledSentence(words=['angel', 'face', 'fairy tale', 'fantasy', 'halo', 'innocent', 'person', 'smile'], tags=['smiling face with halo']),\n",
       " LabeledSentence(words=['face', 'person', 'thinking'], tags=['thinking face']),\n",
       " LabeledSentence(words=['deadpan', 'face', 'neutral', 'person'], tags=['neutral face']),\n",
       " LabeledSentence(words=['expressionless', 'face', 'inexpressive', 'person', 'unexpressive'], tags=['expressionless face']),\n",
       " LabeledSentence(words=['face', 'mouth', 'person', 'quiet', 'silent'], tags=['face without mouth']),\n",
       " LabeledSentence(words=['eyes', 'face', 'person', 'rolling'], tags=['face with rolling eyes']),\n",
       " LabeledSentence(words=['face', 'person', 'smirk'], tags=['smirking face']),\n",
       " LabeledSentence(words=['face', 'persevere', 'person'], tags=['persevering face']),\n",
       " LabeledSentence(words=['disappointed', 'face', 'person', 'relieved', 'whew'], tags=['disappointed but relieved face']),\n",
       " LabeledSentence(words=['face', 'mouth', 'open', 'person', 'sympathy'], tags=['face with open mouth']),\n",
       " LabeledSentence(words=['face', 'mouth', 'person', 'zipper'], tags=['zipper-mouth face']),\n",
       " LabeledSentence(words=['face', 'hushed', 'person', 'stunned', 'surprised'], tags=['hushed face']),\n",
       " LabeledSentence(words=['face', 'person', 'sleep'], tags=['sleepy face']),\n",
       " LabeledSentence(words=['face', 'person', 'tired'], tags=['tired face']),\n",
       " LabeledSentence(words=['face', 'person', 'sleep', 'zzz'], tags=['sleeping face']),\n",
       " LabeledSentence(words=['face', 'person', 'relieved'], tags=['relieved face']),\n",
       " LabeledSentence(words=['face', 'geek', 'nerd', 'person'], tags=['nerd face']),\n",
       " LabeledSentence(words=['face', 'person', 'tongue'], tags=['face with stuck-out tongue']),\n",
       " LabeledSentence(words=['eye', 'face', 'joke', 'person', 'tongue', 'wink'], tags=['face with stuck-out tongue and winking eye']),\n",
       " LabeledSentence(words=['eye', 'face', 'horrible', 'person', 'taste', 'tongue'], tags=['face with stuck-out tongue and tightly-closed eyes']),\n",
       " LabeledSentence(words=['face', 'frown', 'person'], tags=['white frowning face']),\n",
       " LabeledSentence(words=['face', 'frown', 'person'], tags=['slightly frowning face']),\n",
       " LabeledSentence(words=['face', 'person', 'unamused', 'unhappy'], tags=['unamused face']),\n",
       " LabeledSentence(words=['cold', 'face', 'person', 'sweat'], tags=['face with cold sweat']),\n",
       " LabeledSentence(words=['dejected', 'face', 'pensive', 'person'], tags=['pensive face']),\n",
       " LabeledSentence(words=['confused', 'face', 'person'], tags=['confused face']),\n",
       " LabeledSentence(words=['confounded', 'face', 'person'], tags=['confounded face']),\n",
       " LabeledSentence(words=['face', 'person', 'upside-down'], tags=['upside-down face']),\n",
       " LabeledSentence(words=['cold', 'doctor', 'face', 'mask', 'medicine', 'person', 'sick'], tags=['face with medical mask']),\n",
       " LabeledSentence(words=['face', 'ill', 'person', 'sick', 'thermometer'], tags=['face with thermometer']),\n",
       " LabeledSentence(words=['bandage', 'face', 'hurt', 'injury', 'person'], tags=['face with head-bandage']),\n",
       " LabeledSentence(words=['face', 'money', 'mouth', 'person'], tags=['money-mouth face']),\n",
       " LabeledSentence(words=['astonished', 'face', 'person', 'shocked', 'totally'], tags=['astonished face']),\n",
       " LabeledSentence(words=['disappointed', 'face', 'person'], tags=['disappointed face']),\n",
       " LabeledSentence(words=['face', 'person', 'worried'], tags=['worried face']),\n",
       " LabeledSentence(words=['face', 'person', 'triumph', 'won'], tags=['face with look of triumph']),\n",
       " LabeledSentence(words=['cry', 'face', 'person', 'sad', 'tear'], tags=['crying face'])]"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_sentence(_df):\n",
    "    sentences = []\n",
    "    for uid, line in enumerate(_df):\n",
    "        sentences.append(LabeledSentence(words=df_combined.annotations[uid], \\\n",
    "                              tags=[df_combined.descriptions[uid]]))\n",
    "    return sentences\n",
    "\n",
    "label_sentence(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = list(LabeledSentence(df_combined.annotations[uid], (df_combined.descriptions[uid])) for uid, value in enumerate(df_combined))\n",
    "model = Doc2Vec(size=200, min_count=1, workers=16)\n",
    "model.build_vocab(sentences)\n",
    "\n",
    "\n",
    "# model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=8)\n",
    "\n",
    "# model.build_vocab(sentences.to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train(sentences)\n",
    "    model.alpha -= 0.002  # decrease the learning rate\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'face with thermometer' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-609-1f46b5db7b7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sims = model.docvecs.most_similar(['grinning face'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.most_similar('grinning face')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"face with thermometer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                 \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute similarity with no input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'face with thermometer' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "# sims = model.docvecs.most_similar(['grinning face'])\n",
    "# model.most_similar('grinning face')\n",
    "model.most_similar(\"face with thermometer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
