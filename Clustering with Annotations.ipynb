{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose \n",
    "\n",
    "The purpose of the notebook is to use annotatoins (and possibly description) of each emoji to intelligently cluster emojis\n",
    "* use webscraping csv file to get dataframe with emoji, annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Packages **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.data import find\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert the text file into a list of 1) titles 2) descriptions 3) annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_scraped_txt(txt):\n",
    "    with open(\"emoji_webscraped.txt\") as f_in:\n",
    "        titles = []\n",
    "        descriptions = []\n",
    "        annotations = []\n",
    "        for line in f_in:\n",
    "            line = line.strip()\n",
    "            temp = line.split(\", \")\n",
    "            titles.append(temp[0])\n",
    "            descriptions.append(temp[1])\n",
    "            annotations.append(temp[2:len(temp)])\n",
    "        return titles, descriptions, annotations\n",
    "\n",
    "titles, descriptions, annotations = convert_scraped_txt(\"emoji_webscraped.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282\n",
      "1282\n",
      "1282\n"
     ]
    }
   ],
   "source": [
    "print(len(titles))\n",
    "print(len(descriptions))\n",
    "print(len(annotations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create dataframe from three arrays **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {'titles' : (titles),\n",
    "     'annotations' : (annotations),\n",
    "     'descriptions': (descriptions)}\n",
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[face, grin, person]</td>\n",
       "      <td>grinning face</td>\n",
       "      <td>U+1F600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[eye, face, grin, person, smile]</td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "      <td>U+1F601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[face, joy, person, tear]</td>\n",
       "      <td>face with tears of joy</td>\n",
       "      <td>U+1F602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[face, mouth, open, person, smile]</td>\n",
       "      <td>smiling face with open mouth</td>\n",
       "      <td>U+1F603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[eye, face, mouth, open, person, smile]</td>\n",
       "      <td>smiling face with open mouth and smiling eyes</td>\n",
       "      <td>U+1F604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               annotations  \\\n",
       "0                     [face, grin, person]   \n",
       "1         [eye, face, grin, person, smile]   \n",
       "2                [face, joy, person, tear]   \n",
       "3       [face, mouth, open, person, smile]   \n",
       "4  [eye, face, mouth, open, person, smile]   \n",
       "\n",
       "                                    descriptions   titles  \n",
       "0                                  grinning face  U+1F600  \n",
       "1                grinning face with smiling eyes  U+1F601  \n",
       "2                         face with tears of joy  U+1F602  \n",
       "3                   smiling face with open mouth  U+1F603  \n",
       "4  smiling face with open mouth and smiling eyes  U+1F604  "
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subset Dataframe to only annotations which either contain face or person**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def subset_annotations(_df):\n",
    "    list_titles = [list(item) for item in list(_df)]\n",
    "    index_face_person = [index for index,value in enumerate(list_titles) if 'face' in value] # or 'person' in value]\n",
    "    # print(len(index_face_person))\n",
    "    df_face_person = df.iloc[index_face_person]\n",
    "    # print(df_face_person.shape)\n",
    "    # df_face_person.head()\n",
    "    return df_face_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_face_person = subset_annotations(df.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_list(annotations, _common=100):\n",
    "    total_list = [word for item in list(annotations) for word in item]\n",
    "    top_list = nltk.FreqDist(total_list).most_common(_common)\n",
    "    return total_list, top_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_list, top_list = word_list(df_face_person.annotations, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_justwords(top_list):\n",
    "    top_words = [item[0] for item in top_list]\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['face',\n",
       " 'person',\n",
       " 'nature',\n",
       " 'animal',\n",
       " 'smile',\n",
       " 'eye',\n",
       " 'fairy tale',\n",
       " 'cat',\n",
       " 'mouth',\n",
       " 'monster',\n",
       " 'fantasy',\n",
       " 'open',\n",
       " 'space',\n",
       " 'weather',\n",
       " 'place',\n",
       " 'creature',\n",
       " 'kiss',\n",
       " 'tear',\n",
       " 'pet',\n",
       " 'cold',\n",
       " 'monkey',\n",
       " 'moon',\n",
       " 'no',\n",
       " 'evil',\n",
       " 'sad',\n",
       " 'sweat',\n",
       " 'not',\n",
       " 'bright',\n",
       " 'grin',\n",
       " 'frown',\n",
       " 'tongue',\n",
       " 'cry',\n",
       " 'heart',\n",
       " 'body',\n",
       " 'gesture',\n",
       " 'prohibited',\n",
       " 'forbidden',\n",
       " 'angel',\n",
       " 'surprised',\n",
       " 'death',\n",
       " 'weary',\n",
       " 'quarter',\n",
       " 'wink',\n",
       " 'mad',\n",
       " 'pig',\n",
       " 'pouting',\n",
       " 'speak',\n",
       " 'fear',\n",
       " 'disappointed',\n",
       " 'alien']"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_justwords = top_justwords(top_list)\n",
    "top_justwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[face, grin, person]</td>\n",
       "      <td>grinning face</td>\n",
       "      <td>U+1F600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[eye, face, grin, person, smile]</td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "      <td>U+1F601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[face, joy, person, tear]</td>\n",
       "      <td>face with tears of joy</td>\n",
       "      <td>U+1F602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[face, mouth, open, person, smile]</td>\n",
       "      <td>smiling face with open mouth</td>\n",
       "      <td>U+1F603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[eye, face, mouth, open, person, smile]</td>\n",
       "      <td>smiling face with open mouth and smiling eyes</td>\n",
       "      <td>U+1F604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               annotations  \\\n",
       "0                     [face, grin, person]   \n",
       "1         [eye, face, grin, person, smile]   \n",
       "2                [face, joy, person, tear]   \n",
       "3       [face, mouth, open, person, smile]   \n",
       "4  [eye, face, mouth, open, person, smile]   \n",
       "\n",
       "                                    descriptions   titles  \n",
       "0                                  grinning face  U+1F600  \n",
       "1                grinning face with smiling eyes  U+1F601  \n",
       "2                         face with tears of joy  U+1F602  \n",
       "3                   smiling face with open mouth  U+1F603  \n",
       "4  smiling face with open mouth and smiling eyes  U+1F604  "
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_face_person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(columns=top_justwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "top_justwords_array = [(top_justwords) for i in range(df_face_person.shape[0])]\n",
    "# df_face_person['top_words'] = 1\n",
    "df_face_person['top_words'] = pd.Series(top_justwords_array, index=df_face_person.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 4)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_face_person.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(121, 5)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# something = [list(pd.Series(item).isin(df_face_person.annotations)) for item in df_face_person.top_words]\n",
    "\n",
    "df_face_person['top_binary'] = [list(pd.Series(item).isin(list(df_face_person.annotations)[index])) for index, item in enumerate(df_face_person.top_words)]\n",
    "df_face_person = df_face_person.reset_index(drop=True)\n",
    "df_face_person.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 50)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features = list(df_face_person.top_binary)\n",
    "\n",
    "df_features = pd.DataFrame(data_features, columns=top_justwords)\n",
    "df_features = df_features.astype(int)\n",
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_face_person, df_features], axis=1, join_axes=[df_face_person.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 55)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_face_person['top_binary_num'] = None\n",
    "\n",
    "# for index in range((df_face_person.shape)[0]):\n",
    "#     temp = []\n",
    "#     for boolean in df_face_person['top_binary'][index]:\n",
    "#         if boolean==True:\n",
    "#             temp.append(1)\n",
    "#         else:\n",
    "#             temp.append(0)\n",
    "#     df_face_person['top_binary_num'][index] = temp\n",
    "\n",
    "# # for index, _list in enumerate(df_face_person['top_binary']):\n",
    "# #     temp = []\n",
    "# #     for boolean in _list:\n",
    "# #         if boolean==True:\n",
    "# #             temp.append(1)\n",
    "# #         else:\n",
    "# #             temp.append(0)\n",
    "# #     df_face_person['top_binary_num'][index] = temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Notes from John:**\n",
    "count vectorizer on annoations descriptions\n",
    "clustering with binary data, possibly asocaition rules\n",
    "tfidf\n",
    "feature vector\n",
    "k_means on either full vector (or on lower dimensional space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 4 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 4 4 4 4 1 1\n",
      " 4 4 4 1 3 3 3 3 3 3 3 3 3 3 3 3 3 1 4 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 2 2 2 2 2 3 1], \n",
      " cluster centers:\n",
      " [[  1.00000000e+00   1.00000000e+00   1.11022302e-16   5.55111512e-17\n",
      "    8.00000000e-01   4.00000000e-01   1.38777878e-17   2.77555756e-17\n",
      "    4.00000000e-01   1.38777878e-17   1.38777878e-17   4.66666667e-01\n",
      "   -2.08166817e-17   6.66666667e-02  -1.38777878e-17   1.38777878e-17\n",
      "    6.66666667e-02   1.38777878e-17   0.00000000e+00   1.33333333e-01\n",
      "    0.00000000e+00   0.00000000e+00  -6.93889390e-18  -6.93889390e-18\n",
      "   -6.93889390e-18   1.33333333e-01  -6.93889390e-18   6.66666667e-02\n",
      "    6.66666667e-02   6.66666667e-02  -6.93889390e-18  -6.93889390e-18\n",
      "    6.66666667e-02  -6.93889390e-18  -6.93889390e-18  -6.93889390e-18\n",
      "   -6.93889390e-18   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.46666667e+00]\n",
      " [  1.00000000e+00   9.83050847e-01  -2.77555756e-16   2.22044605e-16\n",
      "   -5.55111512e-17   6.77966102e-02   1.69491525e-02  -6.93889390e-17\n",
      "    5.08474576e-02   5.08474576e-02  -2.77555756e-17   9.71445147e-17\n",
      "   -2.08166817e-17  -2.08166817e-17   1.69491525e-02  -3.46944695e-17\n",
      "    5.08474576e-02   5.08474576e-02   4.85722573e-17   3.38983051e-02\n",
      "    4.85722573e-17   4.85722573e-17   1.04083409e-17   1.04083409e-17\n",
      "    3.38983051e-02   1.69491525e-02   1.04083409e-17   1.04083409e-17\n",
      "    1.69491525e-02   3.38983051e-02   5.08474576e-02   3.38983051e-02\n",
      "    1.69491525e-02   5.08474576e-02   1.04083409e-17   1.04083409e-17\n",
      "    1.04083409e-17   2.42861287e-17   1.69491525e-02   3.38983051e-02\n",
      "    1.69491525e-02   2.42861287e-17   3.38983051e-02   3.38983051e-02\n",
      "    2.42861287e-17   1.69491525e-02   1.69491525e-02   3.38983051e-02\n",
      "    3.38983051e-02   2.42861287e-17   1.00000000e+00]\n",
      " [  1.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   1.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   8.00000000e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.00000000e-01\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   4.00000000e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.11022302e-16]\n",
      " [  1.00000000e+00  -5.55111512e-16   1.00000000e+00   9.39393939e-01\n",
      "    1.21212121e-01   9.09090909e-02   3.03030303e-02   3.03030303e-01\n",
      "    3.03030303e-02   3.03030303e-02   1.38777878e-17   3.03030303e-02\n",
      "   -2.08166817e-17   3.03030303e-02  -3.46944695e-17  -6.93889390e-18\n",
      "    3.03030303e-02   6.06060606e-02   1.21212121e-01   0.00000000e+00\n",
      "    1.21212121e-01   0.00000000e+00   9.09090909e-02   9.09090909e-02\n",
      "    3.03030303e-02  -1.73472348e-17   9.09090909e-02  -1.73472348e-17\n",
      "    3.03030303e-02  -1.73472348e-17  -1.73472348e-17   3.03030303e-02\n",
      "    3.03030303e-02  -1.73472348e-17   9.09090909e-02   9.09090909e-02\n",
      "    9.09090909e-02   0.00000000e+00   3.03030303e-02   0.00000000e+00\n",
      "    3.03030303e-02   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    6.06060606e-02   3.03030303e-02   3.03030303e-02   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   6.66133815e-16]\n",
      " [  1.00000000e+00   1.00000000e+00   2.22222222e-01   0.00000000e+00\n",
      "    2.22222222e-01   1.38777878e-17   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   5.55555556e-01   1.00000000e+00   0.00000000e+00\n",
      "    2.22222222e-01  -1.38777878e-17   0.00000000e+00   5.55555556e-01\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.22222222e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.22222222e-01   2.00000000e+00]],\n",
      "  unique labels:\n",
      " [0 1 2 3 4]\n",
      "[(0, array([  1.00000000e+00,   1.00000000e+00,   1.11022302e-16,\n",
      "         5.55111512e-17,   8.00000000e-01,   4.00000000e-01,\n",
      "         1.38777878e-17,   2.77555756e-17,   4.00000000e-01,\n",
      "         1.38777878e-17,   1.38777878e-17,   4.66666667e-01,\n",
      "        -2.08166817e-17,   6.66666667e-02,  -1.38777878e-17,\n",
      "         1.38777878e-17,   6.66666667e-02,   1.38777878e-17,\n",
      "         0.00000000e+00,   1.33333333e-01,   0.00000000e+00,\n",
      "         0.00000000e+00,  -6.93889390e-18,  -6.93889390e-18,\n",
      "        -6.93889390e-18,   1.33333333e-01,  -6.93889390e-18,\n",
      "         6.66666667e-02,   6.66666667e-02,   6.66666667e-02,\n",
      "        -6.93889390e-18,  -6.93889390e-18,   6.66666667e-02,\n",
      "        -6.93889390e-18,  -6.93889390e-18,  -6.93889390e-18,\n",
      "        -6.93889390e-18,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   1.46666667e+00])), (1, array([  1.00000000e+00,   9.83050847e-01,  -2.77555756e-16,\n",
      "         2.22044605e-16,  -5.55111512e-17,   6.77966102e-02,\n",
      "         1.69491525e-02,  -6.93889390e-17,   5.08474576e-02,\n",
      "         5.08474576e-02,  -2.77555756e-17,   9.71445147e-17,\n",
      "        -2.08166817e-17,  -2.08166817e-17,   1.69491525e-02,\n",
      "        -3.46944695e-17,   5.08474576e-02,   5.08474576e-02,\n",
      "         4.85722573e-17,   3.38983051e-02,   4.85722573e-17,\n",
      "         4.85722573e-17,   1.04083409e-17,   1.04083409e-17,\n",
      "         3.38983051e-02,   1.69491525e-02,   1.04083409e-17,\n",
      "         1.04083409e-17,   1.69491525e-02,   3.38983051e-02,\n",
      "         5.08474576e-02,   3.38983051e-02,   1.69491525e-02,\n",
      "         5.08474576e-02,   1.04083409e-17,   1.04083409e-17,\n",
      "         1.04083409e-17,   2.42861287e-17,   1.69491525e-02,\n",
      "         3.38983051e-02,   1.69491525e-02,   2.42861287e-17,\n",
      "         3.38983051e-02,   3.38983051e-02,   2.42861287e-17,\n",
      "         1.69491525e-02,   1.69491525e-02,   3.38983051e-02,\n",
      "         3.38983051e-02,   2.42861287e-17,   1.00000000e+00])), (2, array([  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         8.00000000e-01,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         4.00000000e-01,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   4.00000000e-01,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   1.11022302e-16])), (3, array([  1.00000000e+00,  -5.55111512e-16,   1.00000000e+00,\n",
      "         9.39393939e-01,   1.21212121e-01,   9.09090909e-02,\n",
      "         3.03030303e-02,   3.03030303e-01,   3.03030303e-02,\n",
      "         3.03030303e-02,   1.38777878e-17,   3.03030303e-02,\n",
      "        -2.08166817e-17,   3.03030303e-02,  -3.46944695e-17,\n",
      "        -6.93889390e-18,   3.03030303e-02,   6.06060606e-02,\n",
      "         1.21212121e-01,   0.00000000e+00,   1.21212121e-01,\n",
      "         0.00000000e+00,   9.09090909e-02,   9.09090909e-02,\n",
      "         3.03030303e-02,  -1.73472348e-17,   9.09090909e-02,\n",
      "        -1.73472348e-17,   3.03030303e-02,  -1.73472348e-17,\n",
      "        -1.73472348e-17,   3.03030303e-02,   3.03030303e-02,\n",
      "        -1.73472348e-17,   9.09090909e-02,   9.09090909e-02,\n",
      "         9.09090909e-02,   0.00000000e+00,   3.03030303e-02,\n",
      "         0.00000000e+00,   3.03030303e-02,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   6.06060606e-02,\n",
      "         3.03030303e-02,   3.03030303e-02,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   6.66133815e-16])), (4, array([  1.00000000e+00,   1.00000000e+00,   2.22222222e-01,\n",
      "         0.00000000e+00,   2.22222222e-01,   1.38777878e-17,\n",
      "         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         5.55555556e-01,   1.00000000e+00,   0.00000000e+00,\n",
      "         2.22222222e-01,  -1.38777878e-17,   0.00000000e+00,\n",
      "         5.55555556e-01,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   2.22222222e-01,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   2.22222222e-01,   2.00000000e+00]))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def Clustering(df_combined, n_clusters=5):\n",
    "    _X = np.array(df_combined.ix[:,5:(df_combined.shape)[1]])\n",
    "    k_means = KMeans(init='k-means++', n_clusters= n_clusters, n_init=20)\n",
    "    k_means.fit(_X)\n",
    "    k_means_labels = k_means.labels_\n",
    "    k_means_cluster_centers = k_means.cluster_centers_\n",
    "    k_means_labels_unique = np.unique(k_means_labels)\n",
    "    ft = (k_means_labels, k_means_cluster_centers, k_means_labels_unique)\n",
    "    labels = np.array(k_means_labels_unique)\n",
    "    location = np.array(k_means_cluster_centers)\n",
    "    labels_location = list(zip(labels, location))\n",
    "    # person_df['cluster_label'] = pd.DataFrame(k_means_labels)\n",
    "    print (\"labels:\\n %s, \\n cluster centers:\\n %s,\\n  unique labels:\\n %s\" % ft)\n",
    "    print(labels_location)\n",
    "    return k_means_labels\n",
    "\n",
    "k_means_labels = Clustering(df_combined, n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 56)\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "print(df_combined.shape)\n",
    "print(len(k_means_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_combined['k_means'] = list(k_means_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: None, 1: None, 2: None, 3: None, 4: None}"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = list(labels)\n",
    "dict_grouping = dict.fromkeys(unique_labels)\n",
    "dict_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = df_combined[['k_means','descriptions']]\n",
    "subset = subset.values.tolist()\n",
    "# subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_grouping = defaultdict(list)\n",
    "for key, date in subset:\n",
    "    dict_grouping[key].append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['grinning face with smiling eyes', 'smiling face with open mouth', 'smiling face with open mouth and smiling eyes', 'smiling face with open mouth and cold sweat', 'smiling face with open mouth and tightly-closed eyes', 'smiling face with smiling eyes', 'face savouring delicious food', 'smiling face with sunglasses', 'smiling face with heart-shaped eyes', 'kissing face with smiling eyes', 'white smiling face', 'slightly smiling face', 'face with open mouth', 'frowning face with open mouth', 'face with open mouth and cold sweat']\n",
      "\n",
      "\n",
      "1\n",
      "['grinning face', 'face with tears of joy', 'winking face', 'face throwing a kiss', 'kissing face', 'kissing face with closed eyes', 'hugging face', 'thinking face', 'neutral face', 'expressionless face', 'face without mouth', 'face with rolling eyes', 'smirking face', 'persevering face', 'disappointed but relieved face', 'zipper-mouth face', 'hushed face', 'sleepy face', 'tired face', 'sleeping face', 'relieved face', 'nerd face', 'face with stuck-out tongue', 'face with stuck-out tongue and winking eye', 'face with stuck-out tongue and tightly-closed eyes', 'white frowning face', 'slightly frowning face', 'unamused face', 'face with cold sweat', 'pensive face', 'confused face', 'confounded face', 'upside-down face', 'face with medical mask', 'face with thermometer', 'face with head-bandage', 'money-mouth face', 'astonished face', 'disappointed face', 'worried face', 'face with look of triumph', 'crying face', 'loudly crying face', 'anguished face', 'fearful face', 'weary face', 'grimacing face', 'face screaming in fear', 'flushed face', 'dizzy face', 'pouting face', 'angry face', 'skull', 'skull and crossbones', 'robot face', 'helmet with white cross', 'speaking head in silhouette', 'eyes', 'moyai']\n",
      "\n",
      "\n",
      "2\n",
      "['new moon with face', 'first quarter moon with face', 'last quarter moon with face', 'full moon with face', 'sun with face']\n",
      "\n",
      "\n",
      "3\n",
      "['pile of poo', 'smiling cat face with open mouth', 'grinning cat face with smiling eyes', 'cat face with tears of joy', 'smiling cat face with heart-shaped eyes', 'cat face with wry smile', 'kissing cat face with closed eyes', 'weary cat face', 'crying cat face', 'pouting cat face', 'see-no-evil monkey', 'hear-no-evil monkey', 'speak-no-evil monkey', 'monkey face', 'dog face', 'wolf face', 'cat face', 'lion face', 'tiger face', 'horse face', 'unicorn face', 'cow face', 'pig face', 'pig nose', 'mouse face', 'hamster face', 'rabbit face', 'bear face', 'panda face', 'frog face', 'dragon face', 'spouting whale', 'wind blowing face']\n",
      "\n",
      "\n",
      "4\n",
      "['smiling face with halo', 'smiling face with horns', 'imp', 'japanese ogre', 'japanese goblin', 'ghost', 'extraterrestrial alien', 'alien monster', 'baby angel']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in dict_grouping.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>titles</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_binary</th>\n",
       "      <th>face</th>\n",
       "      <th>person</th>\n",
       "      <th>nature</th>\n",
       "      <th>animal</th>\n",
       "      <th>smile</th>\n",
       "      <th>...</th>\n",
       "      <th>quarter</th>\n",
       "      <th>wink</th>\n",
       "      <th>mad</th>\n",
       "      <th>pig</th>\n",
       "      <th>pouting</th>\n",
       "      <th>speak</th>\n",
       "      <th>fear</th>\n",
       "      <th>disappointed</th>\n",
       "      <th>alien</th>\n",
       "      <th>k_means</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[face, grin, person]</td>\n",
       "      <td>grinning face</td>\n",
       "      <td>U+1F600</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, False, False, False...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[eye, face, grin, person, smile]</td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "      <td>U+1F601</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, True, True, False, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[face, joy, person, tear]</td>\n",
       "      <td>face with tears of joy</td>\n",
       "      <td>U+1F602</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, False, False, False...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[face, mouth, open, person, smile]</td>\n",
       "      <td>smiling face with open mouth</td>\n",
       "      <td>U+1F603</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, True, False, False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[eye, face, mouth, open, person, smile]</td>\n",
       "      <td>smiling face with open mouth and smiling eyes</td>\n",
       "      <td>U+1F604</td>\n",
       "      <td>[face, person, nature, animal, smile, eye, fai...</td>\n",
       "      <td>[True, True, False, False, True, True, False, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               annotations  \\\n",
       "0                     [face, grin, person]   \n",
       "1         [eye, face, grin, person, smile]   \n",
       "2                [face, joy, person, tear]   \n",
       "3       [face, mouth, open, person, smile]   \n",
       "4  [eye, face, mouth, open, person, smile]   \n",
       "\n",
       "                                    descriptions   titles  \\\n",
       "0                                  grinning face  U+1F600   \n",
       "1                grinning face with smiling eyes  U+1F601   \n",
       "2                         face with tears of joy  U+1F602   \n",
       "3                   smiling face with open mouth  U+1F603   \n",
       "4  smiling face with open mouth and smiling eyes  U+1F604   \n",
       "\n",
       "                                           top_words  \\\n",
       "0  [face, person, nature, animal, smile, eye, fai...   \n",
       "1  [face, person, nature, animal, smile, eye, fai...   \n",
       "2  [face, person, nature, animal, smile, eye, fai...   \n",
       "3  [face, person, nature, animal, smile, eye, fai...   \n",
       "4  [face, person, nature, animal, smile, eye, fai...   \n",
       "\n",
       "                                          top_binary  face  person  nature  \\\n",
       "0  [True, True, False, False, False, False, False...     1       1       0   \n",
       "1  [True, True, False, False, True, True, False, ...     1       1       0   \n",
       "2  [True, True, False, False, False, False, False...     1       1       0   \n",
       "3  [True, True, False, False, True, False, False,...     1       1       0   \n",
       "4  [True, True, False, False, True, True, False, ...     1       1       0   \n",
       "\n",
       "   animal  smile   ...     quarter  wink  mad  pig  pouting  speak  fear  \\\n",
       "0       0      0   ...           0     0    0    0        0      0     0   \n",
       "1       0      1   ...           0     0    0    0        0      0     0   \n",
       "2       0      0   ...           0     0    0    0        0      0     0   \n",
       "3       0      1   ...           0     0    0    0        0      0     0   \n",
       "4       0      1   ...           0     0    0    0        0      0     0   \n",
       "\n",
       "   disappointed  alien  k_means  \n",
       "0             0      0        1  \n",
       "1             0      0        0  \n",
       "2             0      0        1  \n",
       "3             0      0        0  \n",
       "4             0      0        0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts= df_combined.annotations\n",
    "\n",
    "#create a Gensim dictionary from the texts\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "#remove extremes (similar to the min/max df step used when creating the tf-idf matrix)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.8)\n",
    "\n",
    "#convert the dictionary to a bag of words corpus for reference\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x10c301898>"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 20.3 ms, total: 12.7 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%time lda = models.LdaModel(corpus, num_topics=10, \\\n",
    "                            id2word=dictionary, \\\n",
    "                            update_every=5, \\\n",
    "                            chunksize=10000, \\\n",
    "                            passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.160*person + 0.054*tear + 0.054*body + 0.054*sad + 0.054*cry + 0.037*monster + 0.037*tongue + 0.037*wink + 0.037*death + 0.037*skull'),\n",
       " (1,\n",
       "  '0.220*person + 0.084*mouth + 0.074*smile + 0.067*open + 0.034*eye + 0.026*frown + 0.026*sweat + 0.026*cold + 0.026*heart + 0.017*mad'),\n",
       " (2,\n",
       "  '0.085*grin + 0.065*person + 0.030*surprised + 0.030*moyai + 0.030*statue + 0.030*travel + 0.030*stunned + 0.030*hushed + 0.030*place + 0.030*horse'),\n",
       " (3,\n",
       "  '0.142*person + 0.127*eye + 0.091*kiss + 0.070*smile + 0.020*horrible + 0.020*taste + 0.020*injury + 0.020*bandage + 0.020*hurt + 0.020*blush'),\n",
       " (4,\n",
       "  '0.226*nature + 0.183*animal + 0.074*cat + 0.045*weather + 0.037*place + 0.037*space + 0.030*moon + 0.030*pet + 0.015*quarter + 0.015*pig'),\n",
       " (5,\n",
       "  '0.167*person + 0.098*fairy tale + 0.088*fantasy + 0.059*monster + 0.049*creature + 0.030*smile + 0.021*nature + 0.020*alien + 0.020*extraterrestrial + 0.020*ufo'),\n",
       " (6,\n",
       "  '0.130*person + 0.034*tired + 0.034*joy + 0.034*tear + 0.021*nature + 0.018*weary + 0.018*delicious + 0.018*um + 0.018*food + 0.018*yum'),\n",
       " (7,\n",
       "  '0.097*animal + 0.097*nature + 0.063*monkey + 0.048*forbidden + 0.048*prohibited + 0.048*not + 0.048*evil + 0.048*no + 0.048*gesture + 0.017*speak'),\n",
       " (8,\n",
       "  '0.102*person + 0.069*sick + 0.036*cold + 0.036*doctor + 0.036*mask + 0.036*medicine + 0.036*triumph + 0.036*won + 0.003*ill + 0.003*thermometer'),\n",
       " (9,\n",
       "  '0.159*person + 0.045*disappointed + 0.045*relieved + 0.024*sleep + 0.024*fearful + 0.024*fear + 0.024*scared + 0.024*head + 0.024*silhouette + 0.024*speaking')]"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('person', 0.15961170571365257),\n",
       "   ('tear', 0.054049528870208134),\n",
       "   ('body', 0.054048960919355127),\n",
       "   ('sad', 0.054048889347755584),\n",
       "   ('cry', 0.054048889347755501),\n",
       "   ('monster', 0.036613954044276337),\n",
       "   ('tongue', 0.036613914152601776),\n",
       "   ('wink', 0.036613820149575593),\n",
       "   ('death', 0.03661380121855598),\n",
       "   ('skull', 0.036613801218555647),\n",
       "   ('eye', 0.036612959518771401),\n",
       "   ('sob', 0.019178667725240899),\n",
       "   ('joke', 0.019178667725222757),\n",
       "   ('rolling', 0.019178667690230852),\n",
       "   ('eyes', 0.019178667690229384),\n",
       "   ('fairy tale', 0.019178116009641769),\n",
       "   ('crossbones', 0.0017580003381538812),\n",
       "   ('cat', 0.0017436440999485186),\n",
       "   ('animal', 0.0017435659004636809),\n",
       "   ('nature', 0.0017435561814640567)]),\n",
       " (1,\n",
       "  [('person', 0.21984458527397097),\n",
       "   ('mouth', 0.08379984779038116),\n",
       "   ('smile', 0.07404616692994731),\n",
       "   ('open', 0.06720580127213728),\n",
       "   ('eye', 0.034035309510224009),\n",
       "   ('frown', 0.02572075675343655),\n",
       "   ('sweat', 0.025720709808085301),\n",
       "   ('cold', 0.025720547266088682),\n",
       "   ('heart', 0.025720537191618636),\n",
       "   ('mad', 0.017423737483722172),\n",
       "   ('angry', 0.017423737483721825),\n",
       "   ('love', 0.017423632530453106),\n",
       "   ('sun', 0.0091268631066823633),\n",
       "   ('cool', 0.0091267201568181883),\n",
       "   ('glasses', 0.00912672015681802),\n",
       "   ('sunglasses', 0.0091267201568180131),\n",
       "   ('eyewear', 0.0091267201568179905),\n",
       "   ('laugh', 0.0091267201401104853),\n",
       "   ('satisfied', 0.0091267201401103327),\n",
       "   ('red', 0.0091267201401010346)]),\n",
       " (2,\n",
       "  [('grin', 0.084746774143314552),\n",
       "   ('person', 0.064572201712389615),\n",
       "   ('surprised', 0.030089059776987458),\n",
       "   ('moyai', 0.030088572850363267),\n",
       "   ('statue', 0.030088572850363232),\n",
       "   ('travel', 0.030088572850362066),\n",
       "   ('stunned', 0.030088572850265113),\n",
       "   ('hushed', 0.030088572850263146),\n",
       "   ('place', 0.030088543707117579),\n",
       "   ('horse', 0.03008775091281737),\n",
       "   ('japanese', 0.030087611930109892),\n",
       "   ('goblin', 0.030087439428520574),\n",
       "   ('pouting', 0.030087357886824723),\n",
       "   ('ghost', 0.030085703460120791),\n",
       "   ('creature', 0.0027356057239091326),\n",
       "   ('smile', 0.0027355715588191724),\n",
       "   ('monster', 0.0027355556610013771),\n",
       "   ('cat', 0.0027354796459144346),\n",
       "   ('fantasy', 0.0027354749388370752),\n",
       "   ('eye', 0.002735469122882707)]),\n",
       " (3,\n",
       "  [('person', 0.14221855939471745),\n",
       "   ('eye', 0.12683444192750293),\n",
       "   ('kiss', 0.091132984991636065),\n",
       "   ('smile', 0.069781185189414299),\n",
       "   ('horrible', 0.01965617263121576),\n",
       "   ('taste', 0.01965617263121475),\n",
       "   ('injury', 0.019656172618583975),\n",
       "   ('bandage', 0.019656172618582452),\n",
       "   ('hurt', 0.019656172618581717),\n",
       "   ('blush', 0.019656172618574556),\n",
       "   ('deadpan', 0.019656172596336105),\n",
       "   ('neutral', 0.019656172596335984),\n",
       "   ('tongue', 0.019656076301156841),\n",
       "   ('blow', 0.019655966488822632),\n",
       "   ('cloud', 0.019655966488822129),\n",
       "   ('wind', 0.019655966488822001),\n",
       "   ('tiger', 0.01965534578759285),\n",
       "   ('closed', 0.0017904820789899102),\n",
       "   ('grin', 0.0017876603129742669),\n",
       "   ('weather', 0.0017873028145806316)]),\n",
       " (4,\n",
       "  [('nature', 0.2257671586044703),\n",
       "   ('animal', 0.18311482165201837),\n",
       "   ('cat', 0.074192705494055156),\n",
       "   ('weather', 0.044809569104233234),\n",
       "   ('place', 0.037463763118964044),\n",
       "   ('space', 0.037463762109121619),\n",
       "   ('moon', 0.030117932939587023),\n",
       "   ('pet', 0.030117799260049535),\n",
       "   ('quarter', 0.015426258316803384),\n",
       "   ('pig', 0.015426258259801489),\n",
       "   ('bright', 0.01542622933365969),\n",
       "   ('smile', 0.010802319075541125),\n",
       "   ('full', 0.0080804210058587501),\n",
       "   ('time', 0.0080804209997534533),\n",
       "   ('oh', 0.0080804209997349385),\n",
       "   ('wry', 0.0080804209997151731),\n",
       "   ('ironic', 0.0080804209997148574),\n",
       "   ('bunny', 0.008080420991008844),\n",
       "   ('rabbit', 0.008080420991008485),\n",
       "   ('whale', 0.0080804209774389159)]),\n",
       " (5,\n",
       "  [('person', 0.16662037824052489),\n",
       "   ('fairy tale', 0.09761325276175771),\n",
       "   ('fantasy', 0.087948375100906417),\n",
       "   ('monster', 0.058954447380910761),\n",
       "   ('creature', 0.04928963598663462),\n",
       "   ('smile', 0.029960083848906204),\n",
       "   ('nature', 0.02058099149375035),\n",
       "   ('alien', 0.020295798719329024),\n",
       "   ('extraterrestrial', 0.020295798719328895),\n",
       "   ('ufo', 0.020295798719328736),\n",
       "   ('angel', 0.020295798704943056),\n",
       "   ('space', 0.02029578974659263),\n",
       "   ('innocent', 0.010631132638542609),\n",
       "   ('halo', 0.010631132638542151),\n",
       "   ('devil', 0.010631132623913157),\n",
       "   ('baby', 0.010631132623913121),\n",
       "   ('imp', 0.010631132623912909),\n",
       "   ('horns', 0.010631132623895746),\n",
       "   ('totally', 0.010631132610537697),\n",
       "   ('astonished', 0.010631132610537145)]),\n",
       " (6,\n",
       "  [('person', 0.12961449204980413),\n",
       "   ('tired', 0.033603965732115874),\n",
       "   ('joy', 0.033603758199839309),\n",
       "   ('tear', 0.033603170681963834),\n",
       "   ('nature', 0.020691780918927899),\n",
       "   ('weary', 0.017602180052301603),\n",
       "   ('delicious', 0.017602077459703536),\n",
       "   ('um', 0.017602077459703245),\n",
       "   ('food', 0.017602077459703103),\n",
       "   ('yum', 0.017602077459703089),\n",
       "   ('savouring', 0.017602077459702367),\n",
       "   ('dung', 0.017602077459702031),\n",
       "   ('comic', 0.017602077459701902),\n",
       "   ('poo', 0.017602077459701736),\n",
       "   ('poop', 0.017602077459701465),\n",
       "   ('object', 0.017602077459701347),\n",
       "   ('munch', 0.017602077453942541),\n",
       "   ('scream', 0.017602077453941947),\n",
       "   ('nerd', 0.017602077410306831),\n",
       "   ('geek', 0.017602077410303858)]),\n",
       " (7,\n",
       "  [('animal', 0.097071418127065517),\n",
       "   ('nature', 0.096624016941751975),\n",
       "   ('monkey', 0.063452799552206549),\n",
       "   ('forbidden', 0.04797650702899145),\n",
       "   ('prohibited', 0.047976507028990818),\n",
       "   ('not', 0.047976507028990659),\n",
       "   ('evil', 0.047976507028990464),\n",
       "   ('no', 0.047976507028990367),\n",
       "   ('gesture', 0.047976507028988938),\n",
       "   ('speak', 0.017023926962466417),\n",
       "   ('hear', 0.017023921832616341),\n",
       "   ('see', 0.017023921832616123),\n",
       "   ('aid', 0.01702392180806429),\n",
       "   ('helmet', 0.01702392180806387),\n",
       "   ('cross', 0.017023921808063641),\n",
       "   ('hat', 0.017023921808063416),\n",
       "   ('bear', 0.017023921772933895),\n",
       "   ('wolf', 0.017023921772931837),\n",
       "   ('dog', 0.017023118306665568),\n",
       "   ('person', 0.017014235458569449)]),\n",
       " (8,\n",
       "  [('person', 0.10231330087946473),\n",
       "   ('sick', 0.069305437138151835),\n",
       "   ('cold', 0.036303568217175827),\n",
       "   ('doctor', 0.036302921642493699),\n",
       "   ('mask', 0.036302921642493061),\n",
       "   ('medicine', 0.036302921642492957),\n",
       "   ('triumph', 0.036302921603908307),\n",
       "   ('won', 0.036302921603907315),\n",
       "   ('ill', 0.0033072354354876854),\n",
       "   ('thermometer', 0.0033072354354872174),\n",
       "   ('crossbones', 0.0033002659171159333),\n",
       "   ('robot', 0.0033002659169178009),\n",
       "   ('sun', 0.0033002657654221485),\n",
       "   ('closed', 0.0033002657635020009),\n",
       "   ('dragon', 0.0033002657435838574),\n",
       "   ('frog', 0.0033002657435177913),\n",
       "   ('tiger', 0.0033002657334190331),\n",
       "   ('smile', 0.0033002657273352803),\n",
       "   ('pouting', 0.0033002657212202005),\n",
       "   ('grimace', 0.0033002657174593351)]),\n",
       " (9,\n",
       "  [('person', 0.1586079801262899),\n",
       "   ('disappointed', 0.045074817579757814),\n",
       "   ('relieved', 0.045074812281148603),\n",
       "   ('sleep', 0.02361098955695437),\n",
       "   ('fearful', 0.023610640562253309),\n",
       "   ('fear', 0.023610640562252108),\n",
       "   ('scared', 0.023610640562251487),\n",
       "   ('head', 0.023610618771388266),\n",
       "   ('silhouette', 0.023610618771388068),\n",
       "   ('speaking', 0.023610618771387877),\n",
       "   ('whew', 0.023610618759052279),\n",
       "   ('thinking', 0.023610618689280313),\n",
       "   ('speak', 0.023610611665470998),\n",
       "   ('cow', 0.023609793355208266),\n",
       "   ('panda', 0.023609793354680404),\n",
       "   ('unicorn', 0.023609793354377333),\n",
       "   ('ogre', 0.023609627369657465),\n",
       "   ('japanese', 0.023609483659396885),\n",
       "   ('hamster', 0.023609286826465372),\n",
       "   ('animal', 0.0021466333418621118)])]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_matrix = lda.show_topics(formatted=False, num_words=20)\n",
    "topics_matrix\n",
    "# topics_matrix = np.array(topics_matrix)\n",
    "\n",
    "# topic_words = topics_matrix[:,:,1]\n",
    "# for i in topic_words:\n",
    "#     print([str(word) for word in i])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, LabeledSentence, Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledSentence(words=['face', 'grin', 'person'], tags=['grinning face']),\n",
       " LabeledSentence(words=['eye', 'face', 'grin', 'person', 'smile'], tags=['grinning face with smiling eyes']),\n",
       " LabeledSentence(words=['face', 'joy', 'person', 'tear'], tags=['face with tears of joy']),\n",
       " LabeledSentence(words=['face', 'mouth', 'open', 'person', 'smile'], tags=['smiling face with open mouth']),\n",
       " LabeledSentence(words=['eye', 'face', 'mouth', 'open', 'person', 'smile'], tags=['smiling face with open mouth and smiling eyes']),\n",
       " LabeledSentence(words=['cold', 'face', 'open', 'person', 'smile', 'sweat'], tags=['smiling face with open mouth and cold sweat']),\n",
       " LabeledSentence(words=['face', 'laugh', 'mouth', 'open', 'person', 'satisfied', 'smile'], tags=['smiling face with open mouth and tightly-closed eyes']),\n",
       " LabeledSentence(words=['face', 'person', 'wink'], tags=['winking face']),\n",
       " LabeledSentence(words=['blush', 'eye', 'face', 'person', 'smile'], tags=['smiling face with smiling eyes']),\n",
       " LabeledSentence(words=['delicious', 'face', 'food', 'person', 'savouring', 'smile', 'um', 'yum'], tags=['face savouring delicious food']),\n",
       " LabeledSentence(words=['bright', 'cool', 'eye', 'eyewear', 'face', 'glasses', 'person', 'smile', 'sun', 'sunglasses', 'weather'], tags=['smiling face with sunglasses']),\n",
       " LabeledSentence(words=['eye', 'face', 'heart', 'love', 'person', 'smile'], tags=['smiling face with heart-shaped eyes']),\n",
       " LabeledSentence(words=['face', 'heart', 'kiss', 'person'], tags=['face throwing a kiss']),\n",
       " LabeledSentence(words=['face', 'kiss', 'person'], tags=['kissing face']),\n",
       " LabeledSentence(words=['eye', 'face', 'kiss', 'person', 'smile'], tags=['kissing face with smiling eyes']),\n",
       " LabeledSentence(words=['closed', 'eye', 'face', 'kiss', 'person'], tags=['kissing face with closed eyes']),\n",
       " LabeledSentence(words=['face', 'outlined', 'person', 'relaxed', 'smile'], tags=['white smiling face']),\n",
       " LabeledSentence(words=['face', 'person', 'smile'], tags=['slightly smiling face']),\n",
       " LabeledSentence(words=['face', 'hug', 'hugging', 'person'], tags=['hugging face']),\n",
       " LabeledSentence(words=['angel', 'face', 'fairy tale', 'fantasy', 'halo', 'innocent', 'person', 'smile'], tags=['smiling face with halo']),\n",
       " LabeledSentence(words=['face', 'person', 'thinking'], tags=['thinking face']),\n",
       " LabeledSentence(words=['deadpan', 'face', 'neutral', 'person'], tags=['neutral face']),\n",
       " LabeledSentence(words=['expressionless', 'face', 'inexpressive', 'person', 'unexpressive'], tags=['expressionless face']),\n",
       " LabeledSentence(words=['face', 'mouth', 'person', 'quiet', 'silent'], tags=['face without mouth']),\n",
       " LabeledSentence(words=['eyes', 'face', 'person', 'rolling'], tags=['face with rolling eyes']),\n",
       " LabeledSentence(words=['face', 'person', 'smirk'], tags=['smirking face']),\n",
       " LabeledSentence(words=['face', 'persevere', 'person'], tags=['persevering face']),\n",
       " LabeledSentence(words=['disappointed', 'face', 'person', 'relieved', 'whew'], tags=['disappointed but relieved face']),\n",
       " LabeledSentence(words=['face', 'mouth', 'open', 'person', 'sympathy'], tags=['face with open mouth']),\n",
       " LabeledSentence(words=['face', 'mouth', 'person', 'zipper'], tags=['zipper-mouth face']),\n",
       " LabeledSentence(words=['face', 'hushed', 'person', 'stunned', 'surprised'], tags=['hushed face']),\n",
       " LabeledSentence(words=['face', 'person', 'sleep'], tags=['sleepy face']),\n",
       " LabeledSentence(words=['face', 'person', 'tired'], tags=['tired face']),\n",
       " LabeledSentence(words=['face', 'person', 'sleep', 'zzz'], tags=['sleeping face']),\n",
       " LabeledSentence(words=['face', 'person', 'relieved'], tags=['relieved face']),\n",
       " LabeledSentence(words=['face', 'geek', 'nerd', 'person'], tags=['nerd face']),\n",
       " LabeledSentence(words=['face', 'person', 'tongue'], tags=['face with stuck-out tongue']),\n",
       " LabeledSentence(words=['eye', 'face', 'joke', 'person', 'tongue', 'wink'], tags=['face with stuck-out tongue and winking eye']),\n",
       " LabeledSentence(words=['eye', 'face', 'horrible', 'person', 'taste', 'tongue'], tags=['face with stuck-out tongue and tightly-closed eyes']),\n",
       " LabeledSentence(words=['face', 'frown', 'person'], tags=['white frowning face']),\n",
       " LabeledSentence(words=['face', 'frown', 'person'], tags=['slightly frowning face']),\n",
       " LabeledSentence(words=['face', 'person', 'unamused', 'unhappy'], tags=['unamused face']),\n",
       " LabeledSentence(words=['cold', 'face', 'person', 'sweat'], tags=['face with cold sweat']),\n",
       " LabeledSentence(words=['dejected', 'face', 'pensive', 'person'], tags=['pensive face']),\n",
       " LabeledSentence(words=['confused', 'face', 'person'], tags=['confused face']),\n",
       " LabeledSentence(words=['confounded', 'face', 'person'], tags=['confounded face']),\n",
       " LabeledSentence(words=['face', 'person', 'upside-down'], tags=['upside-down face']),\n",
       " LabeledSentence(words=['cold', 'doctor', 'face', 'mask', 'medicine', 'person', 'sick'], tags=['face with medical mask']),\n",
       " LabeledSentence(words=['face', 'ill', 'person', 'sick', 'thermometer'], tags=['face with thermometer']),\n",
       " LabeledSentence(words=['bandage', 'face', 'hurt', 'injury', 'person'], tags=['face with head-bandage']),\n",
       " LabeledSentence(words=['face', 'money', 'mouth', 'person'], tags=['money-mouth face']),\n",
       " LabeledSentence(words=['astonished', 'face', 'person', 'shocked', 'totally'], tags=['astonished face']),\n",
       " LabeledSentence(words=['disappointed', 'face', 'person'], tags=['disappointed face']),\n",
       " LabeledSentence(words=['face', 'person', 'worried'], tags=['worried face']),\n",
       " LabeledSentence(words=['face', 'person', 'triumph', 'won'], tags=['face with look of triumph']),\n",
       " LabeledSentence(words=['cry', 'face', 'person', 'sad', 'tear'], tags=['crying face'])]"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_sentence(_df):\n",
    "    sentences = []\n",
    "    for uid, line in enumerate(_df):\n",
    "        sentences.append(LabeledSentence(words=df_combined.annotations[uid], \\\n",
    "                              tags=[df_combined.descriptions[uid]]))\n",
    "    return sentences\n",
    "\n",
    "label_sentence(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = list(LabeledSentence(df_combined.annotations[uid], (df_combined.descriptions[uid])) for uid, value in enumerate(df_combined))\n",
    "model = Doc2Vec(size=200, min_count=1, workers=16)\n",
    "model.build_vocab(sentences)\n",
    "\n",
    "\n",
    "# model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=8)\n",
    "\n",
    "# model.build_vocab(sentences.to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train(sentences)\n",
    "    model.alpha -= 0.002  # decrease the learning rate\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'face with thermometer' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-609-1f46b5db7b7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sims = model.docvecs.most_similar(['grinning face'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.most_similar('grinning face')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"face with thermometer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/carlo_liquido/anaconda/lib/python3.4/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                 \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute similarity with no input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'face with thermometer' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "# sims = model.docvecs.most_similar(['grinning face'])\n",
    "# model.most_similar('grinning face')\n",
    "model.most_similar(\"face with thermometer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
